---
title: "A post-truth public? How the impact of fact-checks is undermined by post-truth
  rhetoric"
output:
  pdf_document: default
  bookdown::html_document2: default
  bookdown::word_document2: default
  bookdown::pdf_document2: default
  word_document: default
fontsize: 12pt
header-includes: \usepackage{setspace}\doublespacing
bibliography: post_truth4.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width=10, warning = FALSE, message = FALSE, echo = FALSE)
```

```{r warning = FALSE, message = FALSE, echo = FALSE} 

# install.packages("arsenal", lib="H:/R/win-library/4.1.2")
# install.packages("dotwhisker", lib="H:/R/win-library/4.1.2")
# install.packages("stargazer", lib="H:/R/win-library/4.1.2")
# install.packages("ggthemes", lib="H:/R/win-library/4.1.2")
# install.packages("ggThemeAssist", lib="H:/R/win-library/4.1.2")
# install.packages("viridis", lib="H:/R/win-library/4.1.2")
# install.packages("hrbrthemes", lib="H:/R/win-library/4.1.2")

rm(list = ls())
setwd("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/") 

library(haven) # for read_dta
library(dplyr) 
library(stringr)
# library(tidyr) 
library(ggplot2)
library(stargazer)
library(knitr)

library(scales) 
library(ggthemes) 
library(ggThemeAssist) 
library(colorspace) 
library(RColorBrewer) 
library(purrr)
library(Hmisc)
library(xtable)
library(viridis)
library(hrbrthemes)

library(modelsummary)
# devtools::install_github("kupietz/kableExtra") # https://stackoverflow.com/questions/76118194/error-when-loading-kableextra-in-markdown-file-after-updating-to-r-4-3-0
library(kableExtra)
library(gt) # for msummary -- tab_spanner
library(gtsummary) # for summary tables
library(arsenal) # for summary tables

# library(tidyverse) # for fct_reorder2
library(dotwhisker)


##### Read in data #####
df <- read_dta("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/rawData/Original data Stata version.dta")
# df <- read_dta("/Users/christine/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/rawData/Original data Stata version.dta")

##### Rename #####

names(df)[names(df) == "E1_1"] <- "issues_immig"
names(df)[names(df) == "E1_2"] <- "issues_econ"
names(df)[names(df) == "E1_3"] <- "issues_nhs"
names(df)[names(df) == "E1_4"] <- "issues_crime"
names(df)[names(df) == "E1_5"] <- "issues_eu"
names(df)[names(df) == "E1_6"] <- "issues_housing"
names(df)[names(df) == "E1_7"] <- "issues_edu"

names(df)[names(df) == "E2_1"] <- "ethno_lot_to_learn" #"ethno1"
names(df)[names(df) == "E2_2"] <- "pop_no_compromise" #"populism6"
names(df)[names(df) == "E2_3"] <- "ethno_Britain_best" # "ethno2"
names(df)[names(df) == "E2_4"] <- "pop_people_make_decisions" #"populism2"
names(df)[names(df) == "E2_5"] <- "immigFeelLikeHome"
names(df)[names(df) == "E2_7"] <- "ethno_less_proud_2B_British" #"ethno6"

names(df)[names(df) == "E3"] <- "leftright"
names(df)[names(df) == "E5"] <- "immigOpinions"
names(df)[names(df) == "E6"] <- "immigImportance"

names(df)[names(df) == "E8_1"] <- "ethno_ashamed_2B_British" # "ethno3"
names(df)[names(df) == "E8_2"] <- "ethno_be_more_like_Britain" #"ethno5"
names(df)[names(df) == "E8_3"] <- "pop_rep_by_citizen" # "populism4" 
names(df)[names(df) == "E8_4"] <- "pop_pol_talk_too_much" # "populism5"
names(df)[names(df) == "E8_5"] <- "immigEcon"
names(df)[names(df) == "E8_6"] <- "ethno_too_critical" #"ethno4"

names(df)[names(df) == "E9_1"] <- "noAsylum_T1"
names(df)[names(df) == "E9_2"] <- "costImmig_T1"
names(df)[names(df) == "E9_3"] <- "whiteCrime_T1"
names(df)[names(df) == "E9_4"] <- "lowPaid_T1"
names(df)[names(df) == "E9_5"] <- "no5_T1"
names(df)[names(df) == "E9_6"] <- "recession_T1"
names(df)[names(df) == "E9_7"] <- "fracking_T1"
names(df)[names(df) == "E9_8"] <- "plasticBags_T1"

names(df)[names(df) == "E15_1"] <- "noAsylum_T2"
names(df)[names(df) == "E15_2"] <- "costImmig_T2"
names(df)[names(df) == "E16_1"] <- "whiteCrime_T2"
names(df)[names(df) == "E16_2"] <- "lowPaid_T2"

names(df)[names(df) == "E17_1"] <- "noAsylum_opinion"
names(df)[names(df) == "E17_2"] <- "costImmig_opinion"

names(df)[names(df) == "E18_1"] <- "whiteCrime_opinion"
names(df)[names(df) == "E18_2"] <- "lowPaid_opinion"

names(df)[names(df) == "E19"] <- "consistent"
names(df)[names(df) == "E20"] <- "ifInconsistent"
names(df)[names(df) == "E21"] <- "ok2disagree"

names(df)[names(df) == "P11"] <- "accurateExpert"
names(df)[names(df) == "P12"] <- "trustExpert"

names(df)[names(df) == "P13"] <- "accuratePostTruthBlogger"
names(df)[names(df) == "P14"] <- "accuratePostTruthProf"

names(df)[names(df) == "P15"] <- "trustPostTruthBlogger"
names(df)[names(df) == "P16"] <- "trustPostTruthProf"

names(df)[names(df) == "QD7"] <- "marital"
names(df)[names(df) == "QD8_0"] <- "kidsNoAnswer"
names(df)[names(df) == "QD8_1"] <- "kidsNone"
names(df)[names(df) == "QD8_2"] <- "kidsUnder5"
names(df)[names(df) == "QD8_3"] <- "kids5To10"
names(df)[names(df) == "QD8_4"] <- "kids11To15"
names(df)[names(df) == "QD8_5"] <- "kids16To18"

names(df)[names(df) == "E7"] <- "votedBrexitRef"
names(df)[names(df) == "E7A"] <- "brexitVote"
names(df)[names(df) == "E7B"] <- "hypBrexitVote"

names(df)[names(df) == "QD9"] <- "householdIncome"
names(df)[names(df) == "E4a"] <- "supportParty"
names(df)[names(df) == "E4b"] <- "party"
names(df)[names(df) == "E4b_8_Other"] <- "otherParty"

names(df)[names(df) == "PolInt"] <- "attention"
names(df)[names(df) == "PollAtt"] <- "attentionCategory"
names(df)[names(df) == "FullAge"] <- "age"
names(df)[names(df) == "Regions"] <- "regions"
names(df)[names(df) == "Gender"] <- "gender"
names(df)[names(df) == "Age"] <- "ageCategory"
names(df)[names(df) == "Vote17"] <- "vote2017"
names(df)[names(df) == "SocGrade"] <- "socialGrade"
names(df)[names(df) == "Region"] <- "region"
names(df)[names(df) == "Quals"] <- "university"

names(df)[names(df) == "HIGH_TEXT2"] <- "whichFactCheckTxt"
names(df)[names(df) == "HIGH_TEXT_ID2"] <- "whichFactCheck"

names(df)[names(df) == "user_id"] <- "id"


#### Data management #### 

#### Managing variables -- Treatment groups ####

df$RandomGrp <- as.factor(df$RandomGrp)

# no comment first

df$treatment[df$RandomGrp=="1"] <- "No undermining message"
df$treatment[df$RandomGrp=="2"] <- "No undermining message"
df$treatment[df$RandomGrp=="3"] <- "Professor: Expert bias" # biased 
df$treatment[df$RandomGrp=="4"] <- "Professor: Personal experience"
df$treatment[df$RandomGrp=="5"] <- "Professor: Truthiness" # OK to disagree
df$treatment[df$RandomGrp=="6"] <- "Blogger: Expert bias"
df$treatment[df$RandomGrp=="7"] <- "Blogger: Personal experience"
df$treatment[df$RandomGrp=="8"] <- "Blogger: Truthiness"

df$treatment <- factor(df$treatment,
                        levels=c("No undermining message",
                                 "Professor: Expert bias",
                                 "Professor: Personal experience",
                                 "Professor: Truthiness",
                                 "Blogger: Expert bias",
                                 "Blogger: Personal experience",
                                 "Blogger: Truthiness"
                        )) 

# no comment last

df$treatment2[df$RandomGrp=="1"] <- "No undermining message"
df$treatment2[df$RandomGrp=="2"] <- "No undermining message"
df$treatment2[df$RandomGrp=="3"] <- "Professor: Expert bias"
df$treatment2[df$RandomGrp=="4"] <- "Professor: Personal experience"
df$treatment2[df$RandomGrp=="5"] <- "Professor: Truthiness"
df$treatment2[df$RandomGrp=="6"] <- "Blogger: Expert bias"
df$treatment2[df$RandomGrp=="7"] <- "Blogger: Personal experience"
df$treatment2[df$RandomGrp=="8"] <- "Blogger: Truthiness"

df$treatment2 <- factor(df$treatment2,
                       levels=c("Blogger: Truthiness",
                                "Professor: Truthiness",
                                "Blogger: Personal experience",
                                "Professor: Personal experience",
                                "Blogger: Expert bias",
                                "Professor: Expert bias",
                                "No undermining message"))

# including ns 

df$treatment3[df$RandomGrp=="1"] <- "No undermining message (n=737)"
df$treatment3[df$RandomGrp=="2"] <- "No undermining message (n=737)"
df$treatment3[df$RandomGrp=="3"] <- "Professor: Expert bias (n=357)"
df$treatment3[df$RandomGrp=="4"] <- "Professor: Personal experience (n=361)"
df$treatment3[df$RandomGrp=="5"] <- "Professor: Truthiness (n=388)"
df$treatment3[df$RandomGrp=="6"] <- "Blogger: Expert bias (n=361)"
df$treatment3[df$RandomGrp=="7"] <- "Blogger: Personal experience (n=375)"
df$treatment3[df$RandomGrp=="8"] <- "Blogger: Truthiness (n=357)"

df$treatment3 <- factor(df$treatment3,
                       levels=c("Blogger: Truthiness (n=357)", 
                                "Blogger: Personal experience (n=375)",
                                "Blogger: Expert bias (n=361)",
                                "Professor: Truthiness (n=388)",
                                "Professor: Personal experience (n=361)",
                                "Professor: Expert bias (n=357)",
                                "No undermining message (n=737)"))

# double check n
# df$treatment3

df$treated <- ifelse(df$RandomGrp %in% c(1,2), 0, 1)

df$comment[df$RandomGrp=="1"] <- "no comment"
df$comment[df$RandomGrp=="2"] <- "no comment"
df$comment[df$RandomGrp=="3"] <- "comment"
df$comment[df$RandomGrp=="4"] <- "comment"
df$comment[df$RandomGrp=="5"] <- "comment"
df$comment[df$RandomGrp=="6"] <- "comment"
df$comment[df$RandomGrp=="7"] <- "comment"
df$comment[df$RandomGrp=="8"] <- "comment"

df$comment <- factor(df$comment, 
                     levels = c("no comment",
                                "comment"))


df$comment2 <- df$comment

levels(df$comment2)[levels(df$comment2)=="comment"] <- "Undermining message"
levels(df$comment2)[levels(df$comment2)=="no comment"] <- "No undermining message"

df$comment2 <- factor(df$comment2,
                       levels=c("No undermining message", "Undermining message"))



df$source[df$RandomGrp=="1"] <- "no comment"
df$source[df$RandomGrp=="2"] <- "no comment"
df$source[df$RandomGrp=="3"] <- "Professor"
df$source[df$RandomGrp=="4"] <- "Professor"
df$source[df$RandomGrp=="5"] <- "Professor"
df$source[df$RandomGrp=="6"] <- "Blogger"
df$source[df$RandomGrp=="7"] <- "Blogger"
df$source[df$RandomGrp=="8"] <- "Blogger"

df$source <- factor(df$source, 
                     levels = c("no comment", "Professor", "Blogger"))


df$message[df$RandomGrp=="1"] <- "No undermining message"
df$message[df$RandomGrp=="2"] <- "No undermining message"
df$message[df$RandomGrp=="3"] <- "Expert bias" 
df$message[df$RandomGrp=="4"] <- "Personal experience"
df$message[df$RandomGrp=="5"] <- "Truthiness" 
df$message[df$RandomGrp=="6"] <- "Expert bias" 
df$message[df$RandomGrp=="7"] <- "Personal experience"
df$message[df$RandomGrp=="8"] <- "Truthiness" 

df$message <- factor(df$message, 
                    levels = c("No undermining message", 
                               "Expert bias", 
                               "Personal experience",
                               "Truthiness"))

# Create these same variables excluding the 'no comment' option

df$source2[df$RandomGrp=="1"] <- NA
df$source2[df$RandomGrp=="2"] <- NA
df$source2[df$RandomGrp=="3"] <- "Professor"
df$source2[df$RandomGrp=="4"] <- "Professor"
df$source2[df$RandomGrp=="5"] <- "Professor"
df$source2[df$RandomGrp=="6"] <- "Blogger"
df$source2[df$RandomGrp=="7"] <- "Blogger"
df$source2[df$RandomGrp=="8"] <- "Blogger"

df$source2 <- factor(df$source2, 
                    levels = c("Professor", "Blogger"))

df$message2[df$RandomGrp=="1"] <- NA
df$message2[df$RandomGrp=="2"] <- NA
df$message2[df$RandomGrp=="3"] <- "Expert bias" # Biased stats
df$message2[df$RandomGrp=="4"] <- "Personal experience"
df$message2[df$RandomGrp=="5"] <- "Truthiness" # OK to disagree
df$message2[df$RandomGrp=="6"] <- "Expert bias" # Biased stats
df$message2[df$RandomGrp=="7"] <- "Personal experience"
df$message2[df$RandomGrp=="8"] <- "Truthiness" # OK to disagree

df$message2 <- factor(df$message2, 
                     levels = c("Expert bias", 
                                "Personal experience",
                                "Truthiness"))

df$message3[df$RandomGrp=="1"] <- "No comment"
df$message3[df$RandomGrp=="2"] <- "No comment"
df$message3[df$RandomGrp=="3"] <- "Expert bias" # Biased stats
df$message3[df$RandomGrp=="4"] <- "Personal experience"
df$message3[df$RandomGrp=="5"] <- "Truthiness" # OK to disagree
df$message3[df$RandomGrp=="6"] <- "Expert bias" # Biased stats
df$message3[df$RandomGrp=="7"] <- "Personal experience"
df$message3[df$RandomGrp=="8"] <- "Truthiness" # OK to disagree

df$message3 <- factor(df$message3, 
                      levels = c("No comment",
                                 "Expert bias", 
                                 "Personal experience",
                                 "Truthiness"))

#### Managing variables -- Corrected fact check ####

df$whichFactCheck[df$whichFactCheck=="1"] <- "noAsylum"
df$whichFactCheck[df$whichFactCheck=="2"] <- "costImmig"
df$whichFactCheck[df$whichFactCheck=="3"] <- "whiteCrime"
df$whichFactCheck[df$whichFactCheck=="4"] <- "lowPaid"

df$whichFactCheck <- factor(df$whichFactCheck, 
                      levels = c("noAsylum", 
                                 "costImmig",
                                 "whiteCrime",
                                 "lowPaid"))


noAsylum_lbl <- "'There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years.'"
costImmig_lbl <- "'Immigrants receive more in benefits and services than they pay in taxes.'"
whiteCrime_lbl <- "'The majority of crimes in London are committed by white people, not ethnic minorities.'"
lowPaid_lbl <- "'Immigration to the UK does not affect the wages of the low-paid.'"


df$whichFactCheck_long <- NA
df$whichFactCheck_long[df$whichFactCheck == "noAsylum"] <- noAsylum_lbl
df$whichFactCheck_long[df$whichFactCheck == "costImmig"] <- costImmig_lbl
df$whichFactCheck_long[df$whichFactCheck == "whiteCrime"] <- whiteCrime_lbl
df$whichFactCheck_long[df$whichFactCheck == "lowPaid"] <- lowPaid_lbl

df$whichFactCheck_long <- factor(df$whichFactCheck,
                                 levels = c("noAsylum", "costImmig",
                                            "whiteCrime", "lowPaid"),
                                 labels = c("No of asylum seekers",
                                            "Cost of immigration",
                                            "Crime in London",
                                            "Effect on low wages"))

df$whichFactCheckTxt <- factor(df$whichFactCheckTxt,
                               levels = c("There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years.", 
                                          "European immigrants receive more in benefits and services than they pay in taxes.",
                                          "The majority of crimes in London are committed by white people, not ethnic minorities.",
                                          "Immigration to the UK does not affect the wages of the low-paid."))
                                          

#### Managing variables -- DVs -- Belief in false claims ####

df$noAsylum_T1 <- as.character(df$noAsylum_T1)
df$noAsylum_T2 <- as.character(df$noAsylum_T2)

df$costImmig_T1 <- as.character(df$costImmig_T1)
df$costImmig_T2 <- as.character(df$costImmig_T2)

df$whiteCrime_T1 <- as.character(df$whiteCrime_T1)
df$whiteCrime_T2 <- as.character(df$whiteCrime_T2)

df$lowPaid_T1 <- as.character(df$lowPaid_T1)
df$lowPaid_T2 <- as.character(df$lowPaid_T2)

df$no5_T1 <- as.character(df$no5_T1)
df$plasticBags_T1 <- as.character(df$plasticBags_T1)
df$recession_T1 <- as.character(df$recession_T1)
df$plasticBags_T1 <- as.character(df$plasticBags_T1)
df$fracking_T1 <- as.character(df$fracking_T1)

# The original scale runs from 0 False to 6 True. 
# Recoding so that 0=True and 6=False (to make it more intuitive). 

# df$noAsylum_fac_T1 <- as.numeric(as.character(df$noAsylum_T1))

df$noAsylum_fac_T1[df$noAsylum_T1 == "1"] <- "6 - Definitely False"
df$noAsylum_fac_T1[df$noAsylum_T1 == "2"] <- "5"
df$noAsylum_fac_T1[df$noAsylum_T1 == "3"] <- "4"
df$noAsylum_fac_T1[df$noAsylum_T1 == "4"] <- "3"
df$noAsylum_fac_T1[df$noAsylum_T1 == "5"] <- "2"
df$noAsylum_fac_T1[df$noAsylum_T1 == "6"] <- "1"
df$noAsylum_fac_T1[df$noAsylum_T1 == "7"] <- "0 - Definitely True"

df$noAsylum_fac_T1 <- factor(df$noAsylum_fac_T1,
                            levels = c("0 - Definitely True", 
                                       "1", "2", "3", "4", "5", 
                                       "6 - Definitely False"))


df$noAsylum_fac_T2[df$noAsylum_T2 == "1"] <- "6 - Definitely False"
df$noAsylum_fac_T2[df$noAsylum_T2 == "2"] <- "5"
df$noAsylum_fac_T2[df$noAsylum_T2 == "3"] <- "4"
df$noAsylum_fac_T2[df$noAsylum_T2 == "4"] <- "3"
df$noAsylum_fac_T2[df$noAsylum_T2 == "5"] <- "2"
df$noAsylum_fac_T2[df$noAsylum_T2 == "6"] <- "1"
df$noAsylum_fac_T2[df$noAsylum_T2 == "7"] <- "0 - Definitely True"


df$noAsylum_fac_T2 <- factor(df$noAsylum_fac_T2,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))


df$costImmig_fac_T1[df$costImmig_T1 == "1"] <- "6 - Definitely False"
df$costImmig_fac_T1[df$costImmig_T1 == "2"] <- "5"
df$costImmig_fac_T1[df$costImmig_T1 == "3"] <- "4"
df$costImmig_fac_T1[df$costImmig_T1 == "4"] <- "3"
df$costImmig_fac_T1[df$costImmig_T1 == "5"] <- "2"
df$costImmig_fac_T1[df$costImmig_T1 == "6"] <- "1"
df$costImmig_fac_T1[df$costImmig_T1 == "7"] <- "0 - Definitely True"

df$costImmig_fac_T1 <- factor(df$costImmig_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$costImmig_fac_T2[df$costImmig_T2 == "1"] <- "6 - Definitely False"
df$costImmig_fac_T2[df$costImmig_T2 == "2"] <- "5"
df$costImmig_fac_T2[df$costImmig_T2 == "3"] <- "4"
df$costImmig_fac_T2[df$costImmig_T2 == "4"] <- "3"
df$costImmig_fac_T2[df$costImmig_T2 == "5"] <- "2"
df$costImmig_fac_T2[df$costImmig_T2 == "6"] <- "1"
df$costImmig_fac_T2[df$costImmig_T2 == "7"] <- "0 - Definitely True"

df$costImmig_fac_T2 <- factor(df$costImmig_fac_T2,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$whiteCrime_fac_T1[df$whiteCrime_T1 == "1"] <- "6 - Definitely False"
df$whiteCrime_fac_T1[df$whiteCrime_T1 == "2"] <- "5"
df$whiteCrime_fac_T1[df$whiteCrime_T1 == "3"] <- "4"
df$whiteCrime_fac_T1[df$whiteCrime_T1 == "4"] <- "3"
df$whiteCrime_fac_T1[df$whiteCrime_T1 == "5"] <- "2"
df$whiteCrime_fac_T1[df$whiteCrime_T1 == "6"] <- "1"
df$whiteCrime_fac_T1[df$whiteCrime_T1 == "7"] <- "0 - Definitely True"

df$whiteCrime_fac_T1 <- factor(df$whiteCrime_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$whiteCrime_fac_T2[df$whiteCrime_T2 == "1"] <- "6 - Definitely False"
df$whiteCrime_fac_T2[df$whiteCrime_T2 == "2"] <- "5"
df$whiteCrime_fac_T2[df$whiteCrime_T2 == "3"] <- "4"
df$whiteCrime_fac_T2[df$whiteCrime_T2 == "4"] <- "3"
df$whiteCrime_fac_T2[df$whiteCrime_T2 == "5"] <- "2"
df$whiteCrime_fac_T2[df$whiteCrime_T2 == "6"] <- "1"
df$whiteCrime_fac_T2[df$whiteCrime_T2 == "7"] <- "0 - Definitely True"

df$whiteCrime_fac_T2 <- factor(df$whiteCrime_fac_T2,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$lowPaid_fac_T1[df$lowPaid_T1 == "1"] <- "6 - Definitely False"
df$lowPaid_fac_T1[df$lowPaid_T1 == "2"] <- "5"
df$lowPaid_fac_T1[df$lowPaid_T1 == "3"] <- "4"
df$lowPaid_fac_T1[df$lowPaid_T1 == "4"] <- "3"
df$lowPaid_fac_T1[df$lowPaid_T1 == "5"] <- "2"
df$lowPaid_fac_T1[df$lowPaid_T1 == "6"] <- "1"
df$lowPaid_fac_T1[df$lowPaid_T1 == "7"] <- "0 - Definitely True"

df$lowPaid_fac_T1 <- factor(df$lowPaid_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$lowPaid_fac_T2[df$lowPaid_T2 == "1"] <- "6 - Definitely False"
df$lowPaid_fac_T2[df$lowPaid_T2 == "2"] <- "5"
df$lowPaid_fac_T2[df$lowPaid_T2 == "3"] <- "4"
df$lowPaid_fac_T2[df$lowPaid_T2 == "4"] <- "3"
df$lowPaid_fac_T2[df$lowPaid_T2 == "5"] <- "2"
df$lowPaid_fac_T2[df$lowPaid_T2 == "6"] <- "1"
df$lowPaid_fac_T2[df$lowPaid_T2 == "7"] <- "0 - Definitely True"

df$lowPaid_fac_T2 <- factor(df$lowPaid_fac_T2,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))


df$noAsylum_T1 <- df$noAsylum_fac_T1
df$costImmig_T1 <- df$costImmig_fac_T1
df$whiteCrime_T1 <- df$whiteCrime_fac_T1
df$lowPaid_T1 <- df$lowPaid_fac_T1

df$noAsylum_fac_T1 <- NULL
df$costImmig_fac_T1 <- NULL
df$whiteCrime_fac_T1 <- NULL
df$lowPaid_fac_T1 <- NULL

df$noAsylum_T2 <- df$noAsylum_fac_T2
df$costImmig_T2 <- df$costImmig_fac_T2
df$whiteCrime_T2 <- df$whiteCrime_fac_T2
df$lowPaid_T2 <- df$lowPaid_fac_T2

df$noAsylum_fac_T2 <- NULL
df$costImmig_fac_T2 <- NULL
df$whiteCrime_fac_T2 <- NULL
df$lowPaid_fac_T2 <- NULL


df$no5_fac_T1[df$no5_T1 == "1"] <- "6 - Definitely False"
df$no5_fac_T1[df$no5_T1 == "2"] <- "5"
df$no5_fac_T1[df$no5_T1 == "3"] <- "4"
df$no5_fac_T1[df$no5_T1 == "4"] <- "3"
df$no5_fac_T1[df$no5_T1 == "5"] <- "2"
df$no5_fac_T1[df$no5_T1 == "6"] <- "1"
df$no5_fac_T1[df$no5_T1 == "7"] <- "0 - Definitely True"

df$no5_fac_T1 <- factor(df$no5_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$plasticBags_fac_T1[df$plasticBags_T1 == "1"] <- "6 - Definitely False"
df$plasticBags_fac_T1[df$plasticBags_T1 == "2"] <- "5"
df$plasticBags_fac_T1[df$plasticBags_T1 == "3"] <- "4"
df$plasticBags_fac_T1[df$plasticBags_T1 == "4"] <- "3"
df$plasticBags_fac_T1[df$plasticBags_T1 == "5"] <- "2"
df$plasticBags_fac_T1[df$plasticBags_T1 == "6"] <- "1"
df$plasticBags_fac_T1[df$plasticBags_T1 == "7"] <- "0 - Definitely True"

df$plasticBags_fac_T1 <- factor(df$plasticBags_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$fracking_fac_T1[df$fracking_T1 == "1"] <- "6 - Definitely False"
df$fracking_fac_T1[df$fracking_T1 == "2"] <- "5"
df$fracking_fac_T1[df$fracking_T1 == "3"] <- "4"
df$fracking_fac_T1[df$fracking_T1 == "4"] <- "3"
df$fracking_fac_T1[df$fracking_T1 == "5"] <- "2"
df$fracking_fac_T1[df$fracking_T1 == "6"] <- "1"
df$fracking_fac_T1[df$fracking_T1 == "7"] <- "0 - Definitely True"

df$fracking_fac_T1 <- factor(df$fracking_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$recession_fac_T1[df$recession_T1 == "1"] <- "6 - Definitely False"
df$recession_fac_T1[df$recession_T1 == "2"] <- "5"
df$recession_fac_T1[df$recession_T1 == "3"] <- "4"
df$recession_fac_T1[df$recession_T1 == "4"] <- "3"
df$recession_fac_T1[df$recession_T1 == "5"] <- "2"
df$recession_fac_T1[df$recession_T1 == "6"] <- "1"
df$recession_fac_T1[df$recession_T1 == "7"] <- "0 - Definitely True"

df$recession_fac_T1 <- factor(df$recession_fac_T1,
                             levels = c("0 - Definitely True", "1", "2", "3",
                                        "4", "5", "6 - Definitely False"))

df$no5_T1 <- df$no5_fac_T1
df$plasticBags_T1 <- df$plasticBags_fac_T1
df$fracking_T1 <- df$fracking_fac_T1
df$recession_T1 <- df$recession_fac_T1

df$no5_fac_T1 <- NULL
df$plasticBags_fac_T1 <- NULL
df$fracking_fac_T1 <- NULL
df$recession_fac_T1 <- NULL


# Reverse coded, numeric

# df$noAsylum_num_T1 <- as.character(df$noAsylum_T1)
df$noAsylum_num_T1[df$noAsylum_T1 == "6 - Definitely False"] <- 6
df$noAsylum_num_T1[df$noAsylum_T1 == "5"] <- 5
df$noAsylum_num_T1[df$noAsylum_T1 == "4"] <- 4
df$noAsylum_num_T1[df$noAsylum_T1 == "3"] <- 3
df$noAsylum_num_T1[df$noAsylum_T1 == "2"] <- 2
df$noAsylum_num_T1[df$noAsylum_T1 == "1"] <- 1
df$noAsylum_num_T1[df$noAsylum_T1 == "0 - Definitely True"] <- 0

df$costImmig_num_T1[df$costImmig_T1 == "6 - Definitely False"] <- 6
df$costImmig_num_T1[df$costImmig_T1 == "5"] <- 5
df$costImmig_num_T1[df$costImmig_T1 == "4"] <- 4
df$costImmig_num_T1[df$costImmig_T1 == "3"] <- 3
df$costImmig_num_T1[df$costImmig_T1 == "2"] <- 2
df$costImmig_num_T1[df$costImmig_T1 == "1"] <- 1
df$costImmig_num_T1[df$costImmig_T1 == "0 - Definitely True"] <- 0

df$whiteCrime_num_T1[df$whiteCrime_T1 == "6 - Definitely False"] <- 6
df$whiteCrime_num_T1[df$whiteCrime_T1 == "5"] <- 5
df$whiteCrime_num_T1[df$whiteCrime_T1 == "4"] <- 4
df$whiteCrime_num_T1[df$whiteCrime_T1 == "3"] <- 3
df$whiteCrime_num_T1[df$whiteCrime_T1 == "2"] <- 2
df$whiteCrime_num_T1[df$whiteCrime_T1 == "1"] <- 1
df$whiteCrime_num_T1[df$whiteCrime_T1 == "0 - Definitely True"] <- 0

df$lowPaid_num_T1[df$lowPaid_T1 == "6 - Definitely False"] <- 6
df$lowPaid_num_T1[df$lowPaid_T1 == "5"] <- 5
df$lowPaid_num_T1[df$lowPaid_T1 == "4"] <- 4
df$lowPaid_num_T1[df$lowPaid_T1 == "3"] <- 3
df$lowPaid_num_T1[df$lowPaid_T1 == "2"] <- 2
df$lowPaid_num_T1[df$lowPaid_T1 == "1"] <- 1
df$lowPaid_num_T1[df$lowPaid_T1 == "0 - Definitely True"] <- 0

df$no5_num_T1[df$no5_T1 == "6 - Definitely False"] <- 6
df$no5_num_T1[df$no5_T1 == "5"] <- 5
df$no5_num_T1[df$no5_T1 == "4"] <- 4
df$no5_num_T1[df$no5_T1 == "3"] <- 3
df$no5_num_T1[df$no5_T1 == "2"] <- 2
df$no5_num_T1[df$no5_T1 == "1"] <- 1
df$no5_num_T1[df$no5_T1 == "0 - Definitely True"] <- 0

df$plasticBags_num_T1[df$plasticBags_T1 == "6 - Definitely False"] <- 6
df$plasticBags_num_T1[df$plasticBags_T1 == "5"] <- 5
df$plasticBags_num_T1[df$plasticBags_T1 == "4"] <- 4
df$plasticBags_num_T1[df$plasticBags_T1 == "3"] <- 3
df$plasticBags_num_T1[df$plasticBags_T1 == "2"] <- 2
df$plasticBags_num_T1[df$plasticBags_T1 == "1"] <- 1
df$plasticBags_num_T1[df$plasticBags_T1 == "0 - Definitely True"] <- 0

df$fracking_num_T1[df$fracking_T1 == "6 - Definitely False"] <- 6
df$fracking_num_T1[df$fracking_T1 == "5"] <- 5
df$fracking_num_T1[df$fracking_T1 == "4"] <- 4
df$fracking_num_T1[df$fracking_T1 == "3"] <- 3
df$fracking_num_T1[df$fracking_T1 == "2"] <- 2
df$fracking_num_T1[df$fracking_T1 == "1"] <- 1
df$fracking_num_T1[df$fracking_T1 == "0 - Definitely True"] <- 0

df$recession_num_T1[df$recession_T1 == "6 - Definitely False"] <- 6
df$recession_num_T1[df$recession_T1 == "5"] <- 5
df$recession_num_T1[df$recession_T1 == "4"] <- 4
df$recession_num_T1[df$recession_T1 == "3"] <- 3
df$recession_num_T1[df$recession_T1 == "2"] <- 2
df$recession_num_T1[df$recession_T1 == "1"] <- 1
df$recession_num_T1[df$recession_T1 == "0 - Definitely True"] <- 0

df$noAsylum_num_T2[df$noAsylum_T2 == "6 - Definitely False"] <- 6
df$noAsylum_num_T2[df$noAsylum_T2 == "5"] <- 5
df$noAsylum_num_T2[df$noAsylum_T2 == "4"] <- 4
df$noAsylum_num_T2[df$noAsylum_T2 == "3"] <- 3
df$noAsylum_num_T2[df$noAsylum_T2 == "2"] <- 2
df$noAsylum_num_T2[df$noAsylum_T2 == "1"] <- 1
df$noAsylum_num_T2[df$noAsylum_T2 == "0 - Definitely True"] <- 0

df$costImmig_num_T2[df$costImmig_T2 == "6 - Definitely False"] <- 6
df$costImmig_num_T2[df$costImmig_T2 == "5"] <- 5
df$costImmig_num_T2[df$costImmig_T2 == "4"] <- 4
df$costImmig_num_T2[df$costImmig_T2 == "3"] <- 3
df$costImmig_num_T2[df$costImmig_T2 == "2"] <- 2
df$costImmig_num_T2[df$costImmig_T2 == "1"] <- 1
df$costImmig_num_T2[df$costImmig_T2 == "0 - Definitely True"] <- 0

df$whiteCrime_num_T2[df$whiteCrime_T2 == "6 - Definitely False"] <- 6
df$whiteCrime_num_T2[df$whiteCrime_T2 == "5"] <- 5
df$whiteCrime_num_T2[df$whiteCrime_T2 == "4"] <- 4
df$whiteCrime_num_T2[df$whiteCrime_T2 == "3"] <- 3
df$whiteCrime_num_T2[df$whiteCrime_T2 == "2"] <- 2
df$whiteCrime_num_T2[df$whiteCrime_T2 == "1"] <- 1
df$whiteCrime_num_T2[df$whiteCrime_T2 == "0 - Definitely True"] <- 0

df$lowPaid_num_T2[df$lowPaid_T2 == "6 - Definitely False"] <- 6
df$lowPaid_num_T2[df$lowPaid_T2 == "5"] <- 5
df$lowPaid_num_T2[df$lowPaid_T2 == "4"] <- 4
df$lowPaid_num_T2[df$lowPaid_T2 == "3"] <- 3
df$lowPaid_num_T2[df$lowPaid_T2 == "2"] <- 2
df$lowPaid_num_T2[df$lowPaid_T2 == "1"] <- 1
df$lowPaid_num_T2[df$lowPaid_T2 == "0 - Definitely True"] <- 0


#### Managing variables -- DVs -- Post-fact check belief in CORRECTED false claims ####

# The lowPaid_T2 etc variable include values for respondents who received the 
# respective fact check (in this case, lowPaid) as well as for respondents 
# who received the fact check to the other false claim on that side of the  
# debate (in this case, the other pro-immigration claim, i.e. whiteCrime). 

# Creating a new variable that only includes values for those who saw the 
# respective fact check and is coded NA for all others. 

# T1 refers to pre-treatment belief in the corrected statement.
# T2 refers to post-correction belief in the corrected statement. 

df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "1"] <- "1"
df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "2"] <- "2"
df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "3"] <- "3"
df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "4"] <- "4"
df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "5"] <- "5"
df$belief_noAsylum_T1[df$whichFactCheck == "noAsylum" & df$noAsylum_T1 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_noAsylum_T1 <- factor(df$belief_noAsylum_T1,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "1"] <- "1"
df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "2"] <- "2"
df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "3"] <- "3"
df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "4"] <- "4"
df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "5"] <- "5"
df$belief_noAsylum_T2[df$whichFactCheck == "noAsylum" & df$noAsylum_T2 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_noAsylum_T2 <- factor(df$belief_noAsylum_T2,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "1"] <- "1"
df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "2"] <- "2"
df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "3"] <- "3"
df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "4"] <- "4"
df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "5"] <- "5"
df$belief_costImmig_T1[df$whichFactCheck == "costImmig" & df$costImmig_T1 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_costImmig_T1 <- factor(df$belief_costImmig_T1,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "1"] <- "1"
df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "2"] <- "2"
df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "3"] <- "3"
df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "4"] <- "4"
df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "5"] <- "5"
df$belief_costImmig_T2[df$whichFactCheck == "costImmig" & df$costImmig_T2 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_costImmig_T2 <- factor(df$belief_costImmig_T2,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "1"] <- "1"
df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "2"] <- "2"
df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "3"] <- "3"
df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "4"] <- "4"
df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "5"] <- "5"
df$belief_whiteCrime_T1[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T1 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_whiteCrime_T1 <- factor(df$belief_whiteCrime_T1,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "1"] <- "1"
df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "2"] <- "2"
df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "3"] <- "3"
df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "4"] <- "4"
df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "5"] <- "5"
df$belief_whiteCrime_T2[df$whichFactCheck == "whiteCrime" & df$whiteCrime_T2 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_whiteCrime_T2 <- factor(df$belief_whiteCrime_T2,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "1"] <- "1"
df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "2"] <- "2"
df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "3"] <- "3"
df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "4"] <- "4"
df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "5"] <- "5"
df$belief_lowPaid_T1[df$whichFactCheck == "lowPaid" & df$lowPaid_T1 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_lowPaid_T1 <- factor(df$belief_lowPaid_T1,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "0 - Definitely True"] <- "0 - Definitely True"
df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "1"] <- "1"
df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "2"] <- "2"
df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "3"] <- "3"
df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "4"] <- "4"
df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "5"] <- "5"
df$belief_lowPaid_T2[df$whichFactCheck == "lowPaid" & df$lowPaid_T2 == "6 - Definitely False"] <- "6 - Definitely False"

df$belief_lowPaid_T2 <- factor(df$belief_lowPaid_T2,
                                levels = c("0 - Definitely True", "1", "2", "3", "4", "5", "6 - Definitely False"))

# numeric

df$belief_noAsylum_num_T1 <- NA
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "6 - Definitely False"] <- 6
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "5"] <- 5
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "4"] <- 4
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "3"] <- 3
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "2"] <- 2
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "1"] <- 1
df$belief_noAsylum_num_T1[df$belief_noAsylum_T1 == "0 - Definitely True"] <- 0

df$belief_costImmig_num_T1 <- NA
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "6 - Definitely False"] <- 6
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "5"] <- 5
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "4"] <- 4
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "3"] <- 3
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "2"] <- 2
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "1"] <- 1
df$belief_costImmig_num_T1[df$belief_costImmig_T1 == "0 - Definitely True"] <- 0

df$belief_whiteCrime_num_T1 <- NA
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "6 - Definitely False"] <- 6
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "5"] <- 5
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "4"] <- 4
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "3"] <- 3
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "2"] <- 2
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "1"] <- 1
df$belief_whiteCrime_num_T1[df$belief_whiteCrime_T1 == "0 - Definitely True"] <- 0

df$belief_lowPaid_num_T1 <- NA
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "6 - Definitely False"] <- 6
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "5"] <- 5
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "4"] <- 4
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "3"] <- 3
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "2"] <- 2
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "1"] <- 1
df$belief_lowPaid_num_T1[df$belief_lowPaid_T1 == "0 - Definitely True"] <- 0


df$belief_noAsylum_num_T2 <- NA
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "6 - Definitely False"] <- 6
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "5"] <- 5
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "4"] <- 4
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "3"] <- 3
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "2"] <- 2
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "1"] <- 1
df$belief_noAsylum_num_T2[df$belief_noAsylum_T2 == "0 - Definitely True"] <- 0

df$belief_costImmig_num_T2 <- NA
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "6 - Definitely False"] <- 6
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "5"] <- 5
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "4"] <- 4
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "3"] <- 3
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "2"] <- 2
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "1"] <- 1
df$belief_costImmig_num_T2[df$belief_costImmig_T2 == "0 - Definitely True"] <- 0

df$belief_whiteCrime_num_T2 <- NA
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "6 - Definitely False"] <- 6
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "5"] <- 5
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "4"] <- 4
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "3"] <- 3
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "2"] <- 2
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "1"] <- 1
df$belief_whiteCrime_num_T2[df$belief_whiteCrime_T2 == "0 - Definitely True"] <- 0

df$belief_lowPaid_num_T2 <- NA
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "6 - Definitely False"] <- 6
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "5"] <- 5
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "4"] <- 4
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "3"] <- 3
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "2"] <- 2
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "1"] <- 1
df$belief_lowPaid_num_T2[df$belief_lowPaid_T2 == "0 - Definitely True"] <- 0

df <-
df %>%
  dplyr::mutate(belief_T1 = case_when(whichFactCheck == "noAsylum" ~ belief_noAsylum_T1,
                               whichFactCheck == "costImmig" ~ belief_costImmig_T1,
                               whichFactCheck == "whiteCrime" ~ belief_whiteCrime_T1,
                               whichFactCheck == "lowPaid" ~ belief_lowPaid_T1))

df <-
df %>%
  dplyr::mutate(belief_T2 = case_when(whichFactCheck == "noAsylum" ~ belief_noAsylum_T2,
                               whichFactCheck == "costImmig" ~ belief_costImmig_T2,
                               whichFactCheck == "whiteCrime" ~ belief_whiteCrime_T2,
                               whichFactCheck == "lowPaid" ~ belief_lowPaid_T2))

df$belief_num_T1 <- NA
df$belief_num_T1[df$belief_T1 == "6 - Definitely False"] <- 6
df$belief_num_T1[df$belief_T1 == "5"] <- 5
df$belief_num_T1[df$belief_T1 == "4"] <- 4
df$belief_num_T1[df$belief_T1 == "3"] <- 3
df$belief_num_T1[df$belief_T1 == "2"] <- 2
df$belief_num_T1[df$belief_T1 == "1"] <- 1
df$belief_num_T1[df$belief_T1 == "0 - Definitely True"] <- 0

df$belief_num_T2 <- NA
df$belief_num_T2[df$belief_T2 == "6 - Definitely False"] <- 6
df$belief_num_T2[df$belief_T2 == "5"] <- 5
df$belief_num_T2[df$belief_T2 == "4"] <- 4
df$belief_num_T2[df$belief_T2 == "3"] <- 3
df$belief_num_T2[df$belief_T2 == "2"] <- 2
df$belief_num_T2[df$belief_T2 == "1"] <- 1
df$belief_num_T2[df$belief_T2 == "0 - Definitely True"] <- 0

#### Managing variables -- DVs -- Belief in the uncorrected false claims ####

# Pre-correction veracity score (claim that is NOT to be corrected)

df <-
  df %>%
  dplyr::mutate(belief_i2_T1 = case_when(whichFactCheck == "costImmig" ~ noAsylum_T1,
                               whichFactCheck == "noAsylum" ~ costImmig_T1,
                               whichFactCheck == "lowPaid" ~ whiteCrime_T1,
                               whichFactCheck == "whiteCrime" ~ lowPaid_T1))


# Post-correction veracity (claim that was NOT corrected)

df <-
  df %>%
  dplyr::mutate(belief_i2_T2 = case_when(whichFactCheck == "costImmig" ~ noAsylum_T2,
                                  whichFactCheck == "noAsylum" ~ costImmig_T2,
                                  whichFactCheck == "lowPaid" ~ whiteCrime_T2,
                                  whichFactCheck == "whiteCrime" ~ lowPaid_T2))



df$belief_i2_num_T1 <- NA
df$belief_i2_num_T1[df$belief_i2_T1 == "6 - Definitely False"] <- 6
df$belief_i2_num_T1[df$belief_i2_T1 == "5"] <- 5
df$belief_i2_num_T1[df$belief_i2_T1 == "4"] <- 4
df$belief_i2_num_T1[df$belief_i2_T1 == "3"] <- 3
df$belief_i2_num_T1[df$belief_i2_T1 == "2"] <- 2
df$belief_i2_num_T1[df$belief_i2_T1 == "1"] <- 1
df$belief_i2_num_T1[df$belief_i2_T1 == "0 - Definitely True"] <- 0


df$belief_i2_num_T2 <- NA
df$belief_i2_num_T2[df$belief_i2_T2 == "6 - Definitely False"] <- 6
df$belief_i2_num_T2[df$belief_i2_T2 == "5"] <- 5
df$belief_i2_num_T2[df$belief_i2_T2 == "4"] <- 4
df$belief_i2_num_T2[df$belief_i2_T2 == "3"] <- 3
df$belief_i2_num_T2[df$belief_i2_T2 == "2"] <- 2
df$belief_i2_num_T2[df$belief_i2_T2 == "1"] <- 1
df$belief_i2_num_T2[df$belief_i2_T2 == "0 - Definitely True"] <- 0

# Creating a dummy variable to indicate if people got their facts wrong 
# before they saw the statistics

df$wrong_T1 <- ifelse(df$belief_num_T1 < 3, 1, 0)
df$wrong_T2 <- ifelse(df$belief_num_T2 < 3, 1, 0)

df$wrong_i2_T1 <- ifelse(df$belief_i2_num_T1 < 3, 1, 0)
df$wrong_i2_T2 <- ifelse(df$belief_i2_num_T2 < 3, 1, 0)

df$bothWrong_T1 <- 0
df$bothWrong_T1[df$belief_num_T1 < 3 & df$belief_i2_num_T1 < 3] <- 1

df$bothWrong_T2 <- 0
df$bothWrong_T2[df$belief_num_T2 < 3 & df$belief_i2_num_T2 < 3] <- 1


#### Managing variables -- DVs --Difference between pre- and post-correction veracity scores ####

df$noAsylum_diff <- df$belief_noAsylum_num_T2 - df$belief_noAsylum_num_T1
df$costImmig_diff <- df$belief_costImmig_num_T2 - df$belief_costImmig_num_T1
df$whiteCrime_diff <- df$belief_whiteCrime_num_T2 - df$belief_whiteCrime_num_T1
df$lowPaid_diff <- df$belief_lowPaid_num_T2 - df$belief_lowPaid_num_T1

df$diff <- df$belief_num_T2 - df$belief_num_T1 # 0 = true, 6=false. Higher diff = more convinced. Most convinced: 0 at T1, 6 at T2, diff=6-0. Least convinced: 0-0
df$diff_i2 <- df$belief_i2_num_T2 - df$belief_i2_num_T1


#### Managing variables -- DVs -- Fact/Opinion #### 

df$noAsylum_opinion_num <- as.numeric(as.character(df$noAsylum_opinion))

df$noAsylum_opinion <- as.character(df$noAsylum_opinion_num)

df$noAsylum_opinion[df$noAsylum_opinion_num == 1] <- "0 - Purely a matter of fact"
df$noAsylum_opinion[df$noAsylum_opinion_num == 2] <- "1"
df$noAsylum_opinion[df$noAsylum_opinion_num == 3] <- "2"
df$noAsylum_opinion[df$noAsylum_opinion_num == 4] <- "3"
df$noAsylum_opinion[df$noAsylum_opinion_num == 5] <- "4"
df$noAsylum_opinion[df$noAsylum_opinion_num == 6] <- "5"
df$noAsylum_opinion[df$noAsylum_opinion_num == 7] <- "6 - Purely a matter of opinion"

df$noAsylum_opinion <- factor(df$noAsylum_opinion,
                         levels = c("0 - Purely a matter of fact", "1", "2", "3",
                                    "4", "5", "6 - Purely a matter of opinion"))

df$noAsylum_opinion_num[df$noAsylum_opinion == "0 - Purely a matter of fact"] <- 0
df$noAsylum_opinion_num[df$noAsylum_opinion == "1"] <- 1
df$noAsylum_opinion_num[df$noAsylum_opinion == "2"] <- 2
df$noAsylum_opinion_num[df$noAsylum_opinion == "3"] <- 3
df$noAsylum_opinion_num[df$noAsylum_opinion == "4"] <- 4
df$noAsylum_opinion_num[df$noAsylum_opinion == "5"] <- 5
df$noAsylum_opinion_num[df$noAsylum_opinion == "6 - Purely a matter of opinion"] <- 6


df$costImmig_opinion_num <- as.numeric(as.character(df$costImmig_opinion))

df$costImmig_opinion <- as.character(df$costImmig_opinion_num)

df$costImmig_opinion[df$costImmig_opinion_num == 1] <- "0 - Purely a matter of fact"
df$costImmig_opinion[df$costImmig_opinion_num == 2] <- "1"
df$costImmig_opinion[df$costImmig_opinion_num == 3] <- "2"
df$costImmig_opinion[df$costImmig_opinion_num == 4] <- "3"
df$costImmig_opinion[df$costImmig_opinion_num == 5] <- "4"
df$costImmig_opinion[df$costImmig_opinion_num == 6] <- "5"
df$costImmig_opinion[df$costImmig_opinion_num == 7] <- "6 - Purely a matter of opinion"

df$costImmig_opinion <- factor(df$costImmig_opinion,
                              levels = c("0 - Purely a matter of fact", "1", "2", "3",
                                         "4", "5", "6 - Purely a matter of opinion"))

df$costImmig_opinion_num[df$costImmig_opinion == "0 - Purely a matter of fact"] <- 0
df$costImmig_opinion_num[df$costImmig_opinion == "1"] <- 1
df$costImmig_opinion_num[df$costImmig_opinion == "2"] <- 2
df$costImmig_opinion_num[df$costImmig_opinion == "3"] <- 3
df$costImmig_opinion_num[df$costImmig_opinion == "4"] <- 4
df$costImmig_opinion_num[df$costImmig_opinion == "5"] <- 5
df$costImmig_opinion_num[df$costImmig_opinion == "6 - Purely a matter of opinion"] <- 6


df$whiteCrime_opinion_num <- as.numeric(as.character(df$whiteCrime_opinion))

df$whiteCrime_opinion <- as.character(df$whiteCrime_opinion_num)

df$whiteCrime_opinion[df$whiteCrime_opinion_num == 1] <- "0 - Purely a matter of fact"
df$whiteCrime_opinion[df$whiteCrime_opinion_num == 2] <- "1"
df$whiteCrime_opinion[df$whiteCrime_opinion_num == 3] <- "2"
df$whiteCrime_opinion[df$whiteCrime_opinion_num == 4] <- "3"
df$whiteCrime_opinion[df$whiteCrime_opinion_num == 5] <- "4"
df$whiteCrime_opinion[df$whiteCrime_opinion_num == 6] <- "5"
df$whiteCrime_opinion[df$whiteCrime_opinion_num == 7] <- "6 - Purely a matter of opinion"

df$whiteCrime_opinion <- factor(df$whiteCrime_opinion,
                              levels = c("0 - Purely a matter of fact", "1", "2", "3",
                                         "4", "5", "6 - Purely a matter of opinion"))

df$whiteCrime_opinion_num[df$whiteCrime_opinion == "0 - Purely a matter of fact"] <- 0
df$whiteCrime_opinion_num[df$whiteCrime_opinion == "1"] <- 1
df$whiteCrime_opinion_num[df$whiteCrime_opinion == "2"] <- 2
df$whiteCrime_opinion_num[df$whiteCrime_opinion == "3"] <- 3
df$whiteCrime_opinion_num[df$whiteCrime_opinion == "4"] <- 4
df$whiteCrime_opinion_num[df$whiteCrime_opinion == "5"] <- 5
df$whiteCrime_opinion_num[df$whiteCrime_opinion == "6 - Purely a matter of opinion"] <- 6



df$lowPaid_opinion_num <- as.numeric(as.character(df$lowPaid_opinion))

df$lowPaid_opinion <- as.character(df$lowPaid_opinion_num)

df$lowPaid_opinion[df$lowPaid_opinion_num == 1] <- "0 - Purely a matter of fact"
df$lowPaid_opinion[df$lowPaid_opinion_num == 2] <- "1"
df$lowPaid_opinion[df$lowPaid_opinion_num == 3] <- "2"
df$lowPaid_opinion[df$lowPaid_opinion_num == 4] <- "3"
df$lowPaid_opinion[df$lowPaid_opinion_num == 5] <- "4"
df$lowPaid_opinion[df$lowPaid_opinion_num == 6] <- "5"
df$lowPaid_opinion[df$lowPaid_opinion_num == 7] <- "6 - Purely a matter of opinion"

df$lowPaid_opinion <- factor(df$lowPaid_opinion,
                              levels = c("0 - Purely a matter of fact", "1", "2", "3",
                                         "4", "5", "6 - Purely a matter of opinion"))

df$lowPaid_opinion_num[df$lowPaid_opinion == "0 - Purely a matter of fact"] <- 0
df$lowPaid_opinion_num[df$lowPaid_opinion == "1"] <- 1
df$lowPaid_opinion_num[df$lowPaid_opinion == "2"] <- 2
df$lowPaid_opinion_num[df$lowPaid_opinion == "3"] <- 3
df$lowPaid_opinion_num[df$lowPaid_opinion == "4"] <- 4
df$lowPaid_opinion_num[df$lowPaid_opinion == "5"] <- 5
df$lowPaid_opinion_num[df$lowPaid_opinion == "6 - Purely a matter of opinion"] <- 6

df <-
  df %>%
  dplyr::mutate(accuratePostTruthComment = case_when(source == "Professor" ~ accuratePostTruthProf,
                                              source == "Blogger" ~ accuratePostTruthBlogger))


df <-
  df %>%
  dplyr::mutate(factOpinion = case_when(whichFactCheck == "noAsylum" ~ noAsylum_opinion,
                                 whichFactCheck == "costImmig" ~ costImmig_opinion,
                                 whichFactCheck == "whiteCrime" ~ whiteCrime_opinion,
                                 whichFactCheck == "lowPaid" ~ lowPaid_opinion,
                                 ))

df <-
  df %>%
  dplyr::mutate(factOpinion_i2 = case_when(whichFactCheck == "costImmig" ~ noAsylum_opinion,
                                 whichFactCheck == "noAsylum" ~ costImmig_opinion,
                                 whichFactCheck == "lowPaid" ~ whiteCrime_opinion,
                                 whichFactCheck == "whiteCrime" ~ lowPaid_opinion,
  ))

df$factOpinion_num <- NA
df$factOpinion_num[df$factOpinion == "0 - Purely a matter of fact"] <- 0
df$factOpinion_num[df$factOpinion == "1"] <- 1
df$factOpinion_num[df$factOpinion == "2"] <- 2
df$factOpinion_num[df$factOpinion == "3"] <- 3
df$factOpinion_num[df$factOpinion == "4"] <- 4
df$factOpinion_num[df$factOpinion == "5"] <- 5
df$factOpinion_num[df$factOpinion == "6 - Purely a matter of opinion"] <- 6

df$factOpinion_i2_num <- NA
df$factOpinion_i2_num[df$factOpinion_i2 == "0 - Purely a matter of fact"] <- 0
df$factOpinion_i2_num[df$factOpinion_i2 == "1"] <- 1
df$factOpinion_i2_num[df$factOpinion_i2 == "2"] <- 2
df$factOpinion_i2_num[df$factOpinion_i2 == "3"] <- 3
df$factOpinion_i2_num[df$factOpinion_i2 == "4"] <- 4
df$factOpinion_i2_num[df$factOpinion_i2 == "5"] <- 5
df$factOpinion_i2_num[df$factOpinion_i2 == "6 - Purely a matter of opinion"] <- 6

df$fact_check_noAsylum <- ifelse(df$whichFactCheck == "noAsylum", 1, 0)
df$fact_check_costImmig <- ifelse(df$whichFactCheck == "costImmig", 1, 0)
df$fact_check_whiteCrime <- ifelse(df$whichFactCheck == "whiteCrime", 1, 0)
df$fact_check_lowPaid <- ifelse(df$whichFactCheck == "lowPaid", 1, 0)


#### Managing variables -- DVs -- consistent #### 

df$consistent <- as.character(df$consistent)

df$consistent[df$consistent == 1] <- "Yes"
df$consistent[df$consistent == 2] <- "No"

df$consistent <- factor(df$consistent,
                         levels = c("Yes", "No"))

# if inconsistent

df$ifInconsistent <- as.character(df$ifInconsistent)

df$ifInconsistent[df$ifInconsistent == 1] <- "The statistics are probably right but I believe something different."
df$ifInconsistent[df$ifInconsistent == 2] <- "I think that the statistics are wrong."
df$ifInconsistent[df$ifInconsistent == 3] <- "The statistics made me change my mind."

df$ifInconsistent <- factor(df$ifInconsistent,
                            levels = c("The statistics are probably right but I believe something different.", 
                                       "I think that the statistics are wrong.",
                                       "The statistics made me change my mind."))


#### Managing variables -- DVs -- OK to disagree #### 

df$ok2disagree_old <- as.numeric(as.character(df$ok2disagree))

df$ok2disagree <- as.character(df$ok2disagree_old)

df$ok2disagree[df$ok2disagree == 1] <- "Strongly agree"
df$ok2disagree[df$ok2disagree == 2] <- "Agree"
df$ok2disagree[df$ok2disagree == 3] <- "Disagree"
df$ok2disagree[df$ok2disagree == 4] <- "Strongly disagree"

df$ok2disagree <- factor(df$ok2disagree,
                         levels = c("Strongly disagree",
                                    "Disagree", 
                                    "Agree",
                                    "Strongly agree"))
# New variable with reverse numbers
df$ok2disagree_num <- NA
df$ok2disagree_num[df$ok2disagree == "Strongly disagree"] <- 1
df$ok2disagree_num[df$ok2disagree == "Disagree"] <- 2
df$ok2disagree_num[df$ok2disagree == "Agree"] <- 3
df$ok2disagree_num[df$ok2disagree == "Strongly agree"] <- 4

# Dummy
df$ok2disagree_d <- NA
df$ok2disagree_d[df$ok2disagree == "Strongly disagree"] <- "Disagree"
df$ok2disagree_d[df$ok2disagree == "Disagree"] <- "Disagree"
df$ok2disagree_d[df$ok2disagree == "Strongly agree"] <- "Agree"
df$ok2disagree_d[df$ok2disagree == "Agree"] <- "Agree"

df$ok2disagree_d <- factor(df$ok2disagree_d,
                           levels = c("Disagree", "Agree"))


#### Managing variables -- DVs -- Perceived accuracy ####

# How people rate the expert 

# NB: The original variable is coded such that 1=very and 4=not at all accurate

df$accurateExpert <- as.character(df$accurateExpert)

df$accurateExpert[df$accurateExpert == "1"] <- "Very accurate"
df$accurateExpert[df$accurateExpert == "2"] <- "Fairly accurate"
df$accurateExpert[df$accurateExpert == "3"] <- "Not very accurate"
df$accurateExpert[df$accurateExpert == "4"] <- "Not at all accurate"
df$accurateExpert[df$accurateExpert == "98"] <- NA


df$accurateExpert <- factor(df$accurateExpert,
                            levels = c("Not at all accurate",
                                       "Not very accurate",
                                       "Fairly accurate",
                                       "Very accurate"))

df$accurateExpert_num[df$accurateExpert == "Very accurate"] <- 4
df$accurateExpert_num[df$accurateExpert == "Fairly accurate"] <- 3
df$accurateExpert_num[df$accurateExpert == "Not very accurate"] <- 2
df$accurateExpert_num[df$accurateExpert == "Not at all accurate"] <- 1


# How people rate the post-truth commentator 

df$accuratePostTruthBlogger <- as.character(df$accuratePostTruthBlogger)

df$accuratePostTruthBlogger[df$accuratePostTruthBlogger == "1"] <- "Very accurate"
df$accuratePostTruthBlogger[df$accuratePostTruthBlogger == "2"] <- "Fairly accurate"
df$accuratePostTruthBlogger[df$accuratePostTruthBlogger == "3"] <- "Not very accurate"
df$accuratePostTruthBlogger[df$accuratePostTruthBlogger == "4"] <- "Not at all accurate"

df$accuratePostTruthBlogger <- factor(df$accuratePostTruthBlogger,
                                      levels = c("Not at all accurate",
                                                 "Not very accurate",
                                                 "Fairly accurate",
                                                 "Very accurate"))

df$accuratePostTruthBlogger_num[df$accuratePostTruthBlogger == "Very accurate"] <- 4
df$accuratePostTruthBlogger_num[df$accuratePostTruthBlogger == "Fairly accurate"] <- 3
df$accuratePostTruthBlogger_num[df$accuratePostTruthBlogger == "Not very accurate"] <- 2
df$accuratePostTruthBlogger_num[df$accuratePostTruthBlogger == "Not at all accurate"] <- 1



df$accuratePostTruthProf <- as.character(df$accuratePostTruthProf)

df$accuratePostTruthProf[df$accuratePostTruthProf == "1"] <- "Very accurate"
df$accuratePostTruthProf[df$accuratePostTruthProf == "2"] <- "Fairly accurate"
df$accuratePostTruthProf[df$accuratePostTruthProf == "3"] <- "Not very accurate"
df$accuratePostTruthProf[df$accuratePostTruthProf == "4"] <- "Not at all accurate"

df$accuratePostTruthProf <- factor(df$accuratePostTruthProf,
                                   levels = c("Not at all accurate",
                                              "Not very accurate",
                                              "Fairly accurate",
                                              "Very accurate"))

df$accuratePostTruthProf_num[df$accuratePostTruthProf == "Very accurate"] <- 4
df$accuratePostTruthProf_num[df$accuratePostTruthProf == "Fairly accurate"] <- 3
df$accuratePostTruthProf_num[df$accuratePostTruthProf == "Not very accurate"] <- 2
df$accuratePostTruthProf_num[df$accuratePostTruthProf == "Not at all accurate"] <- 1

#### Managing variables -- DVs -- Trust ####

# How people rate the expert

# NB: The original variable was coded such that 1 = 6 - Would trust a great deal
# and 7 =  0 - Would not trust at all

df$trustExpert_num <- as.numeric(as.character(df$trustExpert))
df$trustExpert_num[df$trustExpert_num == 98] <- NA


df$trustExpert <- as.character(df$trustExpert_num)

df$trustExpert[df$trustExpert_num == 1] <- "6 - Would trust a great deal"
df$trustExpert[df$trustExpert_num == 2] <- "5"
df$trustExpert[df$trustExpert_num == 3] <- "4"
df$trustExpert[df$trustExpert_num == 4] <- "3"
df$trustExpert[df$trustExpert_num == 5] <- "2"
df$trustExpert[df$trustExpert_num == 6] <- "1"
df$trustExpert[df$trustExpert_num == 7] <- "0 - Would not trust at all"

df$trustExpert <- factor(df$trustExpert, 
                         levels = c("0 - Would not trust at all",
                                    "1", "2", "3", "4", "5",
                                    "6 - Would trust a great deal"))

df$trustExpert_num[df$trustExpert == "6 - Would trust a great deal"] <- 6
df$trustExpert_num[df$trustExpert == "5"] <- 5
df$trustExpert_num[df$trustExpert == "4"] <- 4
df$trustExpert_num[df$trustExpert == "3"] <- 3
df$trustExpert_num[df$trustExpert == "2"] <- 2
df$trustExpert_num[df$trustExpert == "1"] <- 1
df$trustExpert_num[df$trustExpert == "0 - Would not trust at all"] <- 0

# How people rate the post-truth professor 

df$trustPostTruthProf_num <- as.numeric(as.character(df$trustPostTruthProf))
df$trustPostTruthProf_num[df$trustPostTruthProf_num == 98] <- NA

df$trustPostTruthProf <- as.character(df$trustPostTruthProf_num)

df$trustPostTruthProf[df$trustPostTruthProf_num == 1] <- "6 - Would trust a great deal"
df$trustPostTruthProf[df$trustPostTruthProf_num == 2] <- "5"
df$trustPostTruthProf[df$trustPostTruthProf_num == 3] <- "4"
df$trustPostTruthProf[df$trustPostTruthProf_num == 4] <- "3"
df$trustPostTruthProf[df$trustPostTruthProf_num == 5] <- "2"
df$trustPostTruthProf[df$trustPostTruthProf_num == 6] <- "1"
df$trustPostTruthProf[df$trustPostTruthProf_num == 7] <- "0 - Would not trust at all"

df$trustPostTruthProf <- factor(df$trustPostTruthProf,
                                levels = c("0 - Would not trust at all", 
                                           "1", "2", "3", "4", "5",
                                           "6 - Would trust a great deal"))

df$trustPostTruthProf_num[df$trustPostTruthProf == "6 - Would trust a great deal"] <- 6
df$trustPostTruthProf_num[df$trustPostTruthProf == "5"] <- 5
df$trustPostTruthProf_num[df$trustPostTruthProf == "4"] <- 4
df$trustPostTruthProf_num[df$trustPostTruthProf == "3"] <- 3
df$trustPostTruthProf_num[df$trustPostTruthProf == "2"] <- 2
df$trustPostTruthProf_num[df$trustPostTruthProf == "1"] <- 1
df$trustPostTruthProf_num[df$trustPostTruthProf == "0 - Would not trust at all"] <- 0

# How people rate the post-truth blogger 

df$trustPostTruthBlogger_num <- as.numeric(as.character(df$trustPostTruthBlogger))
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger_num == 98] <- NA

df$trustPostTruthBlogger <- as.character(df$trustPostTruthBlogger_num)

df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 1] <- "6 - Would trust a great deal"
df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 2] <- "5"
df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 3] <- "4"
df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 4] <- "3"
df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 5] <- "2"
df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 6] <- "1"
df$trustPostTruthBlogger[df$trustPostTruthBlogger_num == 7] <- "0 - Would not trust at all"

df$trustPostTruthBlogger <- factor(df$trustPostTruthBlogger,
                                   levels = c("0 - Would not trust at all", 
                                              "1", "2", "3", "4", "5",
                                              "6 - Would trust a great deal"))

df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "6 - Would trust a great deal"] <- 6
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "5"] <- 5
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "4"] <- 4
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "3"] <- 3
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "2"] <- 2
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "1"] <- 1
df$trustPostTruthBlogger_num[df$trustPostTruthBlogger == "0 - Would not trust at all"] <- 0



df <-
  df %>%
  dplyr::mutate(accuratePostTruthComment = case_when(source == "Professor" ~ df$accuratePostTruthProf,
                                              source == "Blogger" ~ df$accuratePostTruthBlogger))

df <-
  df %>%
  dplyr::mutate(accuratePostTruthComment_num = case_when(source == "Professor" ~ df$accuratePostTruthProf_num,
                                                  source == "Blogger" ~ df$accuratePostTruthBlogger_num))


df <-
  df %>%
  dplyr::mutate(trustPostTruthComment = case_when(source == "Professor" ~ df$trustPostTruthProf,
                                           source == "Blogger" ~ df$trustPostTruthBlogger))


df <-
  df %>%
  dplyr::mutate(trustPostTruthComment_num = case_when(source == "Professor" ~ df$trustPostTruthProf_num,
                                               source == "Blogger" ~ df$trustPostTruthBlogger_num))



#### Managing variables -- Demographics #### 

df$gender <- as.character(df$gender)

df$gender[df$gender == 1] <- "Male"
df$gender[df$gender == 2] <- "Female"

df$gender <- factor(df$gender, levels = c("Male", "Female"))


# Location 

df$regions <- as.character(df$regions)
df$regions[df$regions == 2] <- "Scotland"
df$regions[df$regions == 3] <- "North West"
df$regions[df$regions == 4] <- "North East"
df$regions[df$regions == 5] <- "Yorkshire and The Humber"
df$regions[df$regions == 6] <- "Wales"
df$regions[df$regions == 7] <- "West Midlands"
df$regions[df$regions == 8] <- "East Midlands"
df$regions[df$regions == 9] <- "South West"
df$regions[df$regions == 10] <- "South East"
df$regions[df$regions == 11] <- "Eastern"
df$regions[df$regions == 12] <- "London"

df$regions <- factor(df$regions, levels = c("London", 
                                            "Eastern", 
                                            "South East",
                                            "South West",
                                            "East Midlands",
                                            "West Midlands",
                                            "Wales",
                                            "Yorkshire and The Humber",
                                            "North East",
                                            "North West",
                                            "Scotland"))


df$region <- as.character(df$region)
df$region[df$region == 1] <- "North"
df$region[df$region == 2] <- "Midlands"
df$region[df$region == 3] <- "London"
df$region[df$region == 4] <- "South"
df$region[df$region == 5] <- "Wales"
df$region[df$region == 6] <- "Scotland"

df$region <- factor(df$region,
                    levels = c("South",
                               "North",
                               "London",
                               "Midlands",
                               "Scotland", 
                               "Wales"))

# Age

df$age <- as.numeric(df$age)

df$ageCategory <- as.character(df$ageCategory)
df$ageCategory[df$ageCategory == 1] <- "18-24"
df$ageCategory[df$ageCategory == 2] <- "25-49"
df$ageCategory[df$ageCategory == 3] <- "50-64"
df$ageCategory[df$ageCategory == 4] <- "65+"

df$ageCategory <- factor(df$ageCategory,
                         levels = c("25-49", "18-24", "50-64", "65+"))

# df$ageCategory <- factor(df$ageCategory,
#                          levels = c("18-24", "25-49", "50-64", "65+"))

df$generation[df$age < 23] <- "Gen Z (1997-2012)"
df$generation[df$age >= 23] <- "Millenials (1981-96)"
df$generation[df$age >= 39] <- "Gen X (1965-80)"
df$generation[df$age >= 54] <- "Baby boomers (1946-64)"
df$generation[df$age >= 74] <- "Silent generation (1928-45)"

df$generation <- factor(df$generation, levels = c("Gen Z (1997-2012)", 
                                                  "Millenials (1981-96)",
                                                  "Gen X (1965-80)",
                                                  "Baby boomers (1946-64)",
                                                  "Silent generation (1928-45)"))

# Changing the reference category to Millenials (because most respondents were millenials)
df$generation2 <- df$generation
df$generation2 <- factor(df$generation2, levels = c("Millenials (1981-96)",
                                                  "Gen Z (1997-2012)", 
                                                  "Gen X (1965-80)",
                                                  "Baby boomers (1946-64)",
                                                  "Silent generation (1928-45)"))


# household income

df$householdIncome <- as.character(as.numeric(df$householdIncome))

df$householdIncome[df$householdIncome == "14"] <- "Prefer not to answer"
df$householdIncome[df$householdIncome == "13"] <- "83,001 or more"
df$householdIncome[df$householdIncome == "12"] <- "76,001 - 83,000"
df$householdIncome[df$householdIncome == "11"] <- "69,001 - 76,000"
df$householdIncome[df$householdIncome == "10"] <- "62,001 - 69,000"
df$householdIncome[df$householdIncome == "9"] <- "55,001 - 62,000"
df$householdIncome[df$householdIncome == "8"] <- "48,001 - 55,000"
df$householdIncome[df$householdIncome == "7"] <- "41,001 - 48,000"
df$householdIncome[df$householdIncome == "6"] <- "34,001 - 41,000"
df$householdIncome[df$householdIncome == "5"] <- "28,001 - 34,000"
df$householdIncome[df$householdIncome == "4"] <- "21,001 - 28,000"
df$householdIncome[df$householdIncome == "3"] <- "14,001 - 21,000"
df$householdIncome[df$householdIncome == "2"] <- "7,001 - 14,000"
df$householdIncome[df$householdIncome == "1"] <- "Up to 7,000"

df$householdIncome <- factor(df$householdIncome,
                             levels = c("Up to 7,000",
                                        "7,001 - 14,000", 
                                        "14,001 - 21,000", 
                                        "21,001 - 28,000",
                                        "28,001 - 34,000",
                                        "34,001 - 41,000",
                                        "41,001 - 48,000",
                                        "48,001 - 55,000",
                                        "55,001 - 62,000",
                                        "62,001 - 69,000",
                                        "69,001 - 76,000",
                                        "76,001 - 83,000",
                                        "83,001 or more",
                                        "Prefer not to answer"
                             ))

df$householdIncome_num[df$householdIncome == "83,001 or more"] <- 13
df$householdIncome_num[df$householdIncome == "76,001 - 83,000"] <- 12
df$householdIncome_num[df$householdIncome == "69,001 - 76,000"] <- 11
df$householdIncome_num[df$householdIncome == "62,001 - 69,000"] <- 10
df$householdIncome_num[df$householdIncome == "55,001 - 62,000"] <- 9
df$householdIncome_num[df$householdIncome == "48,001 - 55,000"] <- 8
df$householdIncome_num[df$householdIncome == "41,001 - 48,000"] <- 7
df$householdIncome_num[df$householdIncome == "34,001 - 41,000"] <- 6
df$householdIncome_num[df$householdIncome == "28,001 - 34,000"] <- 5
df$householdIncome_num[df$householdIncome == "21,001 - 28,000"] <- 4
df$householdIncome_num[df$householdIncome == "14,001 - 21,000"] <- 3
df$householdIncome_num[df$householdIncome == "7,001 - 14,000"] <- 2
df$householdIncome_num[df$householdIncome == "Up to 7,000"] <- 1

# marital status

df$marital <- as.character(as.numeric(df$marital))

df$marital[df$marital == "0"] <- "Prefer not to answer"
df$marital[df$marital == "1"] <- "Single"
df$marital[df$marital == "2"] <- "Married"
df$marital[df$marital == "3"] <- "Civil partnership"
df$marital[df$marital == "4"] <- "Co-habiting"
df$marital[df$marital == "5"] <- "Widowed"
df$marital[df$marital == "6"] <- "Separated"
df$marital[df$marital == "7"] <- "Divorced"

df$marital <- as.factor(df$marital)

# kids

df$kidsUnder5 <- as.numeric(as.character(df$kidsUnder5))
df$kids5To10 <- as.numeric(as.character(df$kids5To10))
df$kids11To15 <- as.numeric(as.character(df$kids11To15))
df$kids16To18 <- as.numeric(as.character(df$kids16To18))
df$kidsNone <- as.numeric(as.character(df$kidsNone))
df$kidsNoAnswer <- as.numeric(as.character(df$kidsNoAnswer))

# political attention

df$attention <- as.character(as.numeric(df$attention))

df$attention[df$attention == "1"] <- "0 - No attention at all"
df$attention[df$attention == "2"] <- "1"
df$attention[df$attention == "3"] <- "2"
df$attention[df$attention == "4"] <- "3"
df$attention[df$attention == "5"] <- "4"
df$attention[df$attention == "6"] <- "5"
df$attention[df$attention == "7"] <- "6"
df$attention[df$attention == "8"] <- "7"
df$attention[df$attention == "9"] <- "8"
df$attention[df$attention == "10"] <- "9"
df$attention[df$attention == "11"] <- "10 - a great deal of attention"

df$attention <- factor(df$attention, levels =
                         c("0 - No attention at all",
                           "1", "2", "3", "4", "5", "6", "7", "8", "9", 
                           "10 - a great deal of attention"))


df$attention_num[df$attention == "0 - No attention at all"] <- 0
df$attention_num[df$attention == "1"] <- 1
df$attention_num[df$attention == "2"] <- 2
df$attention_num[df$attention == "3"] <- 3
df$attention_num[df$attention == "4"] <- 4
df$attention_num[df$attention == "5"] <- 5
df$attention_num[df$attention == "6"] <- 6
df$attention_num[df$attention == "7"] <- 7
df$attention_num[df$attention == "8"] <- 8
df$attention_num[df$attention == "9"] <- 9
df$attention_num[df$attention == "10 - a great deal of attention"] <- 10


df$attentionCategory <- as.character(as.numeric(df$attentionCategory))

df$attentionCategory[df$attentionCategory == "1"] <- "Low (0-2)"
df$attentionCategory[df$attentionCategory == "2"] <- "Medium (3-7)"
df$attentionCategory[df$attentionCategory == "3"] <- "High (8-10)"

df$attentionCategory <- factor(df$attentionCategory, levels =
                                 c("Medium (3-7)", "Low (0-2)", 
                                   "High (8-10)"))

# Same variable, changing order of factor levels (for summary stats)
df$politicalAttention <- df$attentionCategory
df$politicalAttention <- factor(df$politicalAttention, levels =
                                 c("Low (0-2)", "Medium (3-7)",  "High (8-10)"))


# uni

df$university <- as.character(as.numeric(df$university))

df$university[df$university == "1"] <- "Not University"
df$university[df$university == "2"] <- "University"

df$university <- factor(df$university, levels =
                          c("Not University", "University"))


#### Managing variables -- Party ID ####

# support a party

df$supportParty <- as.character(df$supportParty)

df$supportParty[df$supportParty == 1] <- "Supports a party"
df$supportParty[df$supportParty == 2] <- "Does not support a party"

df$supportParty <- factor(df$supportParty, levels = c("Supports a party", "Does not support a party"))

# which party

df$party <- as.character(df$party)
df$party[df$party == 1] <- "Conservative"
df$party[df$party == 2] <- "Labour"
df$party[df$party == 3] <- "Liberal Democrat"
df$party[df$party == 4] <- "Scottish National Party (SNP)"
df$party[df$party == 5] <- "Plaid Cymru (PC)"
df$party[df$party == 6] <- "UK Independence Party (UKIP)"
df$party[df$party == 7] <- "Green"
df$party[df$party == 8] <- "Other (Please Specify)"

df$party <- factor(df$party, levels = c("Conservative", 
                                        "Labour", 
                                        "Liberal Democrat",
                                        "Scottish National Party (SNP)",
                                        "Plaid Cymru (PC)", 
                                        "UK Independence Party (UKIP)",
                                        "Green",
                                        "Other (Please Specify)"))

# otherParty

df$otherParty <- as.character(df$otherParty)

# 2017 vote

df$vote2017 <- as.character(df$vote2017)
df$vote2017[df$vote2017 == 1] <- "Conservative"
df$vote2017[df$vote2017 == 2] <- "Labour"
df$vote2017[df$vote2017 == 3] <- "Liberal Democrat"
df$vote2017[df$vote2017 == 4] <- "UK Independence Party (UKIP)"
df$vote2017[df$vote2017 == 5] <- "Green"
df$vote2017[df$vote2017 == 6] <- "Other"
df$vote2017[df$vote2017 == 7] <- NA

df$vote2017 <- factor(df$vote2017, levels = c("Conservative", 
                                              "Labour", 
                                              "Liberal Democrat",
                                              "UK Independence Party (UKIP)",
                                              "Green",
                                              "Other"))

# Brexit vote

df$votedBrexitRef <- as.character(df$votedBrexitRef)
df$votedBrexitRef[df$votedBrexitRef == "1"] <- "Yes"
df$votedBrexitRef[df$votedBrexitRef == "2"] <- "No"

df$votedBrexitRef <- factor(df$votedBrexitRef, levels = c("Yes", 
                                                  "No"))


df$brexitVote <- as.character(df$brexitVote)
df$brexitVote[df$brexitVote == 1] <- "Leave"
df$brexitVote[df$brexitVote == 2] <- "Remain"
df$brexitVote[df$brexitVote == 3] <- "Don't Know"

df$brexitVote <- factor(df$brexitVote, levels = c("Leave", 
                                                  "Remain", 
                                                  "Don't Know"))

df$hypBrexitVote <- as.character(df$hypBrexitVote)
df$hypBrexitVote[df$hypBrexitVote == 1] <- "Leave"
df$hypBrexitVote[df$hypBrexitVote == 2] <- "Remain"
df$hypBrexitVote[df$hypBrexitVote == 3] <- "Don't Know"

df$hypBrexitVote <- factor(df$hypBrexitVote, levels = c("Leave", 
                                                  "Remain", 
                                                  "Don't Know"))


df$brexit <- "remain/don't know"
df$brexit[df$brexitVote == "Leave"] <- "leave"
df$brexit[df$hypBrexitVote == "Leave"] <- "leave"

df$brexit <- factor(df$brexit, levels = c("remain/don't know", "leave"))




#### Managing variables -- Ideology ####

df$leftright_num <- as.numeric(df$leftright)

df$leftright <- as.character(df$leftright)
df$leftright[df$leftright_num == 1] <- "Very left-wing"
df$leftright[df$leftright_num == 2] <- "Fairly left-wing"
df$leftright[df$leftright_num == 3] <- "Slightly left-wing"
df$leftright[df$leftright_num == 4] <- "Centre"
df$leftright[df$leftright_num == 5] <- "Slightly right-wing"
df$leftright[df$leftright_num == 6] <- "Fairly right-wing"
df$leftright[df$leftright_num == 7] <- "Very right-wing"
df$leftright[df$leftright_num == 8] <- NA

df$leftright <- factor(df$leftright, levels = c("Very left-wing", 
                                                "Fairly left-wing",
                                                "Slightly left-wing",
                                                "Centre",
                                                "Slightly right-wing",
                                                "Fairly right-wing",
                                                "Very right-wing"))

df$leftright3[df$leftright_num %in% c(1,2,3)] <- "left-wing"
df$leftright3[df$leftright_num == 4] <- "centre"
df$leftright3[df$leftright_num %in% c(5,6,7)] <- "right-wing"

df$leftright3 <- factor(df$leftright3, levels = c("left-wing", "centre", "right-wing"))


#### Managing variables -- Immigration opinions ####

df$immigOpinions <- as.character(df$immigOpinions)

df$immigOpinions[df$immigOpinions == 1] <- "+3 = many more"
df$immigOpinions[df$immigOpinions == 2] <- "+2"
df$immigOpinions[df$immigOpinions == 3] <- "+1"
df$immigOpinions[df$immigOpinions == 4] <- "0 = no change"
df$immigOpinions[df$immigOpinions == 5] <- "-1"
df$immigOpinions[df$immigOpinions == 6] <- "-2"
df$immigOpinions[df$immigOpinions == 7] <- "-3 = many fewer"

df$immigOpinions <- factor(df$immigOpinions, levels = c("-3 = many fewer",
                                                        "-2", "-1", 
                                                        "0 = no change",
                                                        "+1", "+2", 
                                                        "+3 = many more"))

# NB: immigOpinions is coded so that higher numbers = FEWER IMMIGRANTS!!
# i.e. immigOpinions > 4: fewer immigrants; immigOpinions < 4 : more

df$immigOpinions_num[df$immigOpinions == "-3 = many fewer"] <- 1
df$immigOpinions_num[df$immigOpinions == "-2"] <- 2
df$immigOpinions_num[df$immigOpinions == "-1"] <- 3
df$immigOpinions_num[df$immigOpinions == "0 = no change"] <- 4
df$immigOpinions_num[df$immigOpinions == "+1"] <- 5
df$immigOpinions_num[df$immigOpinions == "+2"] <- 6
df$immigOpinions_num[df$immigOpinions == "+3 = many more"] <- 7

df$antiImmig <- ifelse(df$immigOpinions_num < 4, 1, 0)
df$proImmig <- ifelse(df$immigOpinions_num > 4, 1, 0)

df$immigOpinions3[df$immigOpinions_num < 4] <- "fewer"
df$immigOpinions3[df$immigOpinions_num == 4] <- "no change"
df$immigOpinions3[df$immigOpinions_num > 4] <- "more"

df$immigOpinions3 <- factor(df$immigOpinions3, levels = c("fewer",
                                                          "no change",
                                                          "more"))

df$immigImportance <- as.character(df$immigImportance)
df$immigImportance[df$immigImportance == "1"] <- "Extremely important"
df$immigImportance[df$immigImportance == "2"] <- "Very important"
df$immigImportance[df$immigImportance == "3"] <- "Somewhat important"
df$immigImportance[df$immigImportance == "4"] <- "Not at all important"
df$immigImportance[df$immigImportance == "5"] <- "Don't know"

df$immigImportance <- factor(df$immigImportance, 
                             levels = c("Extremely important",
                                        "Very important",
                                        "Somewhat important", 
                                        "Not at all important",
                                        "Don't know"))

df$immigImportance_num[df$immigImportance == "Extremely important"] <- 4
df$immigImportance_num[df$immigImportance == "Very important"] <- 3
df$immigImportance_num[df$immigImportance == "Somewhat important"] <- 2
df$immigImportance_num[df$immigImportance == "Not at all important"] <- 1

df$immigImportance3[df$immigImportance_num %in% c(3, 4)] <- "very/extremely important"
df$immigImportance3[df$immigImportance_num == 2] <- "somewhat important"
df$immigImportance3[df$immigImportance_num == 1] <- "not important"

df$immigImportance3 <- factor(df$immigImportance3, levels = c("very/extremely important", "somewhat important", "not important"))


# Immigration =  most/ 2nd most / 3rd most important issue
# Variable takes on a value of 1 if immigration is among the 3 most 
# important issues

df$immigImportantIssue <- ifelse(complete.cases(df$issues_immig), 1, 0)

# Create a variable for the most important issue 

df$mostImportantIssue[df$issues_immig == 1] <- "Immigration"
df$mostImportantIssue[df$issues_econ == 1] <- "The economy"
df$mostImportantIssue[df$issues_nhs == 1] <- "NHS/Health"
df$mostImportantIssue[df$issues_crime == 1] <- "Crime"
df$mostImportantIssue[df$issues_eu == 1] <- "EU/Brexit"
df$mostImportantIssue[df$issues_housing == 1] <- "Housing"
df$mostImportantIssue[df$issues_edu == 1] <- "Schools/Education"

df$issues_crime <- as.numeric(df$issues_crime)
df$issues_econ <- as.numeric(df$issues_econ)
df$issues_immig <- as.numeric(df$issues_immig)
df$issues_nhs <- as.numeric(df$issues_nhs)
df$issues_eu <- as.numeric(df$issues_eu)
df$issues_housing <- as.numeric(df$issues_housing)
df$issues_edu <- as.numeric(df$issues_edu)

# Dummies denoting whether respondent received a pro/anti-immigration fact check

df$gotAnti <- ifelse(df$whichFactCheck %in% c("noAsylum", "costImmig"), 1, 0)
df$gotPro <- ifelse(df$whichFactCheck %in% c("whiteCrime", "lowPaid"), 1, 0)

df$FactCheckProOrAnti <- ifelse(df$gotAnti==1, "anti-immigration statement",
                                "pro-immigration statement")


df$proOrAnti <- as.character(df$FactCheckProOrAnti)
df$proOrAnti[df$proOrAnti == "anti-immigration statement"] <- "anti"
df$proOrAnti[df$proOrAnti == "pro-immigration statement"] <- "pro"

df$proOrAnti <- factor(df$proOrAnti,
                       labels=c("anti", "pro"))

#### Managing variables -- Motivation to reject expert advice ####

# Creating a 'motivated to reject' variable in which I define everyone who
# wants '0 - no change' in the number of asylum seekers to be 'pro-immigration' 
# so that they would be motivated to accept the whiteCrime and lowPaid stats
# and motivated to reject the noAsylum and costImmig ones. 

# Motivated to reject the fact check:
# - People who want to take in fewer immigrants and get an anti-immigration fact check. 
# - People who want to take in more/the same number of immigrants and get a pro-immigration fact check.
# - In both cases: People who care at least somewhat about immigration


df$m2r <- 0
df$m2r[df$immigOpinions3 == "fewer" & df$whichFactCheck %in%c("noAsylum", "costImmig")] <- 1
df$m2r[df$immigOpinions3 == "more" | df$immigOpinions3 == "no change" & df$whichFactCheck %in%c("whiteCrime", "lowPaid")] <- 1

# Uncongenial fact check AND cared about immig!

df$m2r_imp <- 0
df$m2r_imp[df$immigOpinions3 == "fewer" & df$whichFactCheck %in%c("noAsylum", "costImmig") & df$immigImportance %in%c("Extremely important", "Very important", "Somewhat important")] <- 1

df$m2r_imp[df$immigOpinions3 == "more" | df$immigOpinions3 == "no change" & df$whichFactCheck %in%c("whiteCrime", "lowPaid") & df$immigImportance %in%c("Extremely important", "Very important", "Somewhat important") ] <- 1


# Creating a 'motivated to accept' variable 

df$m2a <- 0
df$m2a[df$immigOpinions3 == "more" & df$whichFactCheck %in%c("noAsylum", "costImmig")] <- 1
df$m2a[df$immigOpinions3 == "fewer" & df$whichFactCheck %in%c("whiteCrime", "lowPaid")] <- 1

df$motivation <- "not motivated to reject the statistics"

df$motivation[df$immigOpinions3 == "fewer" & df$gotAnti == 1] <- "motivated to reject the statistics"
df$motivation[df$immigOpinions3 == "more" & df$gotPro == 1 ] <- "motivated to reject the statistics"

df$motivation <- factor(df$motivation, levels = c("motivated to reject the statistics",
                                                  "not motivated to reject the statistics"))

df$motivation3 <- "neutral"

df$motivation3[df$immigOpinions3 == "fewer" & df$gotAnti == 1] <- "motivated to reject the statistics"
df$motivation3[df$immigOpinions3 == "more" & df$gotAnti == 1] <- "motivated to accept the statistics"

df$motivation3[df$immigOpinions3 == "no change"] <- "no motivation"

df$motivation3[df$immigOpinions3 == "more" & df$gotPro == 1 ] <- "motivated to accept the statistics"
df$motivation3[df$immigOpinions3 == "fewer" & df$gotPro == 1 ] <- "motivated to reject the statistics"


df$motivation3 <- factor(df$motivation3, levels = c("motivated to reject the statistics",
                                                   "no motivation", 
                                                  "motivated to accept the statistics"))



# df$motivation <- "not motivated to reject the statistics"
# 
# df$motivation[df$immigOpinions3 == "fewer" & df$gotAnti == 1 & df$immigImportance %in%c("Extremely important", "Very important", "Somewhat important")] <- "motivated to reject the statistics"
# df$motivation[df$immigOpinions3 == "more" & df$gotPro == 1 & df$immigImportance %in%c("Extremely important", "Very important", "Somewhat important")] <- "motivated to reject the statistics"
# 
# 
# df$motivation <- factor(df$motivation, levels = c("motivated to reject the statistics",
#                                                   "not motivated to reject the statistics"))


# Attitudes

df$attitude <- "anti-immigration respondents who got an anti-immigration statement (n=1156)"

df$attitude[df$immigOpinions3 == "fewer" & df$gotAnti == 1] <- "anti-immigration respondents who got an anti-immigration statement (n=1156)"
df$attitude[df$immigOpinions3 == "fewer" & df$gotPro == 1] <- "anti-immigration respondents who got a pro-immigration statement (n=232)"


df$attitude[df$immigOpinions3 == "more" & df$gotAnti == 1] <- "pro-immigration respondents who got an anti-immigration statement (n=257)"
df$attitude[df$immigOpinions3 == "more" & df$gotPro == 1] <- "pro-immigration respondents who got a pro-immigration statement (n=352)"


df$attitude[df$immigOpinions3 == "no change" & df$gotAnti == "1"] <- "neutral respondents who got an anti-immigration statement (n=465)"
df$attitude[df$immigOpinions3 == "no change" & df$gotPro == "1"] <- "neutral respondents who got a pro-immigration statement (n=474)"

df$attitude <- factor(df$attitude, levels = c(
  "anti-immigration respondents who got an anti-immigration statement (n=1156)",
  "anti-immigration respondents who got a pro-immigration statement (n=232)",
  "pro-immigration respondents who got an anti-immigration statement (n=257)",
  "pro-immigration respondents who got a pro-immigration statement (n=352)",
  "neutral respondents who got an anti-immigration statement (n=465)",
  "neutral respondents who got a pro-immigration statement (n=474)"
  ))



# df$motivation <- "neutral"
# 
# df$motivation[df$immigOpinions3 == "fewer" & df$gotAnti == 1] <- "motivated to reject"
# df$motivation[df$immigOpinions3 == "fewer" & df$gotPro == 1] <- "motivated to accept"
# 
# df$motivation[df$immigOpinions3 == "more" & df$gotPro == 1] <- "motivated to reject"
# df$motivation[df$immigOpinions3 == "more" & df$gotAnti == 1] <- "motivated to accept"
# 
# 
# df$motivation <- factor(df$motivation, levels = c("motivated to reject",
#                                                   "neutral",
#                                                   "motivated to accept"))


#### Managing variables -- Predispositions -- Populism #### 

df$pop_people_make_decisions <- as.character(df$pop_people_make_decisions)
df$pop_people_make_decisions[df$pop_people_make_decisions == 1] <- "Strongly agree"
df$pop_people_make_decisions[df$pop_people_make_decisions == 2] <- "Agree"
df$pop_people_make_decisions[df$pop_people_make_decisions == 3] <- "Disagree"
df$pop_people_make_decisions[df$pop_people_make_decisions == 4] <- "Strongly disagree"
df$pop_people_make_decisions[df$pop_people_make_decisions == 5] <- "Don't Know"

df$pop_people_make_decisions <- factor(df$pop_people_make_decisions, 
                                       levels = c("Strongly agree",
                                                  "Agree", 
                                                  "Don't Know",
                                                  "Disagree",
                                                  "Strongly disagree"))

df$pop_rep_by_citizen <- as.character(df$pop_rep_by_citizen)
df$pop_rep_by_citizen[df$pop_rep_by_citizen == 1] <- "Strongly agree"
df$pop_rep_by_citizen[df$pop_rep_by_citizen == 2] <- "Agree"
df$pop_rep_by_citizen[df$pop_rep_by_citizen == 3] <- "Disagree"
df$pop_rep_by_citizen[df$pop_rep_by_citizen == 4] <- "Strongly disagree"
df$pop_rep_by_citizen[df$pop_rep_by_citizen == 5] <- "Don't Know"

df$pop_rep_by_citizen <- factor(df$pop_rep_by_citizen, 
                                       levels = c("Strongly agree",
                                                  "Agree", 
                                                  "Don't Know",
                                                  "Disagree",
                                                  "Strongly disagree"))

df$pop_pol_talk_too_much <- as.character(df$pop_pol_talk_too_much)
df$pop_pol_talk_too_much[df$pop_pol_talk_too_much == 1] <- "Strongly agree"
df$pop_pol_talk_too_much[df$pop_pol_talk_too_much == 2] <- "Agree"
df$pop_pol_talk_too_much[df$pop_pol_talk_too_much == 3] <- "Disagree"
df$pop_pol_talk_too_much[df$pop_pol_talk_too_much == 4] <- "Strongly disagree"
df$pop_pol_talk_too_much[df$pop_pol_talk_too_much == 5] <- "Don't Know"


df$pop_pol_talk_too_much <- factor(df$pop_pol_talk_too_much, 
                                       levels = c("Strongly agree",
                                                  "Agree", 
                                                  "Don't Know",
                                                  "Disagree",
                                                  "Strongly disagree"))

df$pop_no_compromise <- as.character(df$pop_no_compromise)
df$pop_no_compromise[df$pop_no_compromise == 1] <- "Strongly agree"
df$pop_no_compromise[df$pop_no_compromise == 2] <- "Agree"
df$pop_no_compromise[df$pop_no_compromise == 3] <- "Disagree"
df$pop_no_compromise[df$pop_no_compromise == 4] <- "Strongly disagree"
df$pop_no_compromise[df$pop_no_compromise == 5] <- "Don't Know"

df$pop_no_compromise <- factor(df$pop_no_compromise, 
                                       levels = c("Strongly agree",
                                                  "Agree", 
                                                  "Don't Know",
                                                  "Disagree",
                                                  "Strongly disagree"))

df$pop_people_make_decisions_num[df$pop_people_make_decisions == "Strongly agree"] <- 5
df$pop_people_make_decisions_num[df$pop_people_make_decisions == "Agree"] <- 4
df$pop_people_make_decisions_num[df$pop_people_make_decisions == "Don't Know"] <- 3
df$pop_people_make_decisions_num[df$pop_people_make_decisions == "Disagree"] <- 2
df$pop_people_make_decisions_num[df$pop_people_make_decisions == "Strongly disagree"] <- 1

df$pop_rep_by_citizen_num[df$pop_rep_by_citizen == "Strongly agree"] <- 5
df$pop_rep_by_citizen_num[df$pop_rep_by_citizen == "Agree"] <- 4
df$pop_rep_by_citizen_num[df$pop_rep_by_citizen == "Don't Know"] <- 3
df$pop_rep_by_citizen_num[df$pop_rep_by_citizen == "Disagree"] <- 2
df$pop_rep_by_citizen_num[df$pop_rep_by_citizen == "Strongly disagree"] <- 1

df$pop_pol_talk_too_much_num[df$pop_pol_talk_too_much == "Strongly agree"] <- 5
df$pop_pol_talk_too_much_num[df$pop_pol_talk_too_much == "Agree"] <- 4
df$pop_pol_talk_too_much_num[df$pop_pol_talk_too_much == "Don't Know"] <- 3
df$pop_pol_talk_too_much_num[df$pop_pol_talk_too_much == "Disagree"] <- 2
df$pop_pol_talk_too_much_num[df$pop_pol_talk_too_much == "Strongly disagree"] <- 1

df$pop_no_compromise_num[df$pop_no_compromise == "Strongly agree"] <- 5
df$pop_no_compromise_num[df$pop_no_compromise == "Agree"] <- 4
df$pop_no_compromise_num[df$pop_no_compromise == "Don't Know"] <- 3
df$pop_no_compromise_num[df$pop_no_compromise == "Disagree"] <- 2
df$pop_no_compromise_num[df$pop_no_compromise == "Strongly disagree"] <- 1

# Create a scale
df$populism_scale = (df$pop_people_make_decisions_num + 
                       df$pop_rep_by_citizen_num + 
                       df$pop_pol_talk_too_much_num + 
                       df$pop_no_compromise_num) / 4


#### Managing variables -- Predispositions -- Nationalism #### 

df$ethno_lot_to_learn <- as.character(df$ethno_lot_to_learn)
df$ethno_lot_to_learn[df$ethno_lot_to_learn == "1"] <- "Strongly agree"
df$ethno_lot_to_learn[df$ethno_lot_to_learn == "2"] <- "Agree"
df$ethno_lot_to_learn[df$ethno_lot_to_learn == "3"] <- "Disagree"
df$ethno_lot_to_learn[df$ethno_lot_to_learn == "4"] <- "Strongly disagree"
df$ethno_lot_to_learn[df$ethno_lot_to_learn == "5"] <- "Don't Know"

df$ethno_lot_to_learn <- factor(df$ethno_lot_to_learn,
                                levels = c("Strongly disagree", "Disagree", 
                                           "Don't Know", "Agree", 
                                           "Strongly agree")) 

df$ethno_lot_to_learn_num <- as.character(as.numeric(df$ethno_lot_to_learn))
df$ethno_lot_to_learn_num[df$ethno_lot_to_learn == "Strongly agree"] <- 1
df$ethno_lot_to_learn_num[df$ethno_lot_to_learn == "Agree"] <- 2
df$ethno_lot_to_learn_num[df$ethno_lot_to_learn == "Don't Know"] <- 3
df$ethno_lot_to_learn_num[df$ethno_lot_to_learn == "Disagree"] <- 4
df$ethno_lot_to_learn_num[df$ethno_lot_to_learn == "Strongly disagree"] <- 5
df$ethno_lot_to_learn_num <- as.numeric(df$ethno_lot_to_learn_num)

df$ethno_ashamed_2B_British <- as.character(df$ethno_ashamed_2B_British)
df$ethno_ashamed_2B_British[df$ethno_ashamed_2B_British == 1] <- "Strongly agree"
df$ethno_ashamed_2B_British[df$ethno_ashamed_2B_British == 2] <- "Agree"
df$ethno_ashamed_2B_British[df$ethno_ashamed_2B_British == 3] <- "Disagree"
df$ethno_ashamed_2B_British[df$ethno_ashamed_2B_British == 4] <- "Strongly disagree"
df$ethno_ashamed_2B_British[df$ethno_ashamed_2B_British == 5] <- "Don't Know"

df$ethno_ashamed_2B_British <- factor(df$ethno_ashamed_2B_British,
                                levels = c("Strongly disagree", "Disagree", 
                                           "Don't Know", "Agree", 
                                           "Strongly agree")) 

df$ethno_ashamed_2B_British_num <- as.character(as.numeric(df$ethno_ashamed_2B_British))
df$ethno_ashamed_2B_British_num[df$ethno_ashamed_2B_British == "Strongly agree"] <- 1
df$ethno_ashamed_2B_British_num[df$ethno_ashamed_2B_British == "Agree"] <- 2
df$ethno_ashamed_2B_British_num[df$ethno_ashamed_2B_British == "Don't Know"] <- 3
df$ethno_ashamed_2B_British_num[df$ethno_ashamed_2B_British == "Disagree"] <- 4
df$ethno_ashamed_2B_British_num[df$ethno_ashamed_2B_British == "Strongly disagree"] <- 5
df$ethno_ashamed_2B_British_num <- as.numeric(df$ethno_ashamed_2B_British_num)

df$ethno_less_proud_2B_British <- as.character(df$ethno_less_proud_2B_British)
df$ethno_less_proud_2B_British[df$ethno_less_proud_2B_British == 1] <- "Strongly agree"
df$ethno_less_proud_2B_British[df$ethno_less_proud_2B_British == 2] <- "Agree"
df$ethno_less_proud_2B_British[df$ethno_less_proud_2B_British == 3] <- "Disagree"
df$ethno_less_proud_2B_British[df$ethno_less_proud_2B_British == 4] <- "Strongly disagree"
df$ethno_less_proud_2B_British[df$ethno_less_proud_2B_British == 5] <- "Don't Know"

df$ethno_less_proud_2B_British <- factor(df$ethno_less_proud_2B_British,
                                levels = c("Strongly disagree", "Disagree", 
                                           "Don't Know", "Agree", 
                                           "Strongly agree")) 

df$ethno_less_proud_2B_British_num <- as.character(as.numeric(df$ethno_less_proud_2B_British))
df$ethno_less_proud_2B_British_num[df$ethno_less_proud_2B_British == "Strongly agree"] <- 1
df$ethno_less_proud_2B_British_num[df$ethno_less_proud_2B_British == "Agree"] <- 2
df$ethno_less_proud_2B_British_num[df$ethno_less_proud_2B_British == "Don't Know"] <- 3
df$ethno_less_proud_2B_British_num[df$ethno_less_proud_2B_British == "Disagree"] <- 4
df$ethno_less_proud_2B_British_num[df$ethno_less_proud_2B_British == "Strongly disagree"] <- 5
df$ethno_less_proud_2B_British_num <- as.numeric(df$ethno_less_proud_2B_British_num)

df$ethno_Britain_best <- as.character(df$ethno_Britain_best)
df$ethno_Britain_best[df$ethno_Britain_best == 1] <- "Strongly agree"
df$ethno_Britain_best[df$ethno_Britain_best == 2] <- "Agree"
df$ethno_Britain_best[df$ethno_Britain_best == 3] <- "Disagree"
df$ethno_Britain_best[df$ethno_Britain_best == 4] <- "Strongly disagree"
df$ethno_Britain_best[df$ethno_Britain_best == 5] <- "Don't Know"

df$ethno_Britain_best <- factor(df$ethno_Britain_best,
                                levels = c("Strongly disagree", "Disagree", 
                                           "Don't Know", "Agree", 
                                           "Strongly agree")) 

df$ethno_Britain_best_num <- as.character(as.numeric(df$ethno_Britain_best))
df$ethno_Britain_best_num[df$ethno_Britain_best == "Strongly agree"] <- 5
df$ethno_Britain_best_num[df$ethno_Britain_best == "Agree"] <- 4
df$ethno_Britain_best_num[df$ethno_Britain_best == "Don't Know"] <- 3
df$ethno_Britain_best_num[df$ethno_Britain_best == "Disagree"] <- 2
df$ethno_Britain_best_num[df$ethno_Britain_best == "Strongly disagree"] <- 1
df$ethno_Britain_best_num <- as.numeric(df$ethno_Britain_best_num)

df$ethno_too_critical <- as.character(df$ethno_too_critical)
df$ethno_too_critical[df$ethno_too_critical == 1] <- "Strongly agree"
df$ethno_too_critical[df$ethno_too_critical == 2] <- "Agree"
df$ethno_too_critical[df$ethno_too_critical == 3] <- "Disagree"
df$ethno_too_critical[df$ethno_too_critical == 4] <- "Strongly disagree"
df$ethno_too_critical[df$ethno_too_critical == 5] <- "Don't Know"

df$ethno_too_critical <- factor(df$ethno_too_critical,
                                levels = c("Strongly disagree", "Disagree", 
                                           "Don't Know", "Agree", 
                                           "Strongly agree")) 

df$ethno_too_critical_num <- as.character(as.numeric(df$ethno_too_critical))
df$ethno_too_critical_num[df$ethno_too_critical == "Strongly agree"] <- 5
df$ethno_too_critical_num[df$ethno_too_critical == "Agree"] <- 4
df$ethno_too_critical_num[df$ethno_too_critical == "Don't Know"] <- 3
df$ethno_too_critical_num[df$ethno_too_critical == "Disagree"] <- 2
df$ethno_too_critical_num[df$ethno_too_critical == "Strongly disagree"] <- 1
df$ethno_too_critical_num <- as.numeric(df$ethno_too_critical_num)

df$ethno_be_more_like_Britain <- as.character(df$ethno_be_more_like_Britain)
df$ethno_be_more_like_Britain[df$ethno_be_more_like_Britain == 1] <- "Strongly agree"
df$ethno_be_more_like_Britain[df$ethno_be_more_like_Britain == 2] <- "Agree"
df$ethno_be_more_like_Britain[df$ethno_be_more_like_Britain == 3] <- "Disagree"
df$ethno_be_more_like_Britain[df$ethno_be_more_like_Britain == 4] <- "Strongly disagree"
df$ethno_be_more_like_Britain[df$ethno_be_more_like_Britain == 5] <- "Don't Know"

df$ethno_be_more_like_Britain <- factor(df$ethno_be_more_like_Britain,
                                         levels = c("Strongly disagree", "Disagree", 
                                                    "Don't Know", "Agree", 
                                                    "Strongly agree")) 

df$ethno_be_more_like_Britain_num <- as.character(as.numeric(df$ethno_be_more_like_Britain))
df$ethno_be_more_like_Britain_num[df$ethno_be_more_like_Britain == "Strongly agree"] <- 5
df$ethno_be_more_like_Britain_num[df$ethno_be_more_like_Britain == "Agree"] <- 4
df$ethno_be_more_like_Britain_num[df$ethno_be_more_like_Britain == "Don't Know"] <- 3
df$ethno_be_more_like_Britain_num[df$ethno_be_more_like_Britain == "Disagree"] <- 2
df$ethno_be_more_like_Britain_num[df$ethno_be_more_like_Britain == "Strongly disagree"] <- 1
df$ethno_be_more_like_Britain_num <- as.numeric(df$ethno_be_more_like_Britain_num)

df$ethno_scale <- df$ethno_lot_to_learn_num + df$ethno_ashamed_2B_British_num + df$ethno_less_proud_2B_British_num + 
  df$ethno_Britain_best_num + df$ethno_too_critical_num + df$ethno_be_more_like_Britain_num/6


#### Managing variables -- Predispositions -- Feels like home #### 

df$immigFeelLikeHome <- as.character(as.numeric(df$immigFeelLikeHome))
df$immigFeelLikeHome[df$immigFeelLikeHome == "1"] <- "Strongly agree"
df$immigFeelLikeHome[df$immigFeelLikeHome == "2"] <- "Agree"
df$immigFeelLikeHome[df$immigFeelLikeHome == "3"] <- "Disagree"
df$immigFeelLikeHome[df$immigFeelLikeHome == "4"] <- "Strongly disagree"
df$immigFeelLikeHome[df$immigFeelLikeHome == "5"] <- "Don't know"

df$immigFeelLikeHome <- factor(df$immigFeelLikeHome, 
                               levels = c("Strongly disagree",
                                          "Disagree", 
                                          "Don't Know",
                                          "Agree",
                                          "Strongly agree"))

df$immigFeelLikeHome_num <- NA
df$immigFeelLikeHome_num[df$immigFeelLikeHome %in% c("Strongly agree")] <- 5
df$immigFeelLikeHome_num[df$immigFeelLikeHome %in% c("Agree")] <- 4
df$immigFeelLikeHome_num[df$immigFeelLikeHome %in% c("Don't Know")] <- 3
df$immigFeelLikeHome_num[df$immigFeelLikeHome %in% c("Disagree")] <- 2
df$immigFeelLikeHome_num[df$immigFeelLikeHome %in% c("Strongly disagree")] <- 1


# To see where respondents rank on populism, nationalism, compared to others

df <- 
  df %>%
  dplyr::mutate(ethno_quartile = ntile(ethno_scale, 4),
         pop_quartile = ntile(populism_scale, 4))

# Looking at 2 items in the populism scale to see if it worked...

# # People should make decisions
# table(df$pop_peopleDecisions, df$pop_quintile)
# 
# # Compromise = BS
# table(df$pop_compromise, df$pop_quintile)

# --> it works. People who strongly agree tend to be in the 
# higher quintiles (4 or 5). 

# Create new variables for df dataset

# fact opinion ratings

df$factOpinion3 <- df$factOpinion

levels(df$factOpinion3)[levels(df$factOpinion3)=="0 - Purely a matter of fact"] <- "fact"
levels(df$factOpinion3)[levels(df$factOpinion3)=="1"] <- "fact"
levels(df$factOpinion3)[levels(df$factOpinion3)=="2"] <- "fact"
levels(df$factOpinion3)[levels(df$factOpinion3)=="3"] <- "neutral"
levels(df$factOpinion3)[levels(df$factOpinion3)=="4"] <- "opinion"
levels(df$factOpinion3)[levels(df$factOpinion3)=="5"] <- "opinion"
levels(df$factOpinion3)[levels(df$factOpinion3)=="6 - Purely a matter of opinion"] <- "opinion"

df$factOpinion3 <- factor(df$factOpinion3,
                       levels=c("fact", "neutral", "opinion"))


df$pop_quartile <- as.factor(as.character(df$pop_quartile))
levels(df$pop_quartile)[levels(df$pop_quartile)==1] <- "very low (Q1)"
levels(df$pop_quartile)[levels(df$pop_quartile)==2] <- "fairly low (Q2)"
levels(df$pop_quartile)[levels(df$pop_quartile)==3] <- "fairy high (Q3)"
levels(df$pop_quartile)[levels(df$pop_quartile)==4] <- "very high (Q4)"

df$pop_quartile <- factor(df$pop_quartile, 
                          levels = c("very low (Q1)",
                                     "fairly low (Q2)",
                                     "fairy high (Q3)",
                                     "very high (Q4)"))


df$ethno_quartile <- as.factor(as.character(df$ethno_quartile))
levels(df$ethno_quartile)[levels(df$ethno_quartile)==1] <- "very low (Q1)"
levels(df$ethno_quartile)[levels(df$ethno_quartile)==2] <- "fairly low (Q2)"
levels(df$ethno_quartile)[levels(df$ethno_quartile)==3] <- "fairy high (Q3)"
levels(df$ethno_quartile)[levels(df$ethno_quartile)==4] <- "very high (Q4)"


df$ethno_quartile <- factor(df$ethno_quartile, 
                            levels = c("very low (Q1)",
                                       "fairly low (Q2)",
                                       "fairy high (Q3)",
                                       "very high (Q4)"))


#### Managing variables -- Predispositions -- Immigration is good for the economy #### 

df$immigEcon <- as.character(as.numeric(df$immigEcon))
df$immigEcon[df$immigEcon == "1"] <- "Strongly agree"
df$immigEcon[df$immigEcon == "2"] <- "Agree"
df$immigEcon[df$immigEcon == "3"] <- "Disagree"
df$immigEcon[df$immigEcon == "4"] <- "Strongly disagree"
df$immigEcon[df$immigEcon == "5"] <- "Don't Know"

df$immigEcon <- factor(df$immigEcon, 
                               levels = c("Strongly disagree",
                                          "Disagree", 
                                          "Don't Know",
                                          "Agree",
                                          "Strongly agree"))

df$immigEcon_num[df$immigEcon == "Strongly agree"] <- 5
df$immigEcon_num[df$immigEcon == "Agree"] <- 4
df$immigEcon_num[df$immigEcon == "Don't Know"] <- 3
df$immigEcon_num[df$immigEcon == "Disagree"] <- 2
df$immigEcon_num[df$immigEcon == "Strongly disagree"] <- 1


# social grade

df$socialGrade <- as.character(as.numeric(df$socialGrade))
df$socialGrade[df$socialGrade == "1"] <- "AB"
df$socialGrade[df$socialGrade == "2"] <- "C1"
df$socialGrade[df$socialGrade == "3"] <- "C2"
df$socialGrade[df$socialGrade == "4"] <- "DE"

df$socialGrade <- factor(df$socialGrade, levels=c("AB", "C1", "C2", "DE"))

df$socialGrade_num <- NA
df$socialGrade_num[df$socialGrade == "AB"] <- 4
df$socialGrade_num[df$socialGrade == "C1"] <- 3
df$socialGrade_num[df$socialGrade == "C2"] <- 2
df$socialGrade_num[df$socialGrade == "DE"] <- 1


#### Managing variables -- Other #### 

df$w8 <- as.numeric(as.character(df$w8))


##### Order dataframe alphabetically #####

# names(df)

# Order columns alphabetically
# sort.df <- df[ , order(names(df))]

# Order columns alphabetically but have id first
# df <- df[ , c("id", sort(setdiff(names(df), "id")))]

# Order rows by immigration, and treatment
df <- with(df, df[order(immigOpinions, whichFactCheck) , ])

# glimpse(df)


##### Looking into response behaviour #####

# Excluding 2 responses that did not make it to the fact check

# temp <- df[ which(complete.cases(df$whichFactCheck)), ]

df <- df[ which(complete.cases(df$whichFactCheck)), ]

# # 2 respondents rated all false facts as 'Definitely false'
# # 
# # smartypants <- df[ which(!complete.cases(df$whichFactCheck)), ]
# # str(smartypants)
# 
# # df <- df[ which(complete.cases(df$whichFactCheck)), ]

# 2 respondents selected don't know whenever they could
# and were missing on the key IVs.
# 
# lazyfolks <- df[ which(!complete.cases(df$belief_T1)), ]

# Turn remaining character strings into factors
# characters <- sapply(df, is.character)
# df[characters] <- lapply(df[characters], as.factor)



#### Save the short data set #### 

save(df, file="/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/df.RData")
# save(df, file="/Users/christine/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/df.RData")
# write.dta(df, file="/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/df.dta")

# load(df)


##### Wide to long #####

library(tidyr)
# http://www.cookbook-r.com/Manipulating_data/Converting_data_between_wide_and_long_format/

# Gathering all variables that contain the letters '_T'. 
# Then splitting the key variable into 2 at the _ 
# Regular expressions used in the code below: 
# .{2,}   --> any 2 or more characters
# \\_     --> escape _
# T.      --> . because it could be T1 or T2

# glimpse(df_long)
# temp <- df_long[c("key", "value"),  ]

# https://community.rstudio.com/t/spread-why-errors/2076/2


df_long <-
  df %>% 
  gather(key, value, contains('_T', ignore.case = FALSE)) %>% 
  tidyr::extract(key, c("question", "time"), "(.{2,})\\_(T.)") %>%
  spread(question, value) # note that variable names including _T1 or _T2 need to end in _T1 or _T2.


# Lost some of the data types, so turning them back into numeric

intoNum_long <- c(
  "noAsylum_num",
  "costImmig_num",
  "whiteCrime_num",
  "lowPaid_num",
  "fracking_num",
  "no5_num",
  "plasticBags_num",
  "recession_num",
  "belief_num",
  "belief_i2_num",
  # "belief_i3_num",
  # "belief_i4_num",
  "belief_noAsylum_num",
  "belief_costImmig_num",
  "belief_whiteCrime_num",
  "belief_lowPaid_num",
  # "bothWrong",
  "wrong",
  "wrong_i2"
  # "wrong_noAsylum",
  # "wrong_costImmig",
  # "wrong_whiteCrime",
  # "wrong_lowPaid"
)

# Turn into numeric
df_long[ , intoNum_long] <-
  lapply(df_long[ ,intoNum_long], as.numeric)

# Turn into factor
df_long$time <- as.factor(as.character(df_long$time))

# str(df_long)

# Order columns
# df_long <- df_long[, c(1,137:157 ,2:136)]


df_long$comment2 <- df_long$comment

levels(df_long$comment2)[levels(df_long$comment2)=="comment"] <- "Undermining message"
levels(df_long$comment2)[levels(df_long$comment2)=="no comment"] <- "No undermining message"

df_long$comment2 <- factor(df_long$comment2,
                       levels=c("No undermining message", "Undermining message"))



df$believeSomethingDifferent <- ifelse(df$ifInconsistent == "The statistics are probably right but I believe something different.", 1, 0)


# Create subsets

df_long_ctrl <- subset(df_long, RandomGrp %in% c(1, 2))


##### Create new variables in the long dataset #####

# # To determine the spillover effects of a fact-check on 
# # belief in un-fact-checked claims I am running a paired 
# # t-test on a subset of people who were a) in the control
# # group and who b) rated both false facts as 'true' at time T1. 
# # I need a variable to determine if they got both items 
# # on their side of the debate wrong. 

# Creating a dummy variable that is 1 if respondents rated both false 
# claims at 'true' at time T1. 
# NB: I need this variable to find the spillover effects of a fact-check on 
# belief in un-fact-checked claims. I am running a paired 
# t-test on a subset of people who were a) in the control
# group and who b) rated both false facts as 'true' at time T1. 
# So I need a variable to determine if they got both items 
# on their side of the debate wrong. 

df_long$bothWrongT1 <- ifelse(df_long$time == "T1" &
                                df_long$wrong == "1" & 
                                df_long$wrong_i2 == "1", 1, 0)

df_long$bothWrongT2 <- ifelse(df_long$time == "T2" &
                                df_long$wrong == "1" & 
                                df_long$wrong_i2 == "1", 1, 0)

# Now I want this value to appear in both rows for each column

df_long <-
  df_long %>% 
  #filter(time == "T1") %>%
  group_by(id) %>%
  dplyr::mutate(
    bothWrongT1 = sum(bothWrongT1),
    bothWrongT2 = sum(bothWrongT2)
  )

# Order rows
df_long <- df_long[order(df_long$id), ]

# See if it worked -- yes
# head(df_long[ , c("id",
#                   "time",
#                   "belief",
#                   "belief_num",
#                   "wrong",                  
#                   "belief_i2",
#                   "belief_i2_num",
#                   "wrong_i2",
#                   # "bothWrong",
#                   "bothWrongT1",
#                   "bothWrongT2"
#                   
# )])


#### Save the long data set #### 

save(df_long, file="/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/df_long.RData")
# save(df_long, file="/Users/christine/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/df_long.RData")

# write.dta(df_long, file="/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/df_long.dta")

# setwd("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/R/graphs/for publication") 

# setwd("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/") 
# load("workingData/df.RData")
# load("workingData/df_long.RData")

noAsylum_lbl <- "'There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years.'"
costImmig_lbl <- "'Immigrants receive more in benefits and services than they pay in taxes.'"
whiteCrime_lbl <- "'The majority of crimes in London are committed by white people, not ethnic minorities.'"
lowPaid_lbl <- "'Immigration to the UK does not affect the wages of the low-paid.'"

pro <- subset(df, immigOpinions3 == "more")
anti <- subset(df, immigOpinions3 == "fewer")

gotAnti <- subset(df, df$whichFactCheck %in% c("noAsylum", "costImmig"))
gotPro <- subset(df, df$whichFactCheck %in% c("whiteCrime", "lowPaid"))


convinced <- subset(df, belief_num_T2 > belief_num_T1) # higher values = more false
notConvinced <- subset(df, belief_num_T2 <= belief_num_T1)

df$convinced <- ifelse(df$belief_num_T2 > df$belief_num_T1, "convinced", "not convinced")

noAsylum <- subset(df, whichFactCheck == "noAsylum")
costImmig <- subset(df, whichFactCheck == "costImmig")
whiteCrime <- subset(df, whichFactCheck == "whiteCrime")
lowPaid <- subset(df, whichFactCheck == "lowPaid")
clueless <- subset(df, consistent == "Yes" & wrong_T1 == 1)
m2r <- subset(df, m2r == 1)
  
twoReds <- c("#c8c3cc", "#563f46")
fourReds <- c("#E9E5E7","#938489", "#78656B", "#563f46")

twoLightGreys <- c("#f0f0f0", "#bdbdbd")
twoDarkGreys <- c("#bdbdbd", "#636363")
threeGreys <- c("#f0f0f0", "#bdbdbd", "#636363")
threeLightGreys <- c("#f7f7f7", "#cccccc", "#969696")

```

# Abstract {.unlisted .unnumbered}

While fact-checks go some way to increasing the accuracy of public beliefs, they meet with considerable resistance. The motivations behind that resistance are much clearer than the mechanisms through which ostensibly neutral and factual information is rejected. In a survey experiment we demonstrate how various strands of what we term post-truth rhetoric can immediately undermine the effects of fact-checks. We first assessed perceptions about immigration and exposed those with misperceptions to a fact-check. Then we exposed treatment groups to one of three variants of post-truth rhetoric, not directly refuting the accuracy of the fact-check but suggesting that people should take the evidence with a big pinch of salt. This rhetoric undid almost one third of the positive effect of the fact check on the accuracy of respondents beliefs. The effect was significant and similar in size regardless of the variant of rhetoric used or the credentials of the commentator. 

**Keywords**: fact-checking, misperceptions, resistance to correction, post-truth 

$$\\[0.1cm]$$ 

**Word count**: 10188 words 

\newpage

# Introduction {.unlisted .unnumbered}

*An expert or academic has more chance of leading readers astray with their biased and cherry picked information which is the same as lying.*\
Madison [\@MadisonTX766], April 22nd, 2023, Twitter.

*Trust your experience and personal research over anything else.  Especially over hacks like politifacts. \#walkaway.*\
Brian Sanders [\@Brian_Sanders3], August 15th, 2019, Twitter.

*Feelings aren't facts but trust your intuition regardless. If it feels off, troubling or weird then there's a high chance it's not right for you.*\
Master Apprentice [\@truekingmaker], January 12th, 2023, Twitter. 

$$\\[0.1cm]$$ 

Public debates are complex and characterised by a bewildering series of claims and counterclaims. This complexity has increased in recent years. Before the dawn of the internet, parties, experts, and the media used to structure the national conversation. In the last twenty years or so, however, social media have provided almost everyone with access to information and platforms on which to express their views. Experts are present on these platforms but they are outnumbered and often outgunned in a noisy and confusing public debate, and their assertions of the facts are routinely greeted by the kinds of replies that opened this article. Such responses and their popularity  the three tweets between them have over 250 likes  well illustrate Francis Fukuyama's [-@Fukuyama2017] definition of a post-fact world as one in which virtually all authoritative information sources are called into question and challenged by contrary facts of dubious quality and provenance. However meagre their own credentials, those challenging expert information in this way are potentially persuasive either because they are recognised as political allies or because they are personally trusted and it is easier for most of us to abandon facts than friendships. The key question for this article is: how persuasive are such post-truth rhetorical challenges to authoritative expert evidence?

Journalists, public bodies, charities, and academics have responded to the concerns about a post-fact or post-truth world. In particular, there are numerous fact-checking organisations seeking to correct misinformation. In the US, prominent such services include FactCheck.org, PolitiFact and Snopes. In the UK, the empirical focus for this study, the leading public service broadcasters established fact-checks in the mid-2000s [@Graves2016], and Full Fact, a registered charity founded in 2009 to counter misinformation, has partnered with Facebook to provide fact-checking services on that platform since 2019. Many other countries have their own institutions, and the International Fact-Checking Network was established in 2015 to strengthen the sector.

A host of studies have shown that such attempts to correct misinformation enjoy some but only limited success. Three meta-analyses show that peoples perceptions usually shift in the direction of the fact-check but often not by much [@Chan2017; @Walter2018; @Walter2020]. The reason why this success is often limited is also well established: people are motivated reasoners, susceptible to confirmation bias [@Kunda1990]. We all have cognitive, ideological and group-based motivations to be sceptical of fact-checks that challenge things we thought were true and motivations to accept fact-checks (or any other information, true or false) that confirm them [@Kahan2017c].

A defining feature of todays informational environment is that such scepticism is not simply a matter of private reasoning. The challenge to fact-checkers and experts is immediate and public. Debates in TV studios and on social media expose citizens not only to the facts but also to interpretations of those facts. Moreover, anyone can dispute an expert fact-check  and can expect positive reinforcement from partisan or ideological sympathisers, since the age of information abundance and fact-checking is also the era of polarised politics. Extremists and populists alike encourage mistrust of established institutions and their claims to provide objective fact-checking. Populist politicians have portrayed experts as self-interested actors, espousing views that fly in the face of the common sense or the personal experience of the people. In the much-quoted words of Michael Gove, a prominent Leave campaigner during the UKs 2016 referendum on EU membership, "I think the people of this country have had enough of experts with organisations with acronyms saying that they know what is best and getting it consistently wrong" [@SkyNews2016]. In short, there is no lack of elite cueing of the views expressed in the tweets opening this article. 

Yet we know surprisingly little about the persuasiveness of these views. Put another way, how much of the positive effect of fact-checks and corrections is undone when they are challenged in this way? And does the answer depend on the narrative undermining the facts? As illustrated by those sample tweets, post-truth rhetoric offers several such narratives, such as challenging the neutrality of the source, or asserting the primacy of personal experience or even personal feelings over evidence. Which are most persuasive? Existing research has not yet addressed these questions or, more generally, assessed the effectiveness of corrective information in the face of post-truth rhetorical challenge. Instead, studies have typically assessed the impact of fact-checking in one-shot experiments. They have identified those who hold misperceptions, exposed them to a fact-check, and measured the accuracy of belief after the check [@Kuklinski2000, @NyhanReifler2010, @Weeks2015]. This research design is appropriate for measuring the immediate impact of such a correction. However, by giving fact-checkers the final word, it does not replicate a world in which they come under immediate challenge and so cannot estimate the resistance of their corrections against such challenge. 

It is not possible to capture the full cacophony of public debate in a controlled survey experiment. Nevertheless, we can go beyond existing studies by testing the robustness of fact-check effects against the immediate challenges observed in a post-truth environment. We do this with a survey experiment based on perceptions about immigration: an emotionally charged issue influential in recent UK general elections and the 2016 referendum on European Union membership [@Sobolewska2020]. We first established peoples misperceptions about immigration and then treated them to corrective expert evidence countering whichever false claim they were most convinced was true. Then, before measuring the revised perceptions of our treatment groups, we exposed them to a shot of the kind of post-truth rhetoric that opened this article. These undermining messages did not directly refute the accuracy of the fact-check but gave respondents one of three reasons to take the expert evidence with a big pinch of salt.  

Our results support previous studies on the impact of fact-checks. Not everyone switched all the way but most shifted their perceptions in line with the fact check, becoming less convinced it was true. However, exposure to post-truth rhetoric then significantly undermined this effect. Compared to those receiving only the fact check, treatment group respondents moved almost one third of the way back towards their original misperceptions. This effect was consistently significant and varied surprisingly little in size, regardless of the strand of post-truth rhetoric or the credentials of the commentator. 

This paper is structured as follows. First, we review the literature on resistance to factual correction and formulate four hypotheses designed to assess the impact of fact-checking and exposure to post-truth rhetoric. Then we describe the data and design used to test these hypotheses and present our results. Finally, we consider the external validity and implications of these findings, suggesting they may well understate the undermining impact of post-truth rhetoric given its likely repetition and amplification within peoples social networks.

# Resistance to correction: drivers and limits {.unlisted .unnumbered}

Humans tend to resist information that challenges their factual beliefs, even when it represents otherwise compelling testimony [@Johnson1994; @Wyer1987].  The drivers of this resistance are well-known. We are motivated reasoners, driven not only by accuracy but also by directional goals, powerful incentives to maintain existing opinions [@Kunda1990; @Mercier2011; @Bolsen2019]. This is partly because it is easier to stick to ones opinions rather than engage in time-consuming consideration of incoming information. But it is not only about cognitive convenience. Many people are partisans, some are ideologues, and all belong to social groups, and these identities structure and drive motivated reasoning [@NyhanReifler2010; @VanBavel2018; @Ecker2019; @Ecker2022]. There is psychological discomfort in accepting information and forming beliefs in conflict with those held by fellow partisans or other group members  especially if those beliefs are central to the groups identity or that group is central to our own social or political identity [@Zaller1992; @Kahan2017c; @Guess2018b; @Wittenberg2020].

Within this framework, those fact-checking political claims can be seen not only as providing accurate information but also as priming accuracy goals. Their purpose is to encourage citizens to see that, amid the motivated to and fro of political argument, some claims are correct and some are not. The evidence on correction of misinformation suggests that it has a mixed record. There are prominent examples of success (e.g. @Redlawsk2010; @Nyhan2020; @Porter2019) but also prominent examples of resistance to correction (@NyhanReifler2010; @Thorson2016). Reviews of this extensive literature report a similar mixed picture (see @Lewandowsky2012; @Flynn2017; @Swire2018; specifically on fact-checking, see @Nieminen2019). There is now enough empirical work to support meta-analysis, and three recent analyses found that factual corrections significantly increased the accuracy of peoples perceptions [@Chan2017; @Walter2018; @Walter2020]. This effect is moderate in strength (a standardised effect size of around 0.3). It is much weaker in relation to ideologically divisive issues, and in election campaigns when partisan considerations are activated [@Walter2018; @Walter2020]. In short, and not surprisingly, neither accuracy nor directional goals win the battle outright. 

Put another way, fact-checks are a significant intervention in that battle but do not resolve it in favour of accuracy. They are not the last word. Many of those citizens momentarily persuaded by a fact-check retain at least some impulse to reject it, an impulse that can be activated by those with the incentive and platform to do so. The question is: how is it activated? What are the lines of counter-attack against factual correction, and how successful are they? These issues have been much less explored, especially empirically. We know much more about why people might resist correction than about how. 

The theoretical frameworks from previous work allow us to identify three potential mechanisms [@Wittenberg2020; @Ecker2022]. The first, labelled here expert bias, discredits the source of the fact-check. Numerous studies show that the perceived expertise, trustworthiness and general authoritativeness of a source strongly predicts the extent to which people accept their fact-checks and corrections [@Guillory2013;  @Vraga2017; @Berinsky2015; @Swire2017]. And the interventions of fact-checkers can be portrayed as just that  the facts: authoritative and objective contributions from those seeking only to inform the debate. However, a common counter-attack portrays them instead as partial in either or both senses of the term: at best, not telling the full story; at worst, biased contributions from those ideologically committed to one side of the debate [@YlaeAnttila2018; @McIntyre2018]. If sources can be thus discredited, their contributions can be dismissed. 

The second way that checks can be undermined, which we label 'invoking personal experience', asserts the importance of personal experiences rather than objective evidence. Where statistics are at odds with personal experience or anecdotal evidence, people attach more weight to those things that they directly observe [@ShelbyErnst2013]. People are prone "to treat subjective experiences as truer than objective facts" [@Kubin2021]. Corrections can be dismissed as 'your truth but not mine' (see @vanBavel2021). 

That last phrase brings us to the third mechanism that may undermine fact-checks. This line, which we follow Stephen Colbert (2005) in labelling truthiness, suggests that intuition or gut feeling are as valid a route to the truth as statistics or scientific evidence. When seemingly contradictory statistics are already being bandied around in political debate, incoming facts can be dismissed as just more data (and the phrase lies, damned lies and statistics is available to anyone seeking to dismiss inconvenient evidence). This can encourage citizens to suppose that there is no single truth, just rival opinions with their own supporting data  and, in such an unstable climate, people may conclude that their feelings provide a surer basis than objective facts. This is in some ways the most troubling mechanism because it seems to be beyond reason. Nevertheless, it may account for standard defences that those who contest the facts have a right to their opinion.

These three mechanisms are illustrated in turn by the three tweets that opened this article. Those examples were not hard to find. All three mechanisms are readily picked out in the chorus of scepticism that typically greets fact-checking interventions on social media. There are frequent attacks on the neutrality and accuracy of the fact-checkers sources and suggestions that equally valid data exist pointing in the other direction (@Brandtzaeg2017; @Shin2017). These lines are readily available in public discourse to those with reason to dislike the corrective information put in front of them. What is lacking so far  and provided in this article  is empirical evidence on their effectiveness.

There is related evidence that 'objective' statistical evidence can be swiftly undermined. The focus there has been on the effects of journalistic 'false balance.' Reporting the counterarguments of 'maverick scientists' reduces confidence in expert consensus and lends credibility to a minority view that is not supported by the evidence [@Dearing1995]. Climate science provides vivid illustrations [@McCright2016; @VanderLinden2017]. In one study, respondents were presented with a pie chart stating that '97% of climate scientists have concluded that human-caused climate change is happening. Some received an additional treatment: They were shown a (real) petition urging the U.S. government to reject the Kyoto protocol because 'there is no convincing scientific evidence that human release of carbon dioxide... will... cause catastrophic heating of the Earths atmosphere.' On its own, the pie chart had a positive effect on perceptions of expert consensus. When accompanied by the petition, it had no effect at all [@VanderLinden2017].

This raises the two major questions with which our experimental study extends research on resistance to correction. If a fact-check is accompanied by a statement encouraging people to disregard the statistics, how far does this offset the positive effect of the fact-check? And does the answer depend on which of the three mechanisms  expert bias, invoking personal experience, or truthiness  is activated by that message? We also examine the potential importance of source credibility in these dynamics. Finally, we test whether these rhetorical challenges encourage more general 'post-truth' reasoning about the blurring of facts and opinions and the acceptability of ignoring 'the facts.'


# Hypotheses {.unlisted .unnumbered}

We tested four pre-registered hypotheses
^[Registered with OSF at [link blinded for review].] 
<!-- https://osf.io/5q3y6/?view_only=0829c870e63c45dfb8118ae3457ff466 -->
^[Note for reviewers:  Unfortunately, our OSF submission includes a pre-analysis plan that is not anonymised. We have shared a link to our OSF pre-registration with the editors and include an anonymised version of the pre-analysis plan in the appendix.]. The first, consistent with the weight of literature reviewed above, is that the expert factual correction will reduce misperceptions.

**Fact-Check Hypothesis (H1):** When respondents are asked to reassess a false statement after it is corrected by an expert fact-check, they are less likely to rate it as true.

Confirmation of H1 is a precondition for testing our second and most important hypothesis: that the positive effect of the fact check will be undermined by subsequent exposure to post-truth rhetoric. 

**Undermining Message Hypothesis (H2):** The effect of the fact-check is weaker among those who were exposed to an undermining statement.

We tested three post-truth rhetorical messages designed to undermine respondents reliance on expert evidence. These reflect the three mechanisms set out above (expert bias, invoking personal experience or truthiness). While each message is prominent in challenges to factual corrections, their relative persuasiveness has not been tested in past research and we had no a priori expectation that one argument would be more powerful than another. We simply anticipate that H2 will be confirmed for all three messages. 

It seems only natural to suggest that the effectiveness of these rhetorical messages would vary according to how authoritative the individual that makes a statement is. We noted earlier that authoritative sources are more likely to correct misinformation; it seems reasonable to suppose that they can better discredit correct information, too. Testing this supposition and using credentials as a signal for authority, we hypothesise:


**Authoritativeness Hypothesis (H2a).** The effect in H2 is stronger if the undermining statement comes from a professor rather than a blogger.

Finally, we assessed the effect of exposure to undermining challenges on broader post-truth thinking. Here, our experiment stretches well beyond existing research and so our hypotheses are more exploratory and worth setting up in more detail. The first point is that this may be a new contribution but it is on an age-old issue: citizens belief in objective truth and the value they attach to it. Writing about the Holocaust, Hannah Arendt suggested that the scale of lying by politicians had left the public at the point where they would, at the same time, believe everything and nothing. Those purveying mass propaganda discovered that its audience ... did not particularly object to being deceived because it held every statement to be a lie anyhow [@Arendt1951]. 
Forty years later, Steve Tesich [-@Tesich1992] coined the term 'post-truth' in writing about the trauma of the Watergate and the Iran-Contra scandals: "We, by our actions, are saying that this is no longer necessary, that we have acquired a spiritual mechanism that can denude truth of any significance. In a very fundamental way we, as a free people, have freely decided that we want to live in some post-truth world".

Yet there is a long distance between external observers describing the public as post-truth and citizens themselves embracing the rejection of objective truth or endorsing the notion of alternative facts. There is little if any direct evidence of such post-truth reasoning. One important exception tests Brotherton and Sons [-@Brotherton2021] proposition that people might metacognitively categorise uncongenial claims as 'more opinion than factual', and congenial claims as more factual than opinion. In a 2018 Pew survey, 5,000 U.S. Americans were presented with a battery of statements and asked to categorise each as a factual or opinion statement. A substantial proportion mislabelled factual statements as opinion statements  especially if those statements challenged their partisan identity. For instance, almost 40% of Republicans deemed the statement that President Barack Obama was born in the United States as an opinion [@Mitchell2018]. Categorising a statement as opinion may also be a response to complexity: close to half of both Democrats and Republicans categorised Spending on Social Security, Medicare, and Medicaid make up the largest portion of the U.S. federal budget as an opinion. This re-categorization of facts as opinion is one way to allow oneself to disregard the evidence, and thus also a means by which post-truth rhetoric can undermine that evidence. 

Categorising factual corrections as matters of opinion is the first of three strands of post-truth reasoning that we hypothesise will be encouraged by the undermining rhetoric. The other two are more explicit statements of truthiness inspired by a combination of Stephen Colberts [-@Colbert2005] introduction of the notion in 2005 and Kellyanne Conways notorious notion of alternative facts [@NBCNews2017]. The underlying conjecture is that, if encouraged to reject the facts in this specific case, respondents might feel entitled or emboldened to do the same more generally.  

**'Post-truth Reasoning Hypothesis (H3).** Respondents who saw an undermining statement are more likely to: 

a. Categorise uncongenial factual questions as matters of opinion. \newline
b. State that, in this case, they believe something different from the facts; and \newline
c. Agree in general that it is okay to disagree with the facts if the facts point another way.

# Case, data and design {.unlisted .unnumbered}

These hypotheses were tested in a survey experiment based on common misperceptions about immigration in Great Britain. This makes a useful case for several reasons. Immigration is subject to widespread misperceptions. This is especially true of perceptions about the numbers of immigrants, but it also extends to beliefs about the origins and status of immigrants (@Duffy2014; @Hopkins2019; @Gorodzeisky2020; @Lutz2022). The issue has also been thoroughly politicised in Britain (@Sobolewska2020). Many citizens have powerful directional goals about immigration. These were closely tied to voting behaviour in the EU referendum [@Hobolt2021]. The referendum also linked immigration attitudes to powerful group identities.  We might reasonably assume that an expert asserting a pro-immigration view might be labelled as a Remainer  and anyone challenging the same expert would be labelled a Leaver. There is ample evidence that beliefs are harder to shift if they are seen as central to an individuals group identity (@Kahan2017c; @Nyhan2020). Messages that encourage the rejection of unsolicited claims about immigration should therefore fall on receptive ears.

The main survey was fielded online in June 2019 on a sample of 2,936 British citizens. Fieldwork was by Deltapoll, an internet survey agency that recruits from online panels. This was a non-probability sample but is representative of the British electorate on key demographic and political variables. (Sample characteristics are reported in Appendix A.) 

The main survey was preceded by a pilot study with a diverse convenience sample of 200 British adults recruited via Prolific. We pre-tested various false claims on both sides of the immigration debate and used the results to choose two false claims widely believed on each side. The 'pro-immigration' claims were: 'Immigration to the UK does not affect the wages of the low-paid,' and 'The majority of crimes in London are committed by white people, not ethnic minorities.' The 'anti-immigration' claims were: 'There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years,' and 'European immigrants receive more in benefits and services than they pay in taxes.'

![Design of the main experiment](/Users/cstedtnitz/Dropbox/Bibtex/images/post_truth_survey_flow.png)

The survey opened with background questions, including socio-demographics and views about immigration. The experimental phase had four stages, as shown in Figure 1.  In **Stage 1**, we tested belief in the false claims. Respondents were presented with eight statements: four about immigration and, to disguise our intent somewhat, four distractor items about issues like fracking and plastic bag usage. Two statements were common misperceptions among immigration critics ("There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years., and "European immigrants receive more in benefits and services than they pay in taxes."). The other two were common misperceptions among pro-immigration respondents ("The majority of crimes in London are committed by white people, not ethnic minorities."; "Immigration to the UK does not affect the wages of the low-paid.") Respondents rated each claim on a seven-point scale from definitely true to definitely false. We used the true-false labelling (rather than, say, an agree-disagree scale) to encourage respondents to see these as matters of fact rather than opinion, and  a scale rather than a binary ('true' v. false) question to allow respondents to indicate not just their assessment of those statements but also their confidence in their own assessment. The repetition captures how far that confidence is affected by a fact-check and its subsequent undermining. 

**Stage 2** was a fact-check contradicting the false immigration claim that they had rated closest to Definitely true. If two or more items were tied, we randomly assigned respondents to one of the relevant fact-checks. That means that the specific information received at this stage depended on the answers at Stage 1. We attributed all four fact-checks to the same (fictional) person. The introduction read, We have asked Richard Clarke, Professor of Economics at the University of Oxford to provide us with information about the statements you just read. We chose a generic British name and a photo of an austere, nondescript, middle-aged man in front of a blackboard. We gave him impressive credentials to boost his authority: a PhD from Harvard University and consultancy for the Office of National Statistics, a body widely trusted in Britain (Morgan 2019). The content of the fact-checks was based on real statistics and mimicked the general approach of fact-checking sites such as Full Fact.  

At **Stage 3**, the sample was split. Treatment-group respondents (75%) were presented with a message undermining the factual correction while the control group (25%) skipped directly to Stage 4. The undermining message was introduced as a comment on that information from a different source.' It was attributed to 'David Williams', an avuncular, grey-haired man wearing a beret and holding a cigar. (To avoid confounding effects of age, ethnicity, or gender we chose pictures of middle-aged white men for both the expert and the commentator.) Williams was described either as a Retired Professor at the London School of Economics (high authority) or as a Blogger (low authority).

In a 3 x 2 design among treatment-group respondents, we varied both the content of the message and the authoritativeness of the source. The statement always started with the words, I would take these statistics with a big pinch of salt. The variations that followed were designed to capture the three mechanisms described earlier. While they are more formal in tone than the example tweets quoted at the outset, they deploy very similar undermining narratives: 

*Expert bias*: 'The fact that someone is a professor doesnt mean that they dont have an agenda. And we all know that there is a lot of scope to choose and present statistics so that they end up saying just what you want them to say.' 

*Invoking personal experience*: 'A graph might say one thing but the experience of peoples everyday lives could be quite different. And I think that a lot of people reading those statistics will say: that doesnt sound like the world I live in.'

*Truthiness*: 'Theres so much information and so many statistics out there that it can be hard to know what to believe. In that case, I think its best to trust your instincts even if it looks as if the facts are different.'

At **Stage 4** all respondents were asked to rate the corrected claim again on the seven-point true-to-false scale. The difference between these ratings and the pre-correction ratings is the main quantity of interest in our analysis. This stage also included three questions examining why the more resistant respondents blocked out the information from the fact-check and gauging whether these strategies were encouraged by the undermining challenges. Here, we were particularly interested in whether there were signs of reasoning that might be deemed post-truth: that is, evidence that people who were wrangling over the facts would question whether there was such a thing as a fact. First, we asked respondents to rate each of the two (false) statements on a 0-6 scale from Purely a matter of fact to Purely a matter of opinion. Next, we asked whether respondents thought that the statistics that the fact-checker had provided were consistent with what they had believed beforehand. Those answering No were then asked to choose which of three statements best described their position: a) The statistics are probably right but I believe something different; b) I think that the statistics are wrong; or c) The statistics made me change my mind. Then, in perhaps the most direct approach to post-truth thinking, we asked whether respondents agreed or disagreed with the general proposition that It is OK to disagree with the facts if thats what you believe. All these questions were asked of both treatment and control group respondents. 

Finally, we asked two questions about the source of the factual correction (the Oxford professor) and, where applicable, parallel questions about the source of the undermining message (the LSE professor or the blogger): how much respondents trusted the sources, and how much they trusted their information. 

Participation in this study took just over 5 minutes on average; respondents were remunerated according to Deltapoll's standard practice. Participation was strictly voluntary; respondents were asked for consent and could withdraw at any time. The fact-checks were factually accurate; the only deception we used was to attribute the fact-checks, as well as the undermining messages to fictional people. 

# Results {.unlisted .unnumbered}

Before reporting our results, we should note two points about our approach and its implications for those results. The first concerns asymmetries in the sample in terms of overall preferences about immigration and in terms of prior belief in the false claims. In line with other surveys, there was variation in overall preferences but a discernible skew towards preferences for a reduction in immigration to the UK (@Schwartz2021). About a third (32%) were content with current levels, about half (47%) preferred fewer, and about a fifth (21%) preferred more immigrants. Unsurprisingly, the false anti-immigration claims were more widely believed and, therefore, more often provided the basis for fact-checking. They were also more strongly believed. Almost half of those who were directed to an expert challenging one of the two anti-immigration claims had initially rated the respective claim as definitely true (44% of those who learned about the number of asylum seekers, 49% of those who learned about the cost of immigration). This was true of just 30% of those who were directed to an expert challenging one of the two pro-immigration claim (26% of those who learned about crime in London and 34% who read about low-paid wages). 
<!-- The summary statistics in table 1 in the Appendix breaks down preferences about immigration by corrected statement. -->

The second, related point is a cautionary note about the motivations that respondents brought to the treatments. The statements that were corrected were chosen based on specific beliefs rather than underlying ideology or motivations. Our design assumes that those who were most sceptical of immigration would believe most strongly in one of the false anti-immigration claims, and the reverse would be true of pro-immigration respondents. This was mostly but not always the case. 
Overall, just under half of our pooled sample (47%) were directed to a fact-check that challenged a statement on their side of the immigration debate, a fifth (21%) were directed to one that challenged a statement on the other side of the immigration debate, and a third (32%) took no clear side, neither wanting to increase or decrease immigration. Importantly for our purposes, these numbers differed considerably across the four fact-checks: 
<!-- Most of those who saw a fact-check challenging a claim on their side saw an anti-immigration fact-check:  -->
Of those directed to one of the two anti-immigration fact-checks, 62% had expressed anti-immigration views (25% neutral, 14% pro). In contrast, of those directed to one of the two pro-immigration fact-checks, only 33% had expressed pro-immigration opinions (45% neutral, 22% anti).  Given the difficulty of accepting evidence that challenges ones partisan or group identity this means that our anti-immigration sample had a stronger motivation to reject the evidence [@Lodge2013; @Kahan2017c; @NyhanReifler2019]. 
<!-- ^[Among those who said Britain should take in more immigrants, 58% rated a (false) pro-immigration claim closest to true and saw it fact-checked. (The remaining 42% rated a (false) anti-immigration claim closest to true and, therefore, saw a fact-check that was on their side.) Among those who said Britain should take in fewer immigrants, 83% rated a (false) anti-immigration claim closest to true and saw it fact-checked. The remaining 17% rated a (false) pro-immigration claim closest to true and therefore saw a fact-check that was on their side.) Among those who were happy with current levels of immigration, 50% rated a pro-immigration claim closest to true; and 50% rated an anti-immigration claim closest to true.)].  -->

<!-- The full breakdown of prior perceptions and immigration attitudes in each fact check group is reported in the online appendix.  -->

Of course, preferences on immigration numbers are not a perfect measure of underlying attitudes and not a robust basis on which to discard part of the sample at the outset. It is safer simply to bear in mind that our full-sample analyses make for a a conservative test of the effect of that undermining challenge, because of this hefty chunk of the sample that had a weaker incentive to respond to it.


```{r descriptives, warning = FALSE, message = FALSE, echo = FALSE}

library(dplyr)
# prop.table(table(df$immigOpinions3))
# table(df$proOrAnti, df$immigOpinions)

# round(prop.table(table(noAsylum$immigOpinions)), 2)
# round(prop.table(table(costImmig$immigOpinions)), 2)
# round(prop.table(table(whiteCrime$immigOpinions)), 2)
# round(prop.table(table(lowPaid$immigOpinions)), 2)

x <-
df %>%
  group_by(whichFactCheck, immigOpinions) %>%
  dplyr::summarise(count = n()) %>%
  dplyr::mutate(freq = round(count / sum(count), 3)) 
  # arrange(desc(freq))

y <- 
df %>%
  group_by(whichFactCheck, immigImportance) %>%
  dplyr::summarise(count = n()) %>%
  dplyr::mutate(freq = round(count / sum(count), 3))

z <- 
df %>%
  group_by(whichFactCheck, belief_num_T1) %>%
  dplyr::summarise(count = n()) %>%
  dplyr::mutate(freq = round(count / sum(count), 3))
```


\newpage

## Effects of the fact-check and the undermining message {.unlisted .unnumbered}

```{r mean_T1_T2_by_PTC, warning = FALSE, message = FALSE, echo = FALSE, fig.height=6, fig.cap="Average assessment of the false claims by exposure to an undermining message. Mean and 95% confidence intervals."} 

# calculate the mean and the 95% confidence intervals for the mean 
# https://rpubs.com/techanswers88/MeanAndConfidenceIntervals

mean_T1_T2_by_PTC <-
df_long %>%
  group_by(comment2, time) %>%
  dplyr::summarise(n = n(),
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>%
  as.data.frame()  %>%
  
  ggplot(aes(x=time, 
             y=mean,
             fill=time)) +
  stat_summary(fun = mean, # OLD: fun.y ## `fun.y` is deprecated. Use `fun` instead. 
               geom = "bar",
               position="dodge",
               color="black",
               size=.8) +
  # stat_summary(fun.data = mean_cl_normal,
  #              geom = "errorbar",
  #              position = position_dodge(width = .9),
  #              width = .2
  # ) +
  facet_grid(. ~ comment2) +
  coord_cartesian(ylim=c(0,6)) +
  # scale_y_continuous(breaks=seq(0,6,1)) + # tick every point
  scale_y_continuous(breaks=seq(0,6,1),
                     labels=c("0" = "0 - Definitely true",
                              "1" = "1",
                              "2" = "2",
                              "3" = "3",
                              "4" = "4",
                              "5" = "5",
                              "6" = "6 - Definitely false")
  ) +
  geom_abline(slope=0, intercept=3,  col = "black", lty=2) +
  scale_x_discrete(labels=c("T1" = "Before ",
                            "T2" = "After")) +
  scale_fill_manual(name = "",
                    labels = c("Before fact check",
                               "After fact check"),
                    # values=c("#c8c3cc", "#563f46")
                    values=c("#bdbdbd", "#636363") # twoDarkGreys 
  ) + 
  geom_errorbar(aes(ymin=lower_ci, ymax= upper_ci),
                width = 0.4, 
                color ="black", 
                size = .8) +
  geom_text(aes(label=round(mean, 2), # paste(round(mean*100,0),'%'),
                group=time),
            position = position_dodge(width = .9),
            # hjust=1,
            vjust=2,  # inside bars
            color="white", # #252525
            size=6) +
  labs(title="", 
       subtitle = "", 
       x="", 
       y="") +
  theme_minimal() + # theme_light
  theme(text = element_text(size=16),
        axis.text = element_text(size=16),
        plot.title = element_text(hjust = 0.5, color = "#666666"),
        plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
        legend.position = 'top', 
        legend.text = element_text(size = 16),
        strip.text.x = element_text(size = 16), # panel label size
        # axis.text.y = element_blank(), # remove y axis labels
        axis.ticks = element_blank())


print(mean_T1_T2_by_PTC) 
ggsave("mean_T1_T2_by_PTC.png",  width = 35,  height = 20,  units = "cm")

```


As anticipated in H1, our fact-checks did indeed significantly reduce belief in false claims. Figure 9 in the appendix shows that all four corrections had roughly similar effects, which warrants our reporting analyses pooling across the four in the remainder of this article. Those pooled data for the control group are shown at the left-hand side of Figure 2 ('No undermining message'), which shows mean assessments of the respondents key claim (on the 0-6 scale from Definitely true to Definitely false) before and after the authoritative correction. On average, the fact-checks shifted respondents about 1.7 points closer to the false end of the scale, from 1.11 (i.e., barely a point above 0  definitely true) to 2.81 (i.e., almost reaching the mid-point of the scale, as denoted by the dotted line.) This result  the experts fact-checks having considerable impact but leaving plenty of people unconvinced  tallies with the findings of partial success reported earlier from past research. Indeed, given that this was a one-shot challenge of factual beliefs about a politicised issue that engaged strong attitudes, a shift of 1.7 points on a seven-point scale is on the large side relative to previous studies [@Walter2020].

Our key questions are: was that success undermined by post-truth rhetoric and, if so, how far? Comparing the control group and treatment group responses reveals clear support for H2. Exposure to an undermining message did indeed offset a significant chunk of the positive effect of the fact-check. Among treatment group respondents recommended to take those statistics with a pinch of salt, the fact check did have an effect but moved respondents only 1.24 along the scale (from 1.09 to 2.33, as shown at the right-hand side of Figure 2). If this 1.24 is compared to the 1.70-point effect among control group respondents, we can say that the undermining message undid almost a third (1-1.24/1.70, or 27%) of the fact-check effect. The difference between these mean shifts is statistically significant (t(1088)=5.53, p<0.01) and moderate in size by conventional yardsticks, amounting to around a quarter of a standard deviation (Cohens d=0.26). Effect size is partly a matter of interpretation and expectations, however, and in the concluding discussion we assess whether this is a strikingly high or reassuringly low impact of the undermining message.  

These mean differences conceal instructive information about the impact of the fact checks and the subsequent undermining messages. In either case, it could be that a few peoples minds are changed completely while others remain unmoved, or that most people are nudged along the scale by the evidence and arguments. Comparing the top two panels of Figure 3 shows that fact-checks had a particularly pronounced effect on the share of respondents who thought the false statements were definitely true: this halved from 40 per cent (before the fact-check) to 19 per cent (after the fact-check) among the control group who offer our pure test of the effect of the fact-check. Around one in six respondents (17%) were so convinced by the expert fact-check that they re-rated the false claim as 6 - definitely false. If we then compare the bottom two panels (both after the fact-check), we can see the effect of exposure to a message from another professor, or a blogger saying they would 'take those statistics with a pinch of salt'. 
<!-- an undermining message.  -->
The most notable difference is that proportion of the convinced, which was just 7% among those who had seen one of these undermining messages. 
<!-- in the treatment groups.  -->
It is also noteworthy that that the treatment did not send respondents all the way back to Definitely true. The effect of post-truth rhetoric was not to instil conviction but rather to encourage doubt and tilt respondents back towards their original belief. 

$$\\[0.1cm]$$ 

```{r hist_three_in_one, warning = FALSE, message = FALSE, echo = FALSE, fig.height=8, fig.cap="Assessment of the false facts along the full 0-6 scale: pre-treatment (all respondents); post-treatment (control group); post-treatment (treatment group)."} 

# Create 3 graphs

# Panel 1: Control, before
# Panel 2: Control, after
# Panel 3: Treatment, after

df_panel1 <- 
df %>%
  filter(RandomGrp %in% c(1, 2)) %>% 
  group_by(belief_num_T1) %>% 
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(percent = n / sum(n)) %>%
  as.data.frame() 

# Add a row for 6 - definitely false
new_row = list(belief_num_T1=6, n=0, percent = 0)
df_panel1 = rbind(df_panel1, new_row)

panel1 <- 
df_panel1 %>%
  ggplot(aes(x=factor(belief_num_T1),
             y=percent)) +
  geom_bar(stat="identity",
           position = "dodge",
           color = "black",
           fill = "#f0f0f0"
  ) +
  scale_x_discrete(
    labels=c("0" = "0 true",
             "1" = "1",
             "2" = "2",
             "3" = "3",
             "4" = "4",
             "5" = "5",
             "6" = "6 false")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
  theme_minimal() +
  ylim(0, 0.45) + 
  coord_cartesian(ylim=c(0, 0.46)) +
  labs(
    title = "",
    subtitle = "", 
    x="",
    y="") +
  theme(legend.position = 'none', # top
        text = element_text(size=16),
        axis.text.x = element_text(size=16), 
        plot.title = element_text(hjust = 0.5), # , color = "#666666"
        axis.text.y = element_blank(), # remove y axis labels
        axis.ticks = element_blank() # remove y axis ticks
  ) +
  geom_text(aes(label=paste(round(percent*100,0),'%')), 
            vjust=-0.3, # outside bars
            # vjust=1.6,  # inside bars
            color="#666666", 
            size=6) 

panel2 <-
  df  %>%
  filter(treated==0) %>% 
  group_by(belief_num_T2) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(percent = n / sum(n)) %>%
  as.data.frame() %>%
  ggplot(aes(x=factor(belief_num_T2),
             y=percent)) +
  geom_bar(stat="identity",
           position = "dodge",
           color = "black",
           fill = "#bdbdbd"
  ) +
  scale_x_discrete(
    labels=c("0" = "0 true",
             "1" = "1",
             "2" = "2",
             "3" = "3",
             "4" = "4",
             "5" = "5",
             "6" = "6 false")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
  theme_minimal() +
  ylim(0, 0.45) + 
  coord_cartesian(ylim=c(0, 0.46)) +
  labs(
    title = "",
    subtitle = "", 
    x="",
    y="") +
  theme(legend.position = 'none', # top
        text = element_text(size=16),
        axis.text.x = element_text(size=16), 
        plot.title = element_text(hjust = 0.5), # , color = "#666666"
        axis.text.y = element_blank(), # remove y axis labels
        axis.ticks = element_blank() # remove y axis ticks
  ) +
  geom_text(aes(label=paste(round(percent*100,0),'%')), 
            vjust=-0.3, # outside bars
            # vjust=1.6,  # inside bars
            color="#666666", 
            size=6) 


panel3 <-
  df  %>%
  filter(treated==1) %>% 
  group_by(belief_num_T2) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(percent = n / sum(n)) %>%
  as.data.frame() %>%
  ggplot(aes(x=factor(belief_num_T2),
             y=percent)) +
  geom_bar(stat="identity",
           position = "dodge",
           color = "black",
           fill = "#636363"
  ) +
  scale_x_discrete(
    labels=c("0" = "0 true",
             "1" = "1",
             "2" = "2",
             "3" = "3",
             "4" = "4",
             "5" = "5",
             "6" = "6 false")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
  theme_minimal() +
  ylim(0, 0.45) + 
  coord_cartesian(ylim=c(0, 0.46)) +
  labs(
    title = "",
    subtitle = "", 
    x="",
    y="") +
  theme(legend.position = 'none', # top
        # legend.text = element_text(size = 16),
        text = element_text(size=16),
        # strip.text.x = element_text(size = 16), # panel label size
        axis.text.x = element_text(size=16), 
        axis.text.y = element_blank(), # remove y axis labels
        plot.title = element_text(hjust = 0.5), # , color = "#666666"
        axis.ticks = element_blank() # remove y axis ticks
  ) +
  geom_text(aes(label=paste(round(percent*100,0),'%')), 
            vjust=-0.3, # outside bars
            # vjust=1.6,  # inside bars
            color="#666666", 
            size=6) 


# Arrange 3 plots in 1 graph

library(ggpubr)

plot1 <- panel1 + theme(legend.position="left")+
  labs(title="Control group before fact check")
plot2<- panel2 + theme(legend.position="left")+
  labs(title="Control group after fact check")
plot3 <- panel3 + theme(legend.position="left")+
  labs(title="Treatment group after fact check and undermining message")

hist_three_in_one <-
ggarrange(plot1,plot2,plot3,
          common.legend=TRUE,
          hjust=-0.8,
          ncol = 1, 
          nrow = 3)

print(hist_three_in_one) 
ggsave("hist_three_in_one.png",  height = 20,  units = "cm")

```

One of the points we raised at the outset of the results section concerned the tendency for anti-immigration beliefs to be more strongly held. Consistent with that, those who had seen an anti-immigration claim corrected in a fact-check were more sympathetic to the undermining challenge. Among this group, 31% of the effect of the fact-check was undone. This proportion was down to 19% among the smaller group who had seen a pro-immigration claim corrected. This gap largely reflects differences in the strength of prior perceptions. As shown in Figure 9 in the appendix, those seeing one of the anti-immigration claims corrected started out with somewhat stronger misperceptions on average, hovering around 1 on the 0 (true) - 6 (false) scale (0.9 and 1.1, respectively), while those seeing one of the two pro-immigration claims corrected started with an average of 1.2 and 1.5, respectively. That means that our anti-immigration sample had more incentive to follow the lead of the person encouraging them to take those statistics with a pinch of salt. There is a subsidiary point about political context here. An anti-immigration opinion corrected by an academic statistician more closely reflects the nature of an EU referendum campaign in which, as illustrated by the earlier quote from Michael Gove, the notion of expertise became discursively associated with the immigration-friendly Remain side and hence more often questioned by immigration-sceptic Leave campaigners and voters. The content of the undermining challenge, pointing to biased academics, noting that the official information did not match thheir personal experience, or encouraging people to trust their instincts more the statistics is probably more familiar and more popular with those who would like to reduce immigration. 

<!-- As shown in Figure 9 in the appendix, those seeing one of the anti-immigration claims corrected started out with somewhat stronger misperceptions on average, and so had more incentive to return in that direction when encouraged to do so by the undermining narrative. There is a subsidiary point about political context here. An anti-immigration opinion corrected by an academic statistician more closely reflects the nature of an EU referendum campaign in which, as illustrated by the earlier quote from Michael Gove, the notion of 'expertise' became discursively associated with the Remain side and hence more often questioned by immigration-sceptic Leave campaigners and voters. The content of the undermining challenge is probably more familiar and more popular with those who would like to reduce immigration.  -->

The second point is to reiterate that these figures represent a conservative estimate of the effect of these undermining messages because of that one fifth of the sample whose most confident false belief ran against the grain of their immigration preferences. Those respondents had more incentive to embrace the fact-check information as a congenial surprise, and less incentive to respond to the undermining message. If they (and a few more who did not see immigration as an important issue) are removed from the sample, the countering effect of that undermining message among those remaining (n=2054) rises to 29% overall (31 and 32% in the anti-immigration sample; 19 and 29% in the pro-immigration sample, as shown in Figure 10 in the Appendix).

<!--  If they (and a few more who did not see immigration as an important issue) are removed from the sample, the countering effect of that undermining message among those remaining (n=2054) rises to 29%. (In the Appendix, we zoom in on the effect of the undermining message for the motivated in each fact check group.)  -->

Interestingly, however, this same sub-sample whose immigration preferences gave them a reason to reject the facts and accept the challenge was *not* more likely to reject the initial fact-check. They moved 1.67 points closer to 'false' after seeing the statistics (from 0.91 to 2.58)  only marginally below (and not statistically significantly different from) the 1.7-point shift in the full sample. In other words, the more motivated were just as ready to listen to the expert when he had the final word but, when he was challenged, they were particularly inclined to return to their initial belief. This is an important insight both for psychologists studying motivated reasoning and for fact-checkers. 

```{r what % of the effect was cancelled out?, warning = FALSE, message = FALSE, echo = FALSE, results='hide', fig.show='hide'} 
# Effect of the comment in the whole sample

df_long %>%
  # filter(m2r_imp==1) %>%
  group_by(whichFactCheck, comment2, time) %>%
  dplyr::summarise(n = n(),
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>%
  as.data.frame()  

# noAsylum
# No comment: 3.0807018-1.0982456 = 1.982456
# Comment: 2.3535354-0.9685746 = 1.384961
# 1-1.384961/1.982456 = 0.3013913
# --> The comment cancelled out 30% of the effect of the fact-check.

# costImmig
# No comment: 2.4696133-0.9116022 = 1.558011
# Comment: 1.9788868-0.9616123 = 1.017275
# 1-1.017275/1.558011 = 0.3470682
# --> The comment cancelled out 35% of the effect of the fact-check.

# whiteCrime
# No comment: 2.9343066-1.3211679 = 1.613139
# Comment: 2.6676385-1.4635569 = 1.204082
# 1-1.204082/1.613139 = 0.2535783
# --> The comment cancelled out 25% of the effect of the fact-check.

# lowPaid
# No comment: 2.5895522-1.1940299 = 1.395522
# Comment: 2.4481982-1.2094595 = 1.238739
# 1-1.238739/1.395522 = 0.2922863
# --> The comment cancelled out 11% of the effect of the fact-check.




# Effect of the comment in a subset of respondent who were:

# m2r 

df_long %>%
  # filter(m2r_imp==1) %>%
  filter(m2r==1) %>%
  group_by(comment2, time) %>%
  dplyr::summarise(n = n(),
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>%
  as.data.frame()  

# m2r_imp USE THIS
# No comment: 2.5838150-0.9113680   = 1.672447
# Comment: 2.1114007-0.9211726 = 1.190228
# 1-1.190228/1.672447 = 0.2883314
# --> # --> Among the m2r_imp, the comment cancelled out 29% of the effect of the fact-check. 


# m2r
# No comment: 2.6156584-0.9537367 = 1.661922
# Comment: 2.1610018-0.9677996 = 1.193202
# 1-1.193202/1.661922 = 0.2820349
# --> Among the m2r, the comment cancelled out 28% of the effect of the fact-check.

# Pro/anti-immigration

df_long %>%
  # filter(m2r_imp==1) %>%
  group_by(proOrAnti, comment2, time) %>%
  dplyr::summarise(n = n(),
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>%
  as.data.frame()  

# Anti
# No comment: 2.8433476-1.0257511 = 1.817597
# Comment: 2.2152975-0.9660057 = 1.249292
# 1-1.249292/1.817597 = 0.3126683
# --> Among the anti-immig, the comment cancelled out 31% of the effect of the fact-check.

# Pro 
# No comment: 2.7638376-1.2583026 = 1.505535
# Comment: 2.5438374-1.3202033 = 1.223634
# 1-1.223634/1.505535 = 0.1872431
# --> Among the anti-immig, the comment cancelled out 19% of the effect of the fact-check.

# Each statement -- ONLY looking at the m2r
df_long %>%
  filter(m2r_imp==1) %>%
  group_by(whichFactCheck, comment2, time) %>%
  dplyr::summarise(n = n(),
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>%
  as.data.frame()  

# noAsylum
# No comment: 2.7330097-0.8446602 = 1.88835
# Comment: 2.1185647-0.8081123 = 1.310452
# 1-1.310452/1.88835 = 0.3060333
# --> Among those motivated to reject the fact-check on the noAsylum statement, the comment cancelled out 31% of the effect of the fact-check.

# costImmig
# No comment: 2.2740741-0.7777778 = 1.496296
# Comment: 1.7087629-0.6932990 = 1.015464
# 1-1.015464/1.496296 = 0.3213482
# --> Among those motivated to reject the fact-check on the costImmig statement, the comment cancelled out 32% of the effect of the fact-check.

# whiteCrime
# No comment: 2.7708333-1.1354167 = 1.635417
# Comment: 2.5092593-1.3518519 = 1.157407
# 1-1.157407/1.635417 = 0.2922863
# --> Among those motivated to reject the fact-check on the costImmig statement, the comment cancelled out 29% of the effect of the fact-check.

# lowPaid
# No comment: 2.5000000-1.0365854 = 1.463415
# Comment: 2.3379310-1.1551724 = 1.182759
# 1-1.182759/1.463415 = 0.2922863
# --> Among those motivated to reject the fact-check on the costImmig statement, the comment cancelled out 19% of the effect of the fact-check.

```

## Effect of an undermining message by source and content {.unlisted .unnumbered}

```{r coefficient plots all DVs, echo=FALSE, fig.cap=" Effect of the undermining message on the effect of the fact-check.", fig.height=8, message=FALSE, warning=FALSE}

cm <- c("(Intercept)" = "(Intercept)",
        "source2Blogger"= "Source: Blogger",
        "message2Personal experience" = "Message: Personal experience",
        "message2Expert bias" = "Message: Expert bias", 
        "treatmentProfessor: Expert bias"= "Professor: Expert bias",
        "treatmentProfessor: Personal experience" = "Professor: Personal experience",
        "treatmentProfessor: Truthiness" = "Professor: Truthiness",
        "treatmentBlogger: Expert bias"= "Blogger: Expert bias", 
        "treatmentBlogger: Personal experience" = "Blogger: Personal experience",
        "treatmentBlogger: Truthiness" = "Blogger: Truthiness",
        "genderFemale" = "Female",
        "socialGradeC1" = "Social grade C1",
        "socialGradeC2" = "Social grade C2", 
        "socialGradeDE" = "Social grade DE",
        "age" = "Age",
        "generation2Gen Z (1997-2012)" = "Gen Z (1997-2012)",
        "generation2Gen X (1965-80)" = "Gen X (1965-80)",
        "generation2Baby boomers (1946-64)" = "Baby boomers (1946-64)", 
        "generation2Silent generation (1928-45)" = "Silent generation (1928-45)",       
        "attentionCategoryLow (0-2)" = "Political attention (low)",
        "attentionCategoryHigh (8-10)" = "Political attention (high)",
        "brexitleave" = "Voted to leave the EU",
        "immigOpinions_num" = "Support immigrantion",
        "immigImportance_num" = "Importance of immigration",
        "leftright_num" = "left-right ideology",
        "populism_scale" = "Populism scale",
        "ethno_scale" = "Nationalism scale"
)

# Effect of each of the 6 treatments

ols_belief_T2 <- lm(belief_num_T2 ~ treatment, data=df)
ols_diff <- lm(diff ~ treatment, data=df)

ols_accurateExpert <- lm(accurateExpert_num ~ treatment, data=df)
ols_trustExpert <- lm(trustExpert_num ~ treatment, data=df)

ols_factOpinion <- lm(factOpinion_num ~ treatment, data=df)
ols_ok2disagree <- lm(ok2disagree_num ~ treatment, data=df)

logit_sth_different <- glm(believeSomethingDifferent ~ treatment, data=df, family = "binomial")
# summary(logit_sth_different)

# Tidy

ols_belief_T2 <- tidy(ols_belief_T2) %>% filter(term != "(Intercept)") %>% mutate(model = "Belief in false claims after exposure to a fact-check, scale from 0 (definitely true) to 6 (definitely false)\n")
ols_diff <- tidy(ols_diff) %>% filter(term != "(Intercept)") %>% mutate(model = "Difference in belief  before and after exposure to a fact-check, scale from -6 (not convinced) to 6 (convinced)\n")

ols_accurateExpert <- tidy(ols_accurateExpert) %>% filter(term != "(Intercept)") %>% mutate(model = "Perceived accuracy of the expert's information, scale from 1 (not at all) to 4 (very accurate)\n")
ols_trustExpert <- tidy(ols_trustExpert) %>% filter(term != "(Intercept)") %>% mutate(model = "General trust in what the expert says about immigration, scale from 0 (not at all) to 6 (a great deal)\n")

ols_factOpinion <- tidy(ols_factOpinion) %>% filter(term != "(Intercept)") %>% mutate(model = "'Matter of opinion.' OLS regression model, scale from 0 (purely a matter of fact) to 6 (purely a matter of opinion)\n")
ols_ok2disagree <- tidy(ols_ok2disagree) %>% filter(term != "(Intercept)") %>% mutate(model = "'OK to disagree with the facts.' OLS regression model, scale from 1 (strongly agree) to 4 (strongly disagree)\n")

logit_sth_different <- tidy(logit_sth_different) %>% filter(term != "(Intercept)") %>% mutate(model = "'The statistics are probably right but I believe something different.' Logit model.'\n)") # other choices: 'I think that the statistics are wrong.', 'The statistics made me change my mind.


coef_data <- rbind(ols_diff, ols_accurateExpert)

coef_plot <-
  dwplot(coef_data, 
         # dot_args = list(aes(shape=model), size = 5),
         dot_args = list(size = 5),
         whisker_args = list(size = 2), 
         line_args = list(alpha = 0.75),
         vline = geom_vline(xintercept = 0, 
                            colour = "grey60", 
                            linetype = 2),
         dodge_size = 0.7
  ) %>% # plot line at zero _behind_ coefs
  relabel_predictors(cm) + 
  xlim(-1, 1) + 
  theme_bw() + 
  scale_color_grey(labels=function(x) str_wrap(x, width = 30)) + # set legend label width
  # scale_y_discrete(labels = function(x) str_wrap(x, width = 12)) + # set y axis label width
  theme(legend.position = "top",
        # legend.position = "right",
        text=element_text(size=15),
        axis.text = element_text(size=15),
        legend.title = element_blank(),
        legend.text = element_text(size=15),
        panel.border = element_blank(),
        axis.ticks = element_blank()
        ) + 
  labs(
    title = '',
    subtitle = "",
  y="",
  x="\nEffect of exposure to an undermining message") +  
  guides(color=guide_legend(nrow=1, byrow=F))
  
print(coef_plot) # saved 1000
ggsave("coef_plot.png")
```

The next step is to compare the arguments that convinced some respondents to dismiss or at least to doubt the fact-check. Were all three effective? Were some more effective than others? The respective answers, based on Figure 4, are 'yes' and 'not really'. The figure shows coefficients from OLS regression models estimating the effect of exposure to any of the six versions of the undermining message. (Full model results are reported in the appendix.) The first estimate in each pair (printed in black) is the key measure testing H2: how far does the undermining message shift ratings of the original belief on the true-false scale (relative to the control group who see only the fact check)? Scores are negative here because those messages move respondents down the scale towards 0 ('definitely true') and centred around -0.46 which was the average difference among the whole sample. The scores actually vary rather little around that -0.46. All the messages tested undermined a statistically significant chunk of the effect of the fact-check but there is no significant difference by message content. There is some sign that invoking personal experience is least effective and claiming expert bias is most effective, but the differences are small. Whether comparing pairs of the means in Figure 4 or collapsing across sources for an overall ANOVA test of the effect of challenge message, there is no route to a statistically significant result. 

There is another null finding, contrary to H2a, when it comes to the source of the non-factual challenge. Only on one of the three messages ('Personal Experience') was there even a sign of the professor carrying more weight. It may be that the authoritativeness of the source matters less when the content is more 'everyman': no expertise is required to tell people to trust their experience and instincts (and not much is required to know that professors may be biased!). In any case, an uncharitable summary is that respondents clutched at any straw they were offered, by whomever, to discredit statistics challenging their views.

The second estimate in each pair (printed in grey) bears on one potential mechanism through which these challenges could work: by undermining trust in the fact-checker and his evidence. Here, we present evidence from the question asking about the perceived accuracy of the experts information. The pattern is similar (see table 3 in the Supporting Information) if we look instead at more general trust in that expert. That pattern is that, while post-truth rhetoric did leave a small dent in trust in the fact-checker and his information, the effect was relatively small and not always statistically significant at conventional levels. This is consistent with another point which is that, even in the treatment groups, trust in the fact-checker and his information remained on the trusting side of the scale  and significantly higher than trust in the post-truth commentator and their information. 
<!-- DO WE NEED TO SHOW EVIDENCE FOR THAT IN THE APPENDIX? -->

<!-- That pattern is that, while post-truth rhetoric did leave a small dent in the perceived accuracy of the correction, the effect was relatively small and not always statistically significant at conventional levels. This is consistent with another point which is that, even in the treatment groups, trust in the fact-checker and his information remained on the trusting side of the scale  and significantly higher than trust in the post-truth commentator and their information.  -->

# Effect of an undermining message on post-truth reasoning {.unlisted .unnumbered}

```{r hist_factOpinion_2, warning = FALSE, message = FALSE, echo = FALSE, fig.height=5, fig.cap="Assessment of the corrected statements on a fact-opinion scale by exposure to an undermining message."} 

# Responses to the question of whether the corrected statement was closer to a matter of fact or a matter of opinion

twoDarkGreys <- c("#bdbdbd", "#636363")

## new new including CIs

total_n <- df %>% filter(complete.cases(df$factOpinion)) %>% dplyr::summarise(n = n()) %>% as.numeric()
fourGreys <-  c("#f7f7f7", "#cccccc", "#969696", "#525252")

hist_factOpinion_2 <-
  df %>%
  filter(complete.cases(df$factOpinion),
         complete.cases(df$comment2))  %>%
  group_by(comment2, 
           factOpinion) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(
    percent = n / sum(n),
    # total_n = 1337, # total number of people who answered the question
    # alpha = 0.05, # # Set CI alpha level
    # z = qnorm(1-alpha/2), # Calculate the critical z-score # 1.959964
    upperinterval = percent + 1.959964*sqrt(percent*(1-percent)/total_n),
    lowerinterval = percent - 1.959964*sqrt(percent*(1-percent)/total_n)
    ) %>%
  as.data.frame()  %>%
  
  ggplot(aes(x=factor(factOpinion),
             y=percent,
             ymin = lowerinterval,
             ymax = upperinterval,
             fill=comment2)) +
  geom_bar(position = "dodge",
           stat="identity",
           colour="#252525",
           # show.legend = FALSE
           ) +
  geom_errorbar(position = position_dodge(.9),
                width = 0.2, 
                color="#252525")  +
  # facet_wrap(.~comment , 
  #            ncol = 1) + 
  coord_cartesian(ylim=c(0, 0.35)) +
  geom_text(aes(label=paste(round(percent*100,0),'%'),
                group=comment2),
            position = position_dodge(width = .9),
            # hjust=1,
            vjust=3,  # inside bars
            color="white", # #252525
            size=4.5) +
    labs(
    x="",
    y="") +
    scale_x_discrete(name = "",
                     labels=c("0 - Purely a matter of fact" = "0 \nPurely \na matter \nof fact",
                            "1" = "1",
                            "2" = "2",
                            "3" = "3",
                            "4" = "4",
                            "5" = "5",
                            "6 - Purely a matter of opinion" = "6 \nPurely \na matter \nof opinion")) +
  scale_fill_manual(name="",
                    values = twoDarkGreys) + 
  theme_minimal() +
  theme(legend.position='top') + 
  theme(text = element_text(size=16),
        axis.text.x = element_text(size=16),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

print(hist_factOpinion_2) # saved 900
ggsave("hist_factOpinion_2.png",  width = 40,  units = "cm") # height = 20,  

```

How can we reconcile respondents drift back to their original belief after exposure to the  undermining message and their reluctance to dismiss the fact-check and its source? One possibility is that the effect of post-truth rhetoric is to encourage people to believe that both that original belief and the (intended to be) contradictory fact check can be correct  or, at least, are both reasonable points of view. This brings us neatly to H3 and the notion that the treatments encouraged a post-truth mindset. The first test is via that scale asking respondents to locate their key claim on a scale from 'purely a matter of fact' to purely a matter of opinion. We asked this question at the end of the survey. Figure 5 shows that there is very little sign of the undermining narratives nudging respondents up the scale to the latter view. Combining points 4, 5 and 6 on the scale, we can see that about one third reported that the statements were on balance a matter of opinion  but then this was also true among control group respondents in whose case the expert had had the final word. Clearly, as in the examples cited earlier from the 2018 Pew survey many citizens habitually regard political claims as opinions [@Mitchell2018]. 

```{r hist_ifInconsistent_2, warning = FALSE, message = FALSE, echo = FALSE, fig.height=5, fig.cap="Responses to the question of where respondents stood by exposure to an undermining message.'"} 

# 'Respondents who noted that the statistics were not consistent with what they believed (57% of the control group, 53% of the treatment groups) were asked which of these three options best described where they stood.

hist_ifInconsistent_2 <-
  df %>%
  filter(complete.cases(df$ifInconsistent),
         complete.cases(df$comment2))  %>%
  group_by(comment2, ifInconsistent) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(
    percent = n / sum(n),
    # total_n = 1337, # total number of people who answered the question
    # alpha = 0.05, # # Set CI alpha level
    # z = qnorm(1-alpha/2), # Calculate the critical z-score # 1.959964
    upperinterval = percent + 1.959964*sqrt(percent*(1-percent)/total_n),
    lowerinterval = percent - 1.959964*sqrt(percent*(1-percent)/total_n)
    ) %>%
  as.data.frame()  %>%
  
  ggplot(aes(x=factor(ifInconsistent),
             y=percent,
             ymin = lowerinterval,
             ymax = upperinterval,
             fill=comment2)) +
  geom_bar(position = "dodge",
           stat="identity",
           colour="#252525",
           # show.legend = FALSE
           ) +
  geom_errorbar(position = position_dodge(.9),
                width = 0.2, 
                color="#252525")  +
  # facet_wrap(.~comment , 
  #            ncol = 1) + 
  # coord_cartesian(ylim=c(0, 0.3)) +
  geom_text(aes(label=paste(round(percent*100,0),'%'),
                group=comment2),
            position = position_dodge(width = .9),
            # hjust=1,
            vjust=4,  # inside bars
            color="white", # #252525
            size=8) +
    labs(
    x="",
    y="") +
    scale_x_discrete(name = "",
                     labels=c("The statistics are probably right but I believe something different." = 
                                "The statistics are probably right \nbut I believe something different.",
                              "I think that the statistics are wrong." =  
                                "I think that the statistics \nare wrong. ",
                              "The statistics made me change my mind." = 
                              "The statistics made me \nchange my mind.")
                     ) +
  scale_fill_manual(name="",
                    values = twoDarkGreys) + 
  theme_minimal() +
  theme(legend.position='top') + 
  theme(text = element_text(size=20),
        axis.text.x = element_text(size=16),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())


print(hist_ifInconsistent_2)
ggsave("hist_ifInconsistent_2.png",  width = 35, height = 15,  units = "cm") # height = 20, 

# Old Version -- No CIs
# hist_ifInconsistent <-
#    df %>%
#   filter(complete.cases(df$ifInconsistent),
#          complete.cases(df$message3))  %>%
#   group_by(message3, 
#            ifInconsistent) %>%
#   dplyr::summarise(n = n()) %>%
#   dplyr::mutate(percent = n / sum(n)) %>%
#   as.data.frame() %>%
#   
#   ggplot(aes(x=factor(message3),
#              y=percent,
#              fill=ifInconsistent)) +
#   geom_bar(stat="identity",
#            position = "dodge",
#            color = "black"
#   )  + 
#   coord_cartesian(ylim=c(0, 0.6)) +
#   geom_text(aes(label=paste(round(percent*100,0),'%'), group=ifInconsistent), 
#             position = position_dodge(width = .9),
#               vjust=-0.3, # outside bars
#               # vjust=1.6,  # inside bars
#               color="#666666", 
#               size=5) + 
#   labs(
#     x="",
#     y="") +
#   scale_fill_manual(name="",
#                     labels = c("I think the statistics \nare wrong.",
#                                "The statistics are probably right \nbut I believe something different.","The statistics made me \nchange my mind."),
#                     values=threeGreys # twoReds 
#   ) + 
#   scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
#   theme_minimal() +
#   theme(legend.position='top',
#         text = element_text(size=20),
#         axis.text.x = element_text(size=16),
#         axis.title.y=element_blank(),
#         axis.text.y=element_blank(),
#         axis.ticks.y=element_blank())
# 
# print(hist_ifInconsistent)
# ggsave("hist_ifInconsistent.png")

# Add CIs
# Confidence Interval = (point estimate)+/-(critical value)*(standard error)
# Confidence Interval = p  +/-  z*(p(1-p) / n)

# 95% Confidence Interval for Proportions in R
# https://stats.stackexchange.com/questions/207807/95-confidence-interval-for-proportions-in-r
# https://www.r-bloggers.com/2021/11/calculate-confidence-intervals-in-r/

# find total number of people who answered the question
total_n <- df %>%
  dplyr::filter(complete.cases(df$ifInconsistent)) %>%
  dplyr::summarise(n = n()) %>% as.numeric()

library(dplyr)
library(ggplot2)
# total_n <- 1337
  
# https://colorbrewer2.org/#type=sequential&scheme=Greys&n=5

threeLightGreys <- c("#f7f7f7", "#cccccc", "#969696")

hist_ifInconsistent <-
  df %>%
  filter(complete.cases(df$ifInconsistent),
         complete.cases(df$message3))  %>%
  group_by(message3, 
           ifInconsistent) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(
    percent = n / sum(n),
    # total_n = 1337, # total number of people who answered the question
    # alpha = 0.05, # # Set CI alpha level
    # z = qnorm(1-alpha/2), # Calculate the critical z-score # 1.959964
    upperinterval = percent + 1.959964*sqrt(percent*(1-percent)/total_n),
    lowerinterval = percent - 1.959964*sqrt(percent*(1-percent)/total_n)
    ) %>%
  as.data.frame()  %>%
  
  ggplot(aes(x=factor(ifInconsistent),
             y=percent,
             fill=ifInconsistent
             )) +
  # geom_bar(stat="identity",
  #          position = "dodge",
  #          color = "black"
  # )  + 
  geom_bar(stat="identity", 
           colour="#252525",
           show.legend = FALSE) + 
  facet_wrap(.~message3 , 
             ncol = 4) + 
  geom_errorbar(aes(ymin = lowerinterval, 
                    ymax = upperinterval), 
                width = 0.2, 
                color="#252525") +
  coord_cartesian(ylim=c(0, 0.6)) +
  geom_text(aes(label=paste(round(percent*100,0),'%'), 
                group=ifInconsistent), 
            position = position_dodge(width = .9),
            # vjust=-0.3, # outside bars
            vjust=4,  # inside bars
            color="#252525", 
            size=6) + 
  labs(
    x="",
    y="") +
  scale_fill_manual(name="",
                    values=threeLightGreys # twoReds 
  ) + 
  scale_x_discrete(labels=c("Believe \nsome-\nthing \ndifferent",
                            "Statistics \nare \nwrong",
                            "Changed \nmy \nmind")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme_light() + # theme_minimal() +
  theme(# legend.position='bottom', 
        text = element_text(size=21),
        panel.grid.major = element_blank(), 
        axis.text.x = element_text(size=13), 
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

# print(hist_ifInconsistent)
# ggsave("hist_ifInconsistent.png",  width = 35,  height = 20,  units = "cm")

# setwd("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/workingData/") 

```


Next, we asked respondents whether the statistics they had seen were consistent with what they had believed. Despite the fact that the fact check statistics were explicitly presented as contradicting respondents initial beliefs, only 46% said No. That subset of respondents was then presented with three statements about this contradiction and asked to pick the one that best described where they stood. Again, the control group results are striking. Even without any post-truth nudge, the most common response (36%) was simply to assert that the experts statistics were wrong (see Figure 6). Less than a third (32%) said that the statistics had led them to change their mind. Exposure to an undermining message did have a significant impact on responses (${\chi}^2$(2)=24.4, p<.001), increasing the share of respondents who dismissed the statistics as wrong and reducing the share of respondents who reported changing their mind. Interestingly, however, those messages did not lead respondents to endorse the post-truth compromise position that, while the statistics were probably right, they believed something different. There was some support for this position (despite its aroma of alternative facts) but it was not encouraged by undermining messages, whose effect was instead to trigger rejection of the statistical evidence.

```{r hist_ok2disagree, warning = FALSE, message = FALSE, echo = FALSE, fig.height=5, fig.cap="Agreement that Its OK to disagree with the facts if thats what you believe by exposure to an undermining message."} 

# INCLUDING NUMBERS ON DODGED BAR PLOT
# https://stackoverflow.com/questions/6017460/position-geom-text-on-dodged-barplot

total_n <- df %>% filter(complete.cases(df$ok2disagree)) %>% dplyr::summarise(n = n()) %>% as.numeric()
fourGreys <-  c("#f7f7f7", "#cccccc", "#969696", "#525252")

hist_ok2disagree <-
  df %>%
  filter(complete.cases(df$ok2disagree),
         complete.cases(df$comment2))  %>%
  group_by(comment2, 
           ok2disagree) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::mutate(
    percent = n / sum(n),
    # total_n = 1337, # total number of people who answered the question
    # alpha = 0.05, # # Set CI alpha level
    # z = qnorm(1-alpha/2), # Calculate the critical z-score # 1.959964
    upperinterval = percent + 1.959964*sqrt(percent*(1-percent)/total_n),
    lowerinterval = percent - 1.959964*sqrt(percent*(1-percent)/total_n)
    ) %>%
  as.data.frame()  %>%
  
  ggplot(aes(x=factor(ok2disagree),
             y=percent,
             ymin = lowerinterval,
             ymax = upperinterval,
             fill=comment2)) +
  geom_bar(position = "dodge",
           stat="identity",
           colour="#252525",
           # show.legend = FALSE
           ) +
  geom_errorbar(position = position_dodge(.9),
                width = 0.2, 
                color="#252525")  +
  # facet_wrap(.~comment , 
  #            ncol = 1) + 
  coord_cartesian(ylim=c(0, 0.53)) +
  # geom_label(
  #   aes(label = paste(round(percent*100,0),'%'),
  #       group=comment), 
  #   position = position_dodge(width = .9),
  #   # hjust = 2, 
  #   vjust = 2.5, 
  #   # nudge_x = -.5,
  #   size = 4, 
  #   fontface = "bold", 
  #   # ## turn into white box without outline
  #   fill = "white", 
  #   label.size = 0
  # ) +
  geom_text(aes(label=paste(round(percent*100,0),'%'),
                group=comment2),
            position = position_dodge(width = .9),
            # hjust=1,
            vjust=2,  # 3
            color="white", # #252525
            size=5) + # 6.5
  labs(
    x="",
    y="") +
  scale_fill_manual(name="",
                    # labels = c("I think that the \nstatistics are wrong.",
                    #            "The statistics are \nprobably right but \nI believe something \ndifferent.",
                    #            "The statistics made \nme change my mind."),
                    values=twoDarkGreys # twoReds 
  ) + 
  theme_minimal() +
  theme(legend.position='top', # top
        text = element_text(size=16),
        # panel.grid.major = element_blank(), # remove panel grid
        axis.text.x = element_text(size=16),
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

print(hist_ok2disagree)
ggsave("hist_ok2disagree.png",  width = 35,  height = 20,  units = "cm")

```

Figure 7 shows reactions to the final indicator, the statement that "Its OK to disagree with the facts if that's what you believe." There is a hint that the undermining challenge nudged respondents into agreement with that statement but the difference is just a few percentage points and the chi-squared test for the overall comparison falls well short of significance (${\chi}^2$(3)=4.4, p=.22).
One reason may be that almost two thirds of our control group sample (64 per cent) agreed or strongly agreed with the statement. What we had envisaged as a rather controversial claim, that respondents would need to be talked into by the undermining challenge, turned out to be a commonplace view. Throughout this section, the degree to which even the control group agreed with post-truth-flavoured statements far exceeded our expectations  and rather limits the scope for treatment group respondents to agree even more strongly. 

Finally, we test whether these largely null findings conceal at least some differences across the narratives in their capacity to prompt post-truth reasoning. Figure 8 shows the effect of exposure to each of the three undermining messages on the three key post-truth outcomes analysed above. In the case of the two scales (see Figures 5 and 7), the plot shows the OLS coefficient estimating the effect of the treatment on the mean response. With the categorical outcome variable (Figure 6), we estimate a logistic model and plot the treatment effect on the predicted probability of choosing the post-truth flavoured option The statistics are probably right but I believe something different. For the most part, the nulls persist, and there is little sign of differences across the three treatment narratives. The only exception is that exposure to the 'Truthiness message had a significant but, contrary to our expectations, negative effect on the probability of choosing that but I believe something different option. However, this is really just a restatement of this treatments especially positive effect on the probability of responding that the statistics are wrong (Figure 6), a rather less post-truth-flavoured conclusion.

$$\\[0.2cm]$$

```{r coefficient plots post truth DVs, warning = FALSE, message = FALSE, echo = FALSE, fig.height=7, fig.cap="Effect of the undermining message on post-truth reasoning."} 

# OLS regression models. The black coefficients show results from OLS regression models estimating the effect of exposure to one of the three messages on respondents' perceptions of factualness (7-point scale ranging from categorising the statement as '0 - purely a matter of fact' to '6 - purely a matter of opinion. The dark grey coefficients show results from OLS regression models estimating the effect on agreement that it is 'OK to disagree with the facts' (4-point scale from '1 - strongly agree' to  '4 strongly disagree'. The light grey coefficients show results from a logit model estimating the effect on the probability of choosing the option 'The statistics are probably right but I believe something different' to explain why the statistics respondents saw were inconsistent with what they had believed.

# Effect of the 3 messages on 3 indicators of post-truth reasoning

ols_messages_factOpinion <- lm(factOpinion_num ~ message, data=df) 
ols_messages_ok2disagree <- lm(ok2disagree_num ~ message, data=df)
logit_messages_sth_different <- glm(believeSomethingDifferent ~ message, data=df, family = "binomial")
# summary(logit_messages_sth_different)

# Tidy

ols_messages_factOpinion <- tidy(ols_messages_factOpinion) %>% filter(term != "(Intercept)") %>% mutate(model = "'Matter of opinion'. OLS regression model, scale from 0 (purely a matter of fact) to 6 (purely a matter of opinion)") 
ols_messages_ok2disagree <- tidy(ols_messages_ok2disagree) %>% filter(term != "(Intercept)") %>% mutate(model = "'OK to disagree with the facts'. OLS regression model, scale 1 (strongly agree) to 4 (strongly disagree)")
logit_messages_sth_different <- tidy(logit_messages_sth_different) %>% filter(term != "(Intercept)") %>% mutate(model = "'The statistics are probably right but I believe something different.' Logit model.')") # other choices: 'I think that the statistics are wrong.', 'The statistics made me change my mind.


# with controls
# logit_sth_different <- glm(believeSomethingDifferent ~ message + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale, data=df, family = "binomial")


# coef_data_post_truth_dvs <- rbind(ols_factOpinion, ols_ok2disagree)
coef_data_post_truth_dvs <- rbind(ols_messages_factOpinion, ols_messages_ok2disagree, logit_messages_sth_different)


coef_plot_post_truth_dvs <-
  dwplot(coef_data_post_truth_dvs, 
         # dot_args = list(aes(shape=model), size = 5),
         dot_args = list(size = 5),
         whisker_args = list(size = 2), 
         line_args = list(alpha = 0.75),
         vline = geom_vline(xintercept = 0, 
                            colour = "grey60", 
                            linetype = 2),
         dodge_size = 0.7
  ) %>% # plot line at zero _behind_ coefs
  # relabel_predictors(cm) + 
  relabel_predictors(
    "messageExpert bias" = "Expert bias", 
    "messagePersonal experience" = "Personal experience", 
    "messageTruthiness" = "Truthiness"
  ) + 
  xlim(-1, 1) + 
  theme_bw() + 
  scale_color_grey(labels=function(x) str_wrap(x, width = 25)) +
  theme(legend.position = "top",
        text=element_text(size=15),
        axis.text = element_text(size=15),
        legend.text = element_text(size=15),
        legend.title = element_blank(),
        panel.border = element_blank(),
        axis.ticks = element_blank()
        ) + 
  labs(
    title = '',
    subtitle = "",
  y="",
  x="\nEffect of exposure to an undermining message") +
  guides(color=guide_legend(nrow=1, byrow=F))

print(coef_plot_post_truth_dvs)
ggsave("coef_plot_post_truth_dvs.png") # 1300 
```

# Concluding discussion {.unlisted .unnumbered}

From one perspective, the results presented here are reassuring. Evidence from experts is usually heard, even if counter-framed by those seeking to undermine it. Fact-checks made some respondents abandon and many others at least feel less confident in their misperceptions. This was true even of a case like immigration, where many people had strong motivations -- rooted in ideology and identity -- to reject the factual correction. Given the importance of priors in information processing, we would not expect one piece of information to catapult people from one pole of the scale to the other. If a fact-check instead persuades people that they may not be as well informed as they thought, and perhaps induces them to seek out more information, then its work is well done. 

Even where respondents were not just internally motivated but also externally encouraged to reject the fact-check, much of the work of fact-checking remained intact. The percentage of that work undone by a non-factual challenge varied somewhat by subsample but was never more than around one third. Even given a face-saving and cognitively easy excuse to ignore the fact-check, many did not do so. This is in stark contrast to one study we cited when the counter-information eliminated all positive effects of the factual treatment [@VanderLinden2017]. One possible reason for the difference is that their dependent variable -- perceptions of elite consensus on climate change  mattered less to respondents and so was more malleable. Another is that their countering treatment invoked scientific claims in a way that ours  intentionally  did not. 

But there is a less optimistic reading of our results. It begins by emphasising that we gave more weapons to one side in our experiment. The undermining challenges were much briefer than the fact-checks and contained no graphical or supporting information. They were just a one-shot intervention from a lightly-credentialled individual. This is probably a bigger threat to external validity than the similarly one-shot nature of the fact-checks. In the real world, factual corrections -- whether from fact-checkers, news articles or other sources -- are often the single interventions then greeted with a chorus of disapproval along the lines of our non-factual challenges and the illustrative tweets that opened the article. Such 'pile-ons' are a reminder that public opinion is the product of social forces [@Zaller1992]. The undermining chorus will often involve some combination of like-minded politicians, commentators, friends, and family  more trusted than the unknown challenger in our experiment. Our fact-checker was in that sense a more realistic representative of his real-world equivalent than was his subsequent challenger. If one such undermining intervention can overcome nearly one third of a fact-check's effect, perhaps a flurry of interventions could eliminate it entirely.

When the scenario is extended like that, another of our findings -- that all three of the undermining messages had a significant effect -- becomes more pertinent. The flurry of challenges to a fact-check is likely to include attacks from all sides, including the three mechanisms that we tested here. They may appeal to different audiences but, judging by these results, they all have an audience. However, it is hard here to adjudicate between two possibilities: the content of the message matters and all three worked; or the content of the message matters less than its presence. There is indirect support from the latter in the null finding on the source of the undermining message. It seems that some respondents needed very little encouragement to disregard unwelcome information. It just needed someone -- anyone -- to suggest that the statistics should be rejected. That said, we could have tested this 'source irrelevance' hypothesis rather further because, while post-experimental analysis did (mercifully) show appreciable gaps in trust and accuracy between the blogger and the professor, the formers ratings were still quite high in absolute terms. Future research ought to test the effect of undermining messages by individuals who are more clearly non-authoritative -- perhaps someone who openly claims that they have never investigated the statistics.

Among the limitations of our study, one prominent point is the difficulty of interpreting those responses that we suggested had a flavour of post-truth reasoning. Prima facie, the fact that two thirds of British adults agree that "it is OK to disagree with the facts if thats what you believe" looks like a ringing endorsement of Yuval Noah Hararis [-@Harari2018] claim that humans are a post-truth species. Yet they must be taken in context. Respondents had been shown a factual correction of a statement that they had expressed strong belief in and quite possibly held dear. This provided an unusually strong incentive to agree with that statement. (Had the fact-check been designed to confirm respondents beliefs, they may have answered the follow-up question about disagreeing with the facts very differently.) It also raises a question about what respondents read into disagree with the facts. A recurring feature of misperceptions research is that, even when corrections change beliefs, they are unlikely to change underlying attitudes (e.g., @Hopkins2019). If respondents interpreted this statement as "it is OK to maintain your overall opposition to (support for) immigration even if this particular negative (positive) belief about immigration was wrong", then there is much less of a post-truth flavour to their responses.

Even with these caveats, though, the proportions agreeing with those statements -- presumably in the face of social desirability pressures pushing the other way -- are striking enough to justify a research programme that defines and measures the tendency to post-truth reasoning. This is related to but different from the standard 'belief in science' measures. To provide a more nuanced understanding of general acceptance of post-truth arguments, future research ought to investigate post-truth thinking in different contexts, following welcome information, unwelcome information, or no information at all. Given the likely importance of social and ideological networks in vindicating such thinking, future experimental work could usefully gauge the impact of undermining messages such as ours when made by people with strong co-identities and shared group memberships. 

# Acknowledgements {.unlisted .unnumbered}

This work was supported by the British Academy [SRG\\171311]. The data and analysis underpinning this article will be available via [link blinded for review]. 
<!-- https://github.com/cstedtnitz.  -->
The authors declare no competing interests.  

<!-- deception? -->

<!-- Data Availability Statement -->
<!-- The data and analysis underpinning this research note will be available via [repository and link to be provided prior to publication]. -->

<!-- Supplementary Material -->
<!-- Supplementary material has been submitted with this research note to be hosted on the Cambridge platform. -->

<!-- Competing Interests -->
<!-- The authors declare none. -->


\newpage

# References {.unlisted .unnumbered}

<div id="refs"></div>

\newpage

# Supporting Information {.unlisted .unnumbered}

<!-- \pagenumbering{arabic} -->

\setcounter{page}{0}
<!-- \pagenumbering{Roman} -->
<!-- \singlespacing -->
<!-- \onehalfspacing -->

\tableofcontents

\newpage

# Appendix A - Summary statistics

```{r summary stats using tableby, caption = 'Summary statistics by corrected statement', warning = FALSE, message = FALSE, echo = FALSE, results="asis"}

# Tablyby tables: https://cran.r-project.org/web/packages/arsenal/vignettes/tableby.html#modify-how-missing-values-are-displayed

library(arsenal)
require(knitr)

attr(df$gender,'label')  <- 'Gender'
attr(df$age,'label')  <- 'Age'
attr(df$region,'label')  <- 'Region'
attr(df$leftright3,'label')  <- 'Left/Right Ideology'
attr(df$immigOpinions3,'label')  <- 'Immigration Preferences'

tab1 <- tableby(whichFactCheck_long ~ 
                gender + age + region + leftright3 + immigOpinions3, 
                data=df,
                digits=0, 
                digits.pct=0,
                test=FALSE,
                control=tableby.control(numeric.stats=c("mean", "range"), # "Nmiss2", # median
                                        total=FALSE))
summary(tab1, title='Demographics')


```

```{r treatment groups using tableby, caption = 'Summary statistics by corrected statement', warning = FALSE, message = FALSE, echo = FALSE, results="asis"}

library(arsenal)
require(knitr)

attr(df$treatment,'label')  <- 'Treatment Group'

tab2 <- tableby(whichFactCheck_long ~ 
                  treatment, 
                data=df,
                digits=0, 
                digits.pct=0,
                test=FALSE,
                control=tableby.control(numeric.stats=c("mean", "range"), # "Nmiss2", # median
                                        total=FALSE))
summary(tab2, title='Treatment Groups')

```


```{r, include=FALSE}
# ```{r summary stats using tbl_summary, caption = 'Summary statistics by corrected statement', warning = FALSE, message = FALSE, echo = FALSE}

# Summary table
# https://cran.r-project.org/web/packages/gtsummary/vignettes/tbl_summary.html

library(tidyverse) # for read_csv
library(broom)
library(dplyr)
library(knitr)
library(modelsummary) # for msummary
# library(kableExtra) # for msummary
library(gt) # for msummary
library(flextable) # to knit to word
library(dotwhisker)
library(gtsummary)

df %>%
  filter(complete.cases(gender)) %>%
  select(whichFactCheck_long, # whichFactCheck_lbl trt
         gender,
         age,
         # generation, # ageCategory,
         region,
         # householdIncome,
         # socialGrade,
         # marital,
         # university,
         leftright3,
         # vote2017,
         immigOpinions3 # immigOpinions,
         # immigImportance3,
         # immigFeelLikeHome,
         # immigOpinions3, # immigEcon
         # brexitVote
         # politicalAttention
         ) %>%
  gtsummary::tbl_summary(by = "whichFactCheck_long") %>%
  modify_caption("Summary statistics.") %>%
  # tbl_summary(by = "treatment") %>%  # uncomment to split up by treatment
  add_overall()  %>%
  modify_header(label ~ "**Variable**") %>%
  bold_labels()

```

<!-- \newpage -->

<!-- # Number of respondents in each treatment group  {.unlisted .unnumbered} -->

```{r, include=FALSE}
# ```{r treatment groups using tbl_summary, caption = 'Number of respondents in each treatment group', warning = FALSE, message = FALSE, echo = FALSE}

# Summary table
# https://cran.r-project.org/web/packages/gtsummary/vignettes/tbl_summary.html

df %>%
  select(whichFactCheck_long, treatment) %>%
  tbl_summary(by = "whichFactCheck_long") %>%
  modify_caption("Treatment Groups.") %>%
  # tbl_summary(by = "treatment") %>%  # uncomment to split up by treatment
  add_overall()  %>%
  modify_header(label ~ "**Variable**") %>%
  bold_labels()

```

\newpage

# Appendix B - Full Results 

<!-- ## Effect of the four fact-checks on belief in false claims  -->

Figure 9 shows how the four fact-checks affected belief each of the four false claims. To simplify comparisons we use the length of a line to illustrate how far respondents moved in their accuracy perceptions after they saw a fact-check. The grey dots show how true or false they rated the respective false claim when they first saw it at the beginning of the survey. The orange dots show how true or false they rated the respective false claim at the end of the survey, after they had seen a fact-check (and, if treated, an undermining message). Accuracy ratings are shown on a seven-point scale from 0 (Definitely true) to 6 (Definitely false). 
^[Note that the original scale (as shown in the questionnaire) ranged from 0 (Definitely false) to 6 (Definitely true). For ease of interpretation we re-coded it as 0 (Definitely true) to 6 (Definitely false).)] 
The grey lines connecting the grey and orange dots show how much closer they moved to the 'false' end of the scale. The longer the line the more respondents changed their mind after seeing the statistics. 

The pattern is similar: For each line, the top line (showing those who saw the additional undermining message) is shorter than the bottom line (showing those who saw the fact-check only). In other words, the undermining message always cancelled out some of the effect of the fact-check. *How much* it cancelled out was different for each comment:

The first panel shows respondents who rated the false statement that "There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years" closest to true and, therefore, were directed to a fact-check showing statistics on the number of asylum seekers coming into the UK. This fact-check shifted average accuracy ratings 1.98 points closer to the 'false' end of the scale (from 1.1 to 3.08) or, if accompanied by an undermining message, 1.38 points closer to 'false' (from 0.97 to 2.35). Overall, then, the undermining message cancelled out 30% (1-1.38/1.98) of the effect of the fact-check about the number of asylum seekers.

The second panel shows respondents who rated the false statement that "Immigrants receive more in benefits and services than they pay in taxes" closest to true and, therefore, were directed to a fact-check showing statistics on the net fiscal contributions of European immigrants and native British citizens. This fact-check shifted average accuracy ratings 1.61 points closer to the 'false' end of the scale (from 1.32 to 2.93) or, if accompanied by an undermining message, 1.2 points closer to 'false' (from 1.46 to 2.67). Overall, then, the undermining message cancelled out 25% (1-1.2/1.6) of the effect of the fact-check about the number of asylum seekers.

The third panel shows respondents who rated the false statement that "The majority of crimes in London are committed by white people, not ethnic minorities" closest to true and, therefore, were directed to a fact-check showing statistics on minority populations and minority proportions for offenders and victims of various types of reported crime in London. This fact-check shifted average accuracy ratings 1.61 points closer to the 'false' end of the scale (from 1.32 to 2.93) or, if accompanied by an undermining message, 1.20 points closer to 'false' (from 1.46 to 2.67). Overall, then, the undermining message cancelled out 25% (1-1.2/1.61) of the effect of the fact-check about crime in London.

The fourth panel shows respondents who rated the false statement that "Immigration to the UK does not affect the wages of the low-paid" closest to true and, therefore, were directed to a fact-check showing statistics on the effect of immigration on hourly wages for workers employed in the semi- and unskilled services in the UK. This fact-check shifted average accuracy ratings 1.4 points closer to the 'false' end of the scale (from 1.19 to 2.59) or, if accompanied by an undermining message, 1.24 points closer to 'false' (from 1.21 to 2.45). Overall, then, the undermining message cancelled out 11% (1-1.24/1.4) of the effect of the fact-check about the number of asylum seekers.


<!-- For each statement, the top panel shows average 'true' to 'false' ratings among those who saw a fact-check followed by an undermining message; the bottom panel shows ratings among those who saw the fact check only. The grey dots (and corresponding values) show average ratings at the beginning of the survey; the orange dots shows average ratings at the end of the survey, i.e. after respondents read the fact check and, if treated, the undermining message.  -->
<!-- The pattern is similar: Each of the four fact checks reduced belief in the false claims, shifting average perceptions from just above Definitely true (between 0.9 and 1.3) to just below the mid-point of the scale (between 2.5 and 3.1). This was true for fact checks correcting anti-immigration statements (the first two statements) and fact checks correcting pro-immigration statements (the last two statements).  -->


```{r each_statement_cleveland_plot_by_comment, warning = FALSE, message = FALSE, echo = FALSE, fig.height=8, fig.cap="Average belief in false facts before and after exposure to a fact-check."} 

library(dplyr)
library(tidyr)
library(ggplot2)

# removed pooled_cleveland_plot

# Average belief in false facts before and after exposure to a fact check. The top panel shows respondents who skipped the post-truth comment; the bottom panel shows respondents who saw it.

each_statement_cleveland_data_by_comment <- 
  df %>%
  group_by(comment2, whichFactCheckTxt) %>%
  dplyr::summarise(
    m_before = mean(belief_num_T1, na.rm = T),
    m_after = mean(belief_num_T2, na.rm = T)
  ) %>%
  ungroup() %>% 
  gather(key = "key", value = "value", -comment2, -whichFactCheckTxt) %>% 
  separate(col = "key",
           into = c("statistic", "time"),
           sep = "_") %>%
  as.data.frame() %>%
  spread(key = "statistic",
         value = "value") %>%
  mutate(time = factor(time, levels = c("before", "after")))

# How to place labels next to points
# https://uc-r.github.io/cleveland-dot-plots

before_label <- each_statement_cleveland_data_by_comment %>%
  filter(time=='before') %>%
  group_by(comment2) %>%
  select(comment2, whichFactCheckTxt, m, time)

after_label <- each_statement_cleveland_data_by_comment %>%
  filter(time=='after') %>%
  group_by(comment2) %>%
  select(comment2, whichFactCheckTxt, m, time)


each_statement_cleveland_plot_by_comment <-
  each_statement_cleveland_data_by_comment %>%
  ggplot(aes(x=m, 
             y=factor(comment2, level = c("No undermining message", "Undermining message"))
  )) + 
  facet_wrap(~whichFactCheckTxt, ncol=1) + 
  geom_line(aes(group = comment2)) +
  geom_point(aes(colour = time, 
                 fill="white", size=4)) + 
  geom_text(data = before_label, aes(m, color=time, label = round(m, 2)),
            size = 5, hjust = 2) +  # -.5
  geom_text(data = after_label, aes(m, color=time, label = round(m, 2)),
            size = 5, hjust = -1.5) + # 1.5
  scale_color_manual(values = c("#999999", "#E69F00"),
                     labels = c("Before exposure to the fact check", "After exposure to the fact check")) +
  ylab("") +
  scale_x_continuous(
    name = "\nPerceived veracity", 
    limits = c(0, 6.5),
    breaks = seq(0, 6, by = 1),
    labels=c(
      "0" = "0 \nDefinitely \ntrue",
      "1" = "1",
      "2" = "2",
      "3" = "3", # "Don't know",
      "4" = "4",
      "5" = "5",
      "6" = "6 \nDefinitely \nfalse"),
    expand = c(0.02, 0)
  ) + 
  geom_vline(xintercept = 3, 
             alpha = .3,
             linetype="dotted", 
             color = "grey", 
             size=2) +
  theme_minimal() +
  guides(size = FALSE, fill=FALSE, alpha=FALSE) + 
  theme(axis.title = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        #legend.justification = c(0, 1), 
        #legend.position = c(.1, 1.075),
        legend.position = "bottom",
        legend.background = element_blank(),
        legend.direction="horizontal",        
        text = element_text(size=14), # family = "Arial", 
        plot.title = element_text(size = 20, margin = margin(b = 10)),
        plot.subtitle = element_text(size = 10, color = "darkslategrey", margin = margin(b = 25)),
        plot.caption = element_text(size = 10, margin = margin(t = 10), color = "grey70", hjust = 0)
        )

print(each_statement_cleveland_plot_by_comment)
ggsave("each_statement_cleveland_plot_by_comment.png") # 1600*1400
```

<!-- \newpage -->

<!-- The bar plots in Figure 9 show how the four fact-checks affected belief in the four false claims in the control group. (Note that the original scale ranged from 0 (Definitely false) to 6 (Definitely true). For ease of interpretation we re-coded it as 0 (Definitely true) to 6 (Definitely false).) The pattern is similar: Each of the four fact checks reduced belief in the false claims, shifting average perceptions from just above 'Definitely true' to just below the mid-point of the scale. This was true for fact checks correcting anti-immigration statements and fact checks correcting pro-immigration statements. -->

```{r, mean_T1_T2_by_type, include=FALSE}

# ```{r mean_T1_T2_by_type, warning = FALSE, message = FALSE, echo = FALSE, fig.height=7, fig.cap="Mean belief in false claims before and after exposure to a fact check by corrected statement. Control group respondents (n=737)."} 

#### Means -- Belief at T1 and T2 ####

# Means

my_plot_mean_T1_T2 = function(x, y, z) {
  ggplot(x, # df_long, 
         aes(.data[[y]], # comment // time
             .data[[z]], # belief 
             fill = .data[[y]] # time # fill=time
         )) +
    stat_summary(fun = mean,  
                 geom = "bar",
                 position="dodge",
                 color="black") +
    stat_summary(fun.data = mean_cl_normal,
                 geom = "errorbar",
                 position = position_dodge(width = .9),
                 width = .2
    ) +
    coord_cartesian(ylim=c(0,6)) +
    # scale_y_continuous(breaks=seq(0,6,1)) + # tick every point
    scale_y_continuous(breaks=seq(0,6,1),
                       labels=c("0" = "0 - Definitely true",
                                "1" = "1",
                                "2" = "2",
                                "3" = "3",
                                "4" = "4",
                                "5" = "5",
                                "6" = "6 - Definitely false")
    ) +
    geom_abline(slope=0, intercept=3,  col = "black", lty=2) +
    scale_x_discrete(labels=c("T1" = "Before",
                              "T2" = "After")) +
    scale_fill_manual(name = "", 
                      labels = c("Before fact check",
                                 "After fact check"),
                      values= c("#f0f0f0", "#bdbdbd")) + # twoBlues
    labs(title="", # Effect of the fact check on belief in false claim
         # subtitle = "", # Control group respondents
         x="", 
         y="") +
    theme_minimal() + # theme_light
    theme(text = element_text(size=16),
          axis.text.x = element_text(size=14),  # 16
          axis.text.y = element_text(size=14), 
          plot.title = element_text(hjust = 0.5, color = "#666666"),
          plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
          legend.position = 'top', 
          # axis.text.y = element_blank(), # remove y axis labels
          axis.ticks = element_blank())
}

mean_T1_T2 <- 
  my_plot_mean_T1_T2(df_long_ctrl, "time",  "belief_num") #+ coord_flip()

# print(mean_T1_T2)
ggsave("mean_T1_T2.png")


mean_T1_T2_by_type <- 
my_plot_mean_T1_T2(df_long, "time", "belief_num") +
  facet_grid(. ~ whichFactCheckTxt, labeller = labeller(whichFactCheckTxt = label_wrap_gen(width = 15))) 

print(mean_T1_T2_by_type) 
ggsave("mean_T1_T2_by_type.png") 
```


```{r, warning = FALSE, message = FALSE, echo = FALSE}

# Failed attempts to number the figures:
# https://stackoverflow.com/questions/38861041/knitr-rmarkdown-latex-how-to-cross-reference-figures-and-tables
# https://datascienceplus.com/r-markdown-how-to-number-and-reference-tables/
# Regular expressions: https://cran.r-project.org/web/packages/stringr/vignettes/regular-expressions.html 
# Using captioner: https://cran.r-project.org/web/packages/captioner/vignettes/using_captioner.html 

table_captions <- captioner::captioner(prefix="Table")
figure_captions <- captioner::captioner(prefix="Figure")

t.ref <- function(label){
  stringr::str_extract(table_captions(label), "[^:]*")
}

f.ref <- function(label){
  stringr::str_extract(figure_captions(label), "[^:]*")
}

```

```{r, hist_T1_T2_all, include=FALSE}

# ```{r hist_T1_T2_all, warning = FALSE, message = FALSE, echo = FALSE, fig.height=5, fig.cap="Belief in false claims before and after exposure to a fact check. All control group respondents (n=737)."} 

my_hist_T1_T2_pc = function(x) {
    df %>% 
    filter(whichFactCheck %in% x & 
             RandomGrp %in% c(1, 2)) %>% 
    select(belief_num_T1, belief_num_T2 ) %>% 
    gather(key=time, value=score) %>% 
    dplyr::count(time, score) %>%
    group_by(time) %>% 
    dplyr::mutate(
      total=sum(n),
      percent = n/sum(n), 
      score=as.character(score),
      time = recode(time, 
                    belief_num_T1 = "Before",
                    belief_num_T2 = "After"),
      time_2 = factor(time, levels=c('Before', 'After'))
    ) %>%
    ggplot(aes(x=score, # factOpinion
               y=percent, # freq
               fill=time)) + # NEW
    geom_bar(stat="identity",
             position=position_dodge(),
             color="black"
             # fill="steelblue"
    ) +
    geom_bar(stat="identity",
             position=position_dodge(),
             color="black"
    ) +
    facet_grid(time_2 ~ .) +
    coord_cartesian(ylim=c(0, 0.6)) +
    scale_fill_manual(# name="",
      # labels=c("Before fact check", 
      #         "After fact check"), 
      values= c("#bdbdbd", "#f0f0f0")) + # twoLightGreys) + # twoBlues
    labs(
      # title = "Belief in false facts before and after exposure to a fact check", 
      # subtitle = "Control group respondents",
      x="",
      y="") +
    scale_x_discrete(labels=c("0" = "0 \nDefinitely \ntrue",
                              "1" = "1",
                              "2" = "2",
                              "3" = "3",
                              "4" = "4",
                              "5" = "5",
                              "6" = "6 \nDefinitely \nfalse")) +
    # scale_y_continuous(breaks=seq(0, 50, 10)) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
    # scale_y_continuous(labels=scales::percent) +
    theme_minimal() +
    theme(text = element_text(size=14),
          axis.text.x = element_text(size=14),  # 16
          plot.title = element_text(hjust = 0.5, color = "#666666"),
          plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
          legend.position = 'none', 
          axis.text.y = element_blank(), # remove y axis labels
          axis.ticks = element_blank() # remove y axis ticks
    ) +
    # geom_text(aes(label=round(percent*100, 0)), # percentages inside bars
    #           vjust=2) 
    geom_text(aes(label=paste(round(percent*100,0),'%')), 
              vjust=-0.3, # outside bars
              # vjust=1.6,  # inside bars
              color="#666666", 
              size=6) # 3.5 
}

hist_T1_T2_all <- 
  my_hist_T1_T2_pc(c("noAsylum", "costImmig", "whiteCrime", "lowPaid"))

# print(hist_T1_T2_all)
ggsave("hist_T1_T2_all.png")

```

```{r noAsylumHistogram, warning = FALSE, message = FALSE, echo = FALSE, fig.height=3.5, fig.cap=noAsylum_lbl}

# Control group respondents who saw a fact check challenging the statement that 'There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years.' (n=285)

# ```{r my_hist_T1_T2_noAsylum, echo=FALSE, fig.cap=figure_captions("noAsylumHistogram", noAsylum_lbl)}

my_hist_T1_T2_noAsylum <- my_hist_T1_T2_pc(c("noAsylum"))

# print(my_hist_T1_T2_noAsylum)
ggsave("my_hist_T1_T2_noAsylum.png")

```

<!-- As shown in figure `r f.ref("noAsylumHistogram")` -->

```{r costImmigHistogram, warning = FALSE, message = FALSE, echo = FALSE, fig.height=3.5, fig.cap=costImmig_lbl}
# Control group respondents who saw a fact check challenging the statement that 'Immigrants receive more in benefits and services than they pay in taxes.' (n=181)

my_hist_T1_T2_costImmig <- my_hist_T1_T2_pc(c("costImmig"))

# print(my_hist_T1_T2_costImmig)
ggsave("my_hist_T1_T2_costImmig.png")
```


```{r whiteCrimeHistogram, warning = FALSE, message = FALSE, echo = FALSE, fig.height=3.5, fig.cap=whiteCrime_lbl}
# Control group respondents who saw a fact check challenging the statement that 'The majority of crimes in London are committed by white people, not ethnic minorities.' (n=137)

my_hist_T1_T2_whiteCrime <- my_hist_T1_T2_pc(c("whiteCrime"))

# print(my_hist_T1_T2_whiteCrime)
ggsave("my_hist_T1_T2_whiteCrime.png")
```

```{r lowPaidHistogram, warning = FALSE, message = FALSE, echo = FALSE, fig.height=3.5, fig.cap=lowPaid_lbl}

# Control group respondents who saw a fact check challenging the statement that 'Immigration to the UK does not affect the wages of the low-paid.' (n=134)

my_hist_T1_T2_lowPaid <- my_hist_T1_T2_pc(c("lowPaid"))

# print(my_hist_T1_T2_lowPaid)
ggsave("my_hist_T1_T2_lowPaid.png")
```

<!-- But how influential are these four fact-checks if the fact-checker does not have the 'final word'? In the next section, we show how much of the effect of the fact check was offset by six variants of an undermining message.  -->

<!-- \newpage -->

<!-- ## Effect of the undermining messages on the impact of each fact-check -->

<!-- Figures 10-13 show how treated respondents rated the four false claims after they saw the fact-check. Those in the top panels, respectively, saw the fact-check only; those in the bottom panels, respectively, saw a fact-check followed up by an undermining message.  -->
<!-- (Note that the top panels here ('no comment') are the same as the bottom panels ('after') in the previous histograms.)  -->

<!-- Again, the pattern is similar across the four fact check groups: The 'post-truth' comment kept the share of the convinced at bay. The difference is particularly pronounced among respondents who saw a fact check showing that the number of asylum seekers had actually remained relatively constant over the past then years. A full 24% of them were completely convinced by the numbers, i.e. rated the false claim as 'definitely false' after they saw the fact check. Exposure to a post-truth comment shrank that share by two thirds, to 8%. The effect was slightly lower in the other fact check groups where exposure to an undermining message follow-up shrank the share of the convinced by about half.  -->

```{r hist_T2_by_comment_grey, warning = FALSE, message = FALSE, echo = FALSE, fig.height=5, fig.cap="Belief in false claims after exposure to a fact check. The top panel shows control group respondents (i.e. those who saw fact check only, n=737); the bottom panel shows all treatment group respondents (i.e. those who also saw an undermining message, n=2199)."} 

# Grey tones from colour brewer: https://colorbrewer2.org/#type=sequential&scheme=Greys&n=3

my_hist_T2_by_comment_grey = function(df) {
  df %>%
    group_by(comment2, 
             belief_num_T2) %>%
    dplyr::summarise(n = n()) %>%
    dplyr::mutate(percent = n / sum(n)) %>%
    as.data.frame() %>%
    ggplot(aes(x=factor(belief_num_T2),
               y=percent,
               fill=comment2)) +
    geom_bar(stat="identity",
             position = "dodge",
             color = "black"
    ) +
    scale_fill_manual(name="",
                      labels = c("Just the fact check", 
                                 "Also a post-truth comment"), 
                      values=c("#bdbdbd", "#636363") # twoDarkGreys 
    ) + 
    scale_x_discrete(labels=c("0" = "0 \nDefinitely \ntrue",
                              "1" = "1",
                              "2" = "2",
                              "3" = "3",
                              "4" = "4",
                              "5" = "5",
                              "6" = "6 \nDefinitely \nfalse")) +
    #theme_bw() # Hebt Farben auf
    scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
    theme_minimal() +
    # theme(text = element_text(size=15)) +
    facet_grid(comment2 ~ ., labeller = labeller(comment2 = label_wrap_gen(width = 10))) + # wrap label
    # ylim(0, 0.3) + 
    coord_cartesian(ylim=c(0, 0.37)) +
    labs(
      title = "",
      subtitle = "", 
      x="",
      y="") +
    theme(legend.position = 'none', # top
          text = element_text(size=14),
          axis.text.x = element_text(size=14), 
          plot.title = element_text(hjust = 0.5, color = "#666666"),
          plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
          axis.text.y = element_blank(), # remove y axis labels
          axis.ticks = element_blank() # remove y axis ticks
          ) +
    geom_text(aes(label=paste(round(percent*100,0),'%')), 
              vjust=-0.3, # outside bars
              # vjust=1.6,  # inside bars
              color="#666666", 
              size=6) 
}

hist_T2_by_comment_grey <- my_hist_T2_by_comment_grey(df) 

# print(hist_T2_by_comment_grey)
ggsave("hist_T2_by_comment_grey.png")

```


```{r my_hist_T2_by_comment_noAsylum, warning = FALSE, message = FALSE, echo = FALSE, fig.height=4, fig.cap="'There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years' (n=891)"} 

my_hist_T2_by_comment_noAsylum <- my_hist_T2_by_comment_grey(subset(df, whichFactCheck == "noAsylum")) 

# print(my_hist_T2_by_comment_noAsylum)
ggsave("my_hist_T2_by_comment_noAsylum.png")
```


```{r my_hist_T2_by_comment_costImmig, warning = FALSE, message = FALSE, echo = FALSE, fig.height=4, fig.cap="'European immigrants receive more in benefits and services than they pay in taxes.' (n=521)"} 
# Belief in false claims after exposure to a fact check. Respondents who saw a fact check challenging the statement that 

my_hist_T2_by_comment_costImmig <- my_hist_T2_by_comment_grey(subset(df, whichFactCheck == "costImmig"))

# print(my_hist_T2_by_comment_costImmig)
ggsave("my_hist_T2_by_comment_costImmig.png")
```

```{r my_hist_T2_by_comment_whiteCrime, warning = FALSE, message = FALSE, echo = FALSE, fig.height=4, fig.cap="'The majority of crimes in London are committed by white people, not ethnic minorities.' (n=343)"} 

my_hist_T2_by_comment_whiteCrime <- my_hist_T2_by_comment_grey(subset(df, whichFactCheck == "whiteCrime"))

# print(my_hist_T2_by_comment_whiteCrime)
ggsave("my_hist_T2_by_comment_whiteCrime.png")
```

```{r my_hist_T2_by_comment_lowPaid, warning = FALSE, message = FALSE, echo = FALSE, fig.height=4, fig.cap="'Immigration to the UK does not affect the wages of the low-paid.' (n=444)"} 

my_hist_T2_by_comment_lowPaid <- my_hist_T2_by_comment_grey(subset(df, whichFactCheck == "lowPaid"))

# print(my_hist_T2_by_comment_lowPaid)
ggsave("my_hist_T2_by_comment_lowPaid.png")
```


<!-- Figure 10 shows the full breakdown of pre and post-fact-check veracity scores in each treatment group. The effect is similar across the six treatment groups.  -->


```{r, mean_T1_T2_by_treatment, include=FALSE}

# ```{r mean_T1_T2_by_treatment, warning = FALSE, message = FALSE, echo = FALSE, fig.height=7, fig.cap="Mean belief in false claims after exposure to a fact check by corrected statement."} 

####  Means -- Belief at T2 by comment ####

my_plot_mean_T1_T2_by_PTC = function(x, y, z) {
  ggplot(x, # df_long, 
         aes(.data[[y]], # time
             .data[[z]], # belief 
             fill = .data[[y]] # time 
         )) +
    stat_summary(fun = mean, # OLD: fun.y ## `fun.y` is deprecated. Use `fun` instead. 
                 geom = "bar",
                 position="dodge",
                 color="black") +
    stat_summary(fun.data = mean_cl_normal,
                 geom = "errorbar",
                 position = position_dodge(width = .9),
                 width = .2
    ) +
    facet_grid(. ~ comment2) +
    coord_cartesian(ylim=c(0,6)) +
    # scale_y_continuous(breaks=seq(0,6,1)) + # tick every point
    scale_y_continuous(breaks=seq(0,6,1),
                       labels=c("0" = "0 - Definitely true",
                                "1" = "1",
                                "2" = "2",
                                "3" = "3",
                                "4" = "4",
                                "5" = "5",
                                "6" = "6 - Definitely false")
    ) +
    geom_abline(slope=0, intercept=3,  col = "black", lty=2) +
    scale_x_discrete(labels=c("T1" = "Before",
                              "T2" = "After")) +
    scale_fill_manual(name = "",
                      labels = c("Before fact check",
                                 "After fact check"),
                      # values=c("#c8c3cc", "#563f46")
                      values=c("#bdbdbd", "#636363") # twoDarkGreys 
                      ) + 
    labs(title="", 
         subtitle = "", 
         x="", 
         y="") +
    theme_minimal() + # theme_light
    theme(text = element_text(size=13),
          axis.text.x = element_text(size=13),  # 16
          plot.title = element_text(hjust = 0.5, color = "#666666"),
          plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
          legend.position = 'top', 
          # axis.text.y = element_blank(), # remove y axis labels
          axis.ticks = element_blank()) 
}

mean_T1_T2_by_PTC <- 
  my_plot_mean_T1_T2_by_PTC(df_long, "time", "belief_num") 
  # facet_grid(motivation ~ comment)

# print(mean_T1_T2_by_PTC) 
ggsave("mean_T1_T2_by_PTC.png") 


mean_T1_T2_by_treatment <- 
  my_plot_mean_T1_T2_by_PTC(df_long, "time", "belief_num") + 
  facet_grid(. ~ treatment, labeller = labeller(treatment = label_wrap_gen(width = 15))) # wrap facet label 


print(mean_T1_T2_by_treatment) 
ggsave("mean_T1_T2_by_treatment.png") 
```


## OLS Models for the coefficient plots in Figure 4 and 8 

Table 3 shows the three OLS regression models underlying the coefficient plot in Figure 4 of the main body of the text. The models estimate the effect of exposure to a fact-check on three indicators of a successful fact-check: the difference in the seven-point 'true' to 'false' ratings before and after exposure to the respective fact check (T2-T1), the perceived accuracy of the expert's information (1 not at all accurate to 4 very accurate), and trust in what the expert says on immigration (1 not at all accurate to 4 very accurate). 

Table 4 shows the three OLS regression models underlying the coefficient plot in Figure 8 of the main body of the text. The models estimate the effect of exposure to a fact-check on three indicators of post-truth reasoning: fact-opinion ratings, agreement that 'Its OK to disagree with the facts if thats what you believe', and the probability of choosing the statement that "The statistics are probably right, but I believe something different" to explain where respondents stood. Fact-opinion ratings are measured on a scale from 0 (Purely a matter of fact) to 6 (Purely a matter of opinion). The willingness to disagree with the facts is measured on a scale from 1 (Strongly disagree) to 4 (Strongly agree). 

<!-- Table 3 shows three OLS regression models with three different outcome variables: the difference in 'true' to 'false' ratings of the false claims before (T1) and after (T2) exposure to the respective fact check (model 1); perceived accuracy of the expert's information (model 2), and trust in what they say on the issue of immigration (model 3). To compute the difference in perceived veracity we deducted the pre-fact-check veracity scores from the post-fact-check veracity scores, yielding a scale from -6 to 6, where higher values indicate that respondents were more convinced. Perceptions of accuracy were measured on a seven-point scale from 0 (would not trust at all) to 6 (would trust a great deal). Trust in what the expert says on immigration is measured on a four point scale ranging from 1 (not at all accurate) to 4 (very accurate).  -->

<!-- All six versions of the undermining message decreased the effect of the fact check (model 1). When it comes to the other two outcome variables, though, respondents' perceptions of how accurate the expert's information was and how much they would generally trust what those individuals say on the immigration the picture is rather less clear. The messages that discredited the source of the fact check and that pointed to personal experience were associated with slightly lower levels of trust in the fact checker and their information, but the effect was small and did not always reach statistical significance. The message that rejected complexity had no effect on respondents' stated trust in the fact checker or their information. -->
<!-- -- and yet it reduced post-fact check veracity scores by around half a point. -->

<!-- This points to an interesting finding: It seems that exposure to post-truth rhetoric had a subliminal effect. Our data shows that the undermining messages affected actual responses to the fact checks much more than they affected respondents' own stated perceptions of how much they trusted the fact checker or their information. This is particularly striking in the case of the 'rejecting complexity' message. It may seem reassuring that the message that propagated 'trust your instincts even if looks as if the facts are different' had no effect on trust in the expert. It is much less reassuring that it still reduced the effect of the fact-check. Respondents who *thought* they trusted the expert were still influenced by the undermining message. This point to important real-world implications: Post-truth rhetoric can affect us without our knowledge. Critical comments can keep us from listening to the experts even if we know, and are willing to say, that the experts are trustworthy and their information is correct. Future research ought to test the psychological mechanism at play -- in particular, brain imaging studies would help us to understand reactions to arguments that are, factually incorrect or unconvincing but emotionally appealing.   -->

<!-- A few demographic variables are noteworthy. Women updated their factual beliefs more than men (but trusted the experts just as much as men).  Social grade, in contrast, predicted trust but not updating behaviour. Respondents in social grades C2 and DE trusted the expert and their information significantly less than respondents in social grade AB (the reference category). But they adapted their views just as much as AB respondents. We also found some interesting cohort effects. Both generation X and baby boomers trusted the expert less than millenials, the reference group, but updated their factual beliefs just as much as  millenials. ^[Millenials were chosen as the reference category because this was the largest cohort in our sample (n=883), closely followed by Baby Boomers (n=825) and Gen Y'ers (N=753). Gen Z (n=346) and the Silent generation (n=129) were less well represented.]  -->

<!-- There was one cohort that was *more* willing to update their factual beliefs than millenials: The silent generation, the cohort born between 1928 and 1945 who. As shown in model 1, after seeing the fact check the silent generation moved around 0.5 point closer toward 'definitely false', on average, than millenials. (We interpret this finding with caution, partly because we only had 129 silent generation respondents, and partly because we suspect that this cohort may have been more attentive to the undermining message).  -->

<!-- High levels of political attention (8-10 on a scale from 0 to 10) were associated with higher levels of trust in the expert and in their information. Low levels of political attention (0-2) were associated with lower, but not significantly lower levels of trust in the expert and their information. -->
<!-- ^[The reference category was medium levels of attention (3-7 on a scale where 0 meant 'No attention at all' and 10 meant 'A great deal of attention').]  -->

<!-- Support for immigration was associated with higher levels of trust in the expert and in their information, but did not affect updating behaviour. The importance respondents attached to the issue of immigration had a positive effect on trust in the expert and in their information, but did not affect updating behaviour. A Leave vote in the UK's 2016 European Union referendum predicted lower post-fact check veracity scores (model 2) but not trust in the expert or their statistics. Finally, we tested the effect of two scales: A populism scale and a nationalism scale. High scores on the populism scale were associated with lower post-fact check veracity scores (model 2) and slightly lower levels of trust in the expert. High scores on the nationalism scale had effects that were significant in size but so small as to be negligeable (see models 1, 3, and 4).  -->

<!-- \newpage -->

```{r ols_diff_accuracy_trust using stargazer, echo=FALSE, results='asis'}

# https://ignacioriveros1.github.io/r/2021/03/25/stargazer-for-amazing-academic-tables.html
# ```{r ols_diff_accuracy_trust using stargazer, warning = FALSE, message = FALSE, echo = FALSE, fig.cap="Effect of the six post-truth comments on belief in the false claims, and trust in the expert, and their information."} 

library("rmarkdown")
library("tinytex")
library("stargazer")
library("sandwich")

m1 = lm(diff ~ treatment, data = df)
m2 = lm(accurateExpert_num ~ treatment, data = df)
m3 = lm(trustExpert_num ~ treatment, data = df)

model.lst = list(m1, m2, m3)

stargazer(m1,
          m2,
          m3,
          title="Effect of the six post-truth comments on belief in the false claims, and trust in the expert, and their information",
          covariate.labels = c("Prof: Expert bias", "Prof: Personal Experience", "Prof: Truthiness", 
                               "Blogger: Expert bias", "Blogger: Personal Experience", "Blogger: Truthiness"),
          type = "latex", 
          omit = c("Constant"),
          # float = TRUE,
          # report = "vcs*",
          # se=lapply(model.lst, function(x) sqrt(diag(vcovHC(x, type = "HC1")))),
          no.space = TRUE,
          header=FALSE,
          single.row = FALSE,
          font.size = "small",
          intercept.bottom = F,
          column.separate = c(1, 1, 1),
          digits = 2,
          # t.auto = F,
          # p.auto = F,
          # notes.align = "l",
          # notes = c("datasets::swiss", "lm() function with Robust SE"),
          # notes.append = TRUE,
          omit.stat=c("f"),
          # dep.var.caption  = "My new caption",
          dep.var.labels = c("difference in belief", "perceived accuracy", "trust in expert"),
          column.labels = c("OLS", "OLS", "OLS")
          )
```


```{r ols (dvs: fact-opinion and ok to disagree) using stargazer, echo=FALSE, results='asis'}

m1 = lm(factOpinion_num ~ treatment, data = df)
m2 = lm(ok2disagree_num ~ treatment, data = df)
m3 = lm(believeSomethingDifferent ~ treatment, data = df, family = "binomial")

model.lst = list(m1, m2, m3)

stargazer(m1,
          m2,
          m3,
          title="Effect of the six post-truth comments on three indicators of post-truth reasoning",
          covariate.labels = c("Prof: Expert bias", "Prof: Personal Experience", "Prof: Truthiness", 
                               "Blogger: Expert bias", "Blogger: Personal Experience", "Blogger: Truthiness"),
          type = "latex", 
          omit = c("Constant"),
          # float = TRUE,
          # report = "vcs*",
          # se=lapply(model.lst, function(x) sqrt(diag(vcovHC(x, type = "HC1")))),
          no.space = TRUE,
          header=FALSE,
          single.row = FALSE,
          font.size = "small",
          intercept.bottom = F,
          column.separate = c(1, 1, 1),
          digits = 2,
          # t.auto = F,
          # p.auto = F,
          # notes.align = "l",
          # notes = c("datasets::swiss", "lm() function with Robust SE"),
          # notes.append = TRUE,
          omit.stat=c("f"),
          # dep.var.caption  = "My new caption",
          dep.var.labels = c("Matter of opinion", "Okay to disagree", "Believe something different"),
          column.labels = c("OLS", "OLS", "Logit")
          )
```


```{r ols_diff_accuracy_trust, include = FALSE} 

# ```{r ols_diff_accuracy_trust, warning = FALSE, message = FALSE, echo = FALSE, fig.cap="Effect of the six post-truth comments on belief in the false claims, and trust in the expert, and their information."} 

# removed controls: + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale

models <- list(
"(1) Veracity score difference" = lm(diff ~ treatment , data = df), 
# "(2) Perceived veracity after fact check (T2)" = lm(belief_num_T2 ~ treatment + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale, data = df),
"(2) Perceived accuracy" = lm(accurateExpert_num ~ treatment, data = df),
"(3) Trust" = lm(trustExpert_num ~ treatment, data = df)
)

models2 <- list(
    "(1) Perceived accuracy of commentator's information" = lm(accuratePostTruthComment_num ~ source2 + message2 + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale, data = subset(df, treatment != "No comment")),
  "(2) Trust in post-truth commentator"  = lm(trustPostTruthComment_num ~ source2 + message2 + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale, data = subset(df, treatment != "No comment"))
)


cm <- c("(Intercept)" = "(Intercept)",
        "source2Blogger"= "Source: Blogger",
        "message2Personal experience" = "Message: Personal experience",
        "message2Expert bias" = "Message: Expert bias", 
        "treatmentProfessor: Expert bias"= "Professor: Expert bias",
        "treatmentProfessor: Personal experience" = "Professor: Personal experience",
        "treatmentProfessor: Truthiness" = "Professor: Truthiness",
        "treatmentBlogger: Expert bias"= "Blogger: Expert bias", 
        "treatmentBlogger: Personal experience" = "Blogger: Personal experience",
        "treatmentBlogger: Truthiness" = "Blogger: Truthiness"
        # "genderFemale" = "Female",
        # "socialGradeC1" = "Social grade C1",
        # "socialGradeC2" = "Social grade C2", 
        # "socialGradeDE" = "Social grade DE",
        # "age" = "Age",
        # "generation2Gen Z (1997-2012)" = "Gen Z (1997-2012)",
        # "generation2Gen X (1965-80)" = "Gen X (1965-80)",
        # "generation2Baby boomers (1946-64)" = "Baby boomers (1946-64)", 
        # "generation2Silent generation (1928-45)" = "Silent generation (1928-45)",       
        # "attentionCategoryLow (0-2)" = "Political attention (low)",
        # "attentionCategoryHigh (8-10)" = "Political attention (high)",
        # "brexitleave" = "Voted to leave the EU",
        # "immigOpinions_num" = "Support immigrantion",
        # "immigImportance_num" = "Importance of immigration",
        # "leftright_num" = "left-right ideology",
        # "populism_scale" = "Populism scale",
        # "ethno_scale" = "Nationalism scale"
)


# modelsummary(models2, coef_omit = "Intercept", stars=TRUE)
# modelsummary(models, output = "markdown")

msummary(models, 
         output = "markdown", # output = 'table.tex', 
         coef_map = cm, 
         coef_omit = 'Intercept', # Added this to omit the intercept
         stars = c('*' = .05, '**' = .01, '***' = .001), 
         gof_omit = 'AIC|BIC|Log.Lik.|R2 |F', 
         statistic = "std.error", fmt = '%.2f' ,
         title = 'Effect of the undermining messages on responses to the fact-check', #  on the impact of the fact check, and on trust in the fact checker and their information
         # subtitle = "Scale from 0 (Definitely true) to 6 (Definitely false)",
         # notes = list('OLS regression models.')
         ) # %>% 
  # tab_spanner(label = 'Anti-Immigration',
  #             columns = c('asylum', 'cost', 'pooled anti')) %>%
  # tab_spanner(label = 'Pro-Immigration',
  #             columns = c('crime', 'wages', 'pooled pro')) %>%
  # tab_style(style = cell_text(size = 'small'), # x-small
  #           locations = cells_body(columns = c(2:7))) %>%
  # gtsave(filename ='Table_Belief_at_T1.tex',
  # path="/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/R/tables")

```



<!-- As discussed in the main body of the text, none of the undermining messages affected any of these two indicators of post-truth reasoning. (Again, we suspect that ceiling effect may have played a role in these null findings.) -->

<!-- However, a few demographic factors affected agreement with these two indicators of post-truth reasoning: Social grade C1 (Supervisory, clerical & junior managerial, administrative, professional occupations) was associated with *lower* levels of agreement that 'it's okay to disagree with the facts', as compared with AB (Higher & intermediate managerial, administrative, professional occupations).  -->
<!-- Gen Z also scored lower on both indicators of post-truth thinking than Millenials, the reference category.  -->
<!-- Two predictors were associated with *higher* levels of agreement that 'it's okay to disagree with the facts': A leave vote in the European Union referendum, seeing immigration as an 'important issue', and scoring high on our populism scale.  -->

<!-- \newpage -->

```{r ols (dvs: fact-opinion and ok to disagree), include = FALSE} 

# ```{r ols (dvs: fact-opinion and ok to disagree), warning = FALSE, message = FALSE, echo = FALSE, fig.cap="Effect of the six post-truth comments on belief in the false claims, and trust in the expert, and their information"} 

models3 <- list(
  "(1) Matter of opinion (OLS)" = lm(factOpinion_num ~ treatment, data = df),
  "(2) Okay to disagree (OLS)" = lm(ok2disagree_num ~ treatment, data = df),
  "(3) Believe something different (Logit)" = lm(believeSomethingDifferent ~ treatment, data = df, family = "binomial"))

# + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale

# modelsummary(models2, coef_omit = "Intercept", stars=TRUE)
# modelsummary(models, output = "markdown")

msummary(models3, 
         output = "markdown", # output = 'table.tex', 
         coef_map = cm, 
         coef_omit = 'Intercept', # Added this to omit the intercept
         stars = c('*' = .05, '**' = .01, '***' = .001), 
         gof_omit = 'AIC|BIC|Log.Lik.|F', 
         statistic = "std.error", fmt = '%.2f' ,
         title = 'Effect of the undermining messages on post-truth reasoning', 
         # subtitle = "Scale from 0 (Definitely true) to 6 (Definitely false)",
         # notes = list('OLS regression models.')
         ) # %>% 
  # tab_spanner(label = 'Anti-Immigration',
  #             columns = c('asylum', 'cost', 'pooled anti')) %>%
  # tab_spanner(label = 'Pro-Immigration',
  #             columns = c('crime', 'wages', 'pooled pro')) %>%
  # tab_style(style = cell_text(size = 'small'), # x-small
  #           locations = cells_body(columns = c(2:7))) %>%
  # gtsave(filename ='Table_Belief_at_T1.tex', 
  #        path="/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Data/R/tables")

```

\newpage



# Appendix C - Subgroup Analyses 

## Effect of the fact-check and the undermining message among respondents who were motivated to reject the statistics

Up to here, our analyses are based on the entire sample, including some who did not see immigration as an important issue and some whose most confident false belief ran against the grain of their opinions on immigration. For instance, some of those who said that Britain should take in *more* immigrants (so, pro-immigration respondents) thought, incorrectly, that the number of asylum seekers in the UK were rising, and so were directed to statistics proving them wrong. These respondents should be happy to be proven wrong. On the hand, some of those who said that Britain should take in *fewer* immigrants (so, anti-immigration respondents) thought, incorrectly, that immigration to the UK had no effect on low-paid wages. These respondents will have been similarly happy to read the fact-check. 

To examine the effect of the fact-check and the undermining message on those who had a motivation to reject the statistics we created a subsample removing those these respondents (n=882, or 30% of the sample). The following analyses are based on a subset of respondents who said that immigration was at least 'somewhat important' and who were directed to a fact-check that challenged not only their factual beliefs but also their immigration preferences. 
<!-- (In other words, respondents whose answers to our questions about the importance of immigration and what Britain should do about it suggested a motivation to reject the fact-check and accept the undermining message).  -->

The bar plot in Figure 10 (analogous to Figure 2 in the main text) shows the effect of the fact-check and the undermining message on belief in false claims among this subsample of respondents who were motivated to reject the statistics (n=2054). The fact-check alone shifted perceptions 1.67 points along the scale (from 0.91 to 2.58). The fact-check followed by an undermining message shifted perceptions a mere 1.19 points along the scale (from 0.92 to 2.11). That means that the offsetting effect of the undermining message rises to 29% (1-1.19/1.67) among those who had a motivation to reject the fact-check. Figure 11 (analogous to Figure 9 for the whole sample) illustrates the effect of the fact-check and the undermining message for each fact-check group.

The OLS and logit models in tables 5 and 6 show the effect of the treatments on the additional outcome variables among this subsample. Here, too the effects are very similar to the effects in the whole sample (tables 3 and 4). The finding that reactions to the undermining message did not really depend on respondent's incentives to reject the statistics and be nudged back to their prior beliefs is noteworthy: It means that factual beliefs drive responses to fact-checks much more than partisan motivations. How convinced people are the a statement is true is a more powerful predictor than  how much they want it be true.

<!-- This suggests that reactions to fact-checks are shaped by factual beliefs more than political opinions.  -->



<!-- Finally, in tables 5 and 6 we show the same OLS and Logit models as in tables 3 and 4, but restricted to the subsample of respondents who felt strongly about the issue of immigration and were directed to a fact-check that challenged not only their factual beliefs but also their immigration opinions.  -->

<!-- (If this 1.19 is compared to the 1.67-point effect among control group respondents, we can say that the undermining message undid 43% (1-1.19/2.11) of the effect of the fact-check.  -->




<!-- a fourth of whom (24%) were directed to a fact check that challenged not only their factual beliefs but also their opinions about immigration (n=2239, removing 697 respondents (24%) from the sample). Figure 15 (analogous to Figure 2 in the main body of the text) shows how these respondents who had a motivation to disregard the evidence reacted to the fact-check only (left-hand side) and the fact-check followed by an undermining message (right-hand side). The undermining message shifted perceptions 1.66 points along the scale (from 0.95 to 2.62). The right-hand side shows how exposure to the undermining message undermined this effect: Those who saw the message only shifted 1.19 points along the scale (from 0.97 to 2.16); meaning that the message offset about a third of the effect of the fact-check.  -->

<!-- (e.g. respondents who thought Britain should take in fewer immigrants and whohad seen what we think must be inconvenient information refuting that asylum applicationnumbers are rising or that European immigrants receive more in benefits and services thanthey pay in taxes).  -->
<!-- In total, we excluded 27 per cent of respondents in the anti-immigration group (n=508, leaving 1370 in the sample) and 35 per cent of respondents in the pro-immigration group (n=374, leaving 684 in the sample). In this group, respondents were more confident the false claims were true () -->
<!-- Yet, even in this smaller subset of respondents who were all motivated to reject the fact check the undermining messages did more harm to the anti-immigration fact checks than the pro-immigration fact checks. We conclude that differences in directional goals cannot explain why fact checks countering anti-immigration statements were more easily undermined -->

```{r mean_T1_T2_by_PTC_m2r, warning = FALSE, message = FALSE, echo = FALSE, fig.height=6, fig.cap="Average assessment of the false claims by exposure to an undermining message. Subset of respondents who had an incentive to disregard the fact-check they saw."} 

# calculate the meam and the 95% confidence intervals for the mean -- USE THIS
# https://rpubs.com/techanswers88/MeanAndConfidenceIntervals

mean_T1_T2_by_PTC_m2r <-
df_long %>%
  filter(m2r_imp==1) %>%
  # filter(m2r==1) %>%
  group_by(comment2, time) %>%
  dplyr::summarise(n = n(),
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>%
  as.data.frame()  %>%
  
  ggplot(aes(x=time, 
             y=mean,
             fill=time)) +
  stat_summary(fun = mean, # OLD: fun.y ## `fun.y` is deprecated. Use `fun` instead. 
               geom = "bar",
               position="dodge",
               color="black",
               size=.8) +
  # stat_summary(fun.data = mean_cl_normal,
  #              geom = "errorbar",
  #              position = position_dodge(width = .9),
  #              width = .2
  # ) +
  facet_grid(. ~ comment2) +
  coord_cartesian(ylim=c(0,6)) +
  # scale_y_continuous(breaks=seq(0,6,1)) + # tick every point
  scale_y_continuous(breaks=seq(0,6,1),
                     labels=c("0" = "0 - Definitely true",
                              "1" = "1",
                              "2" = "2",
                              "3" = "3",
                              "4" = "4",
                              "5" = "5",
                              "6" = "6 - Definitely false")
  ) +
  geom_abline(slope=0, intercept=3,  col = "black", lty=2) +
  scale_x_discrete(labels=c("T1" = "Before ",
                            "T2" = "After")) +
  scale_fill_manual(name = "",
                    labels = c("Before fact check",
                               "After fact check"),
                    # values=c("#c8c3cc", "#563f46")
                    # values=c("#bdbdbd", "#636363") # twoDarkGreys 
                    values=c("#c8c3cc", "#563f46") #twoReds
  ) + 
  geom_errorbar(aes(ymin=lower_ci, ymax= upper_ci),
                width = 0.4, 
                color ="black", 
                size = .8) +
  geom_text(aes(label=round(mean, 2), # paste(round(mean*100,0),'%'),
                group=time),
            position = position_dodge(width = .9),
            # hjust=1,
            vjust=2,  # inside bars
            color="white", # #252525
            size=6) +
  labs(title="", 
       subtitle = "", 
       x="", 
       y="") +
  theme_minimal() + # theme_light
  theme(text = element_text(size=16),
        axis.text = element_text(size=16),
        plot.title = element_text(hjust = 0.5, color = "#666666"),
        plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
        legend.position = 'top', 
        legend.text = element_text(size = 16),
        strip.text.x = element_text(size = 16), # panel label size
        # axis.text.y = element_blank(), # remove y axis labels
        axis.ticks = element_blank())


print(mean_T1_T2_by_PTC_m2r) 
ggsave("mean_T1_T2_by_PTC_m2r.png",  width = 35,  height = 20,  units = "cm")

```


```{r each_statement_cleveland_plot_by_comment_m2r, warning = FALSE, message = FALSE, echo = FALSE, fig.height=8, fig.cap="Respondents who were motivated to reject the statistics: Average belief in false facts before and after exposure to a fact-check."} 

# ```{r each_statement_cleveland_plot_by_comment_m2r, warning = FALSE, message = FALSE, echo = FALSE, results="asis", fig.show='hide'} 

each_statement_cleveland_data_by_comment_m2r <- 
  df %>%
  filter(m2r_imp==1) %>%
  group_by(comment2, whichFactCheckTxt) %>%
  dplyr::summarise(
    m_before = mean(belief_num_T1, na.rm = T),
    m_after = mean(belief_num_T2, na.rm = T)
  ) %>%
  ungroup() %>% 
  gather(key = "key", value = "value", -comment2, -whichFactCheckTxt) %>% 
  separate(col = "key",
           into = c("statistic", "time"),
           sep = "_") %>%
  as.data.frame() %>%
  spread(key = "statistic",
         value = "value") %>%
  mutate(time = factor(time, levels = c("before", "after")))

# How to place labels next to points
# https://uc-r.github.io/cleveland-dot-plots

before_label <- each_statement_cleveland_data_by_comment_m2r %>%
  filter(time=='before') %>%
  group_by(comment2) %>%
  select(comment2, whichFactCheckTxt, m, time)

after_label <- each_statement_cleveland_data_by_comment_m2r %>%
  filter(time=='after') %>%
  group_by(comment2) %>%
  select(comment2, whichFactCheckTxt, m, time)


each_statement_cleveland_plot_by_comment_m2r <-
  each_statement_cleveland_data_by_comment_m2r %>%
  ggplot(aes(x=m, 
             y=factor(comment2, level = c("No undermining message", "Undermining message"))
  )) + 
  facet_wrap(~whichFactCheckTxt, ncol=1) + 
  geom_line(aes(group = comment2
  )) +
  geom_point(aes(colour = time, 
                 fill="white",
  ),
  size=4
  ) + 
  geom_text(data = before_label, aes(m, color=time, label = round(m, 2)),
            size = 4, hjust = 2) +  # -.5
  geom_text(data = after_label, aes(m, color=time, label = round(m, 2)),
            size = 4, hjust = -1.5) + # 1.5
  scale_color_manual(values = c("#999999", "#E69F00"),
                     labels = c("Before exposure to the fact check", "After exposure to the fact check")) +
  ylab("") +
  scale_x_continuous(
    name = "\nPerceived veracity", 
    limits = c(0, 6.5),
    breaks = seq(0, 6, by = 1),
    labels=c(
      "0" = "0 \nDefinitely \ntrue",
      "1" = "1",
      "2" = "2",
      "3" = "3", # "Don't know",
      "4" = "4",
      "5" = "5",
      "6" = "6 \nDefinitely \nfalse"),
    expand = c(0.02, 0)
  ) + 
  geom_vline(xintercept = 3, 
             alpha = .3,
             linetype="dotted", 
             color = "grey", 
             size=1.5) +
  theme_minimal() +
  guides(size = FALSE, fill=FALSE, alpha=FALSE) + 
  theme(axis.title = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        #legend.justification = c(0, 1), 
        #legend.position = c(.1, 1.075),
        legend.position = "bottom",
        legend.background = element_blank(),
        legend.direction="horizontal",        
        text = element_text(size=14), # family = "Arial", 
        plot.title = element_text(size = 20, margin = margin(b = 10)),
        plot.subtitle = element_text(size = 10, color = "darkslategrey", margin = margin(b = 25)),
        plot.caption = element_text(size = 10, margin = margin(t = 10), color = "grey70", hjust = 0)
        )

print(each_statement_cleveland_plot_by_comment_m2r)
ggsave("each_statement_cleveland_plot_by_comment_m2r.png")

```


```{r mean_T1_T2_by_PTC_each_statement_m2r, include = FALSE} 

# ```{r mean_T1_T2_by_PTC_each_statement_m2r, warning = FALSE, message = FALSE, echo = FALSE, fig.height=11, fig.cap="Average assessment of the false claims by exposure to an undermining message. Subset of respondents who were motivated to reject the statistics."} 

# calculate the meam and the 95% confidence intervals for the mean -- USE THIS
# https://rpubs.com/techanswers88/MeanAndConfidenceIntervals

mean_T1_T2_by_PTC_each_statement_m2r <- 
df_long %>% 
  filter(m2r_imp==1) %>% 
  group_by(whichFactCheck_long, comment2, time) %>% 
  dplyr::summarise(n = n(), 
                   mean = mean(belief_num),
                   lower_ci = t.test(belief_num, conf.level = 0.95)$conf.int[1], 
                   upper_ci = t.test(belief_num, conf.level = 0.95)$conf.int[2]) %>% 
  as.data.frame()  %>% 
  
  ggplot(aes(x=time, 
             y=mean, 
             fill=time)) + 
  stat_summary(fun = mean, # OLD: fun.y ## `fun.y` is deprecated. Use `fun` instead. 
               geom = "bar",
               position="dodge",
               color="black",
               size=.8) +
  facet_grid(whichFactCheck_long ~ comment2) +
  # coord_cartesian(ylim=c(0,6)) +
  coord_cartesian(ylim=c(0,3.5)) +
  # scale_y_continuous(breaks=seq(0,6,1)) + # tick every point
  scale_y_continuous(breaks=seq(0,6,1),
                     labels=c("0" = "0 - Definitely true",
                              "1" = "1",
                              "2" = "2",
                              "3" = "3",
                              "4" = "4",
                              "5" = "5",
                              "6" = "6 - Definitely false")
  ) +
  geom_abline(slope=0, intercept=3,  col = "black", lty=2) +
  scale_x_discrete(labels=c("T1" = "Before ",
                            "T2" = "After")) +
  scale_fill_manual(name = "",
                    labels = c("Before fact check",
                               "After fact check"),
                    # values=c("#c8c3cc", "#563f46")
                    values=c("#bdbdbd", "#636363") # twoDarkGreys 
  ) + 
  geom_errorbar(aes(ymin=lower_ci, ymax= upper_ci),
                width = 0.4, 
                color ="black", 
                size = .5) +
  geom_text(aes(label=round(mean, 2), # paste(round(mean*100,0),'%'),
                group=time),
            position = position_dodge(width = .9),
            # hjust=1,
            # vjust=-1.4,  # inside bars
            vjust=2.6,  # inside bars
            color="white", # #252525
            # color="black", # #252525
            size=5) +
  labs(title="", 
       subtitle = "", 
       x="", 
       y="") +
  theme_minimal() + # theme_light
  theme(text = element_text(size=14),
        axis.text = element_text(size=14),
        plot.title = element_text(hjust = 0.5, color = "#666666"),
        plot.subtitle = element_text(hjust = 0.5, color = "#666666"),
        legend.position = 'top', 
        legend.text = element_text(size = 14),
        strip.text.x = element_text(size = 14), # panel label size
        # axis.text.y = element_blank(), # remove y axis labels
        axis.ticks = element_blank())

print(mean_T1_T2_by_PTC_each_statement_m2r) 
ggsave("mean_T1_T2_by_PTC_each_statement_m2r.png",  width = 35,  height = 20,  units = "cm") 

```



```{r ols_diff_accuracy_trust using stargazer - m2r, echo=FALSE, results='asis'}

m1 = lm(diff ~ treatment, data = subset(df, m2r_imp==1))
m2 = lm(accurateExpert_num ~ treatment, data = subset(df, m2r_imp==1))
m3 = lm(trustExpert_num ~ treatment, data = subset(df, m2r_imp==1))

model.lst = list(m1, m2, m3)

stargazer(m1,
          m2,
          m3,
          title="Respondents who were motivated to reject the statistics: Effect of the six post-truth comments on belief in the false claims, and trust in the expert, and their information",
          covariate.labels = c("Prof: Expert bias", "Prof: Personal Experience", "Prof: Truthiness", 
                               "Blogger: Expert bias", "Blogger: Personal Experience", "Blogger: Truthiness"),
          type = "latex", 
          omit = c("Constant"),
          # float = TRUE,
          # report = "vcs*",
          # se=lapply(model.lst, function(x) sqrt(diag(vcovHC(x, type = "HC1")))),
          no.space = TRUE,
          header=FALSE,
          single.row = FALSE,
          font.size = "small",
          intercept.bottom = F,
          column.separate = c(1, 1, 1),
          digits = 2,
          # t.auto = F,
          # p.auto = F,
          # notes.align = "l",
          # notes = c("datasets::swiss", "lm() function with Robust SE"),
          # notes.append = TRUE,
          omit.stat=c("f"),
          # dep.var.caption  = "My new caption",
          dep.var.labels = c("difference in belief", "perceived accuracy", "trust in expert"),
          column.labels = c("OLS", "OLS", "OLS")
          )
```


```{r ols (dvs: fact-opinion and ok to disagree) using stargazer - m2r, echo=FALSE, results='asis'}

m1 = lm(factOpinion_num ~ treatment, data = subset(df, m2r_imp==1))
m2 = lm(ok2disagree_num ~ treatment, data = subset(df, m2r_imp==1))
m3 = lm(believeSomethingDifferent ~ treatment, data = subset(df, m2r_imp==1), family = "binomial")

model.lst = list(m1, m2, m3)

stargazer(m1,
          m2,
          m3,
          title="Respondents who were motivated to reject the statistics: Effect of the six post-truth comments on three indicators of post-truth reasoning",
          covariate.labels = c("Prof: Expert bias", "Prof: Personal Experience", "Prof: Truthiness", 
                               "Blogger: Expert bias", "Blogger: Personal Experience", "Blogger: Truthiness"),
          type = "latex", 
          omit = c("Constant"),
          # float = TRUE,
          # report = "vcs*",
          # se=lapply(model.lst, function(x) sqrt(diag(vcovHC(x, type = "HC1")))),
          no.space = TRUE,
          header=FALSE,
          single.row = FALSE,
          font.size = "small",
          intercept.bottom = F,
          column.separate = c(1, 1, 1),
          digits = 2,
          # t.auto = F,
          # p.auto = F,
          # notes.align = "l",
          # notes = c("datasets::swiss", "lm() function with Robust SE"),
          # notes.append = TRUE,
          omit.stat=c("f"),
          # dep.var.caption  = "My new caption",
          dep.var.labels = c("Matter of opinion", "Okay to disagree", "Believe something different"),
          column.labels = c("OLS", "OLS", "Logit")
          )
```


```{r ols_diff_accuracy_trust - m2r, include = FALSE} 

# ```{r ols_diff_accuracy_trust - m2r, warning = FALSE, message = FALSE, echo = FALSE, fig.cap="Effect of the six post-truth comments on belief in false claims -- respondents who were motivated to reject the statistics."} 

# removed controls: + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale

models_belief_m2r <- list(
"(1) Veracity score difference" = lm(diff ~ treatment , data = subset(df, m2r_imp==1)),
# "(2) Perceived veracity after fact check (T2)" = lm(belief_num_T2 ~ treatment + gender + generation2 + socialGrade + attentionCategory + brexit + immigOpinions_num + immigImportance_num + populism_scale + ethno_scale, data = df),
"(2) Perceived accuracy" = lm(accurateExpert_num ~ treatment, data = subset(df, m2r_imp==1)),
"(3) Trust" = lm(trustExpert_num ~ treatment, data = subset(df, m2r_imp==1))
)

# modelsummary(models2, coef_omit = "Intercept", stars=TRUE)
# modelsummary(models, output = "markdown")

msummary(models_belief_m2r, 
         output = "markdown", # output = 'table.tex', 
         coef_map = cm, 
         coef_omit = 'Intercept', # Added this to omit the intercept
         stars = c('*' = .05, '**' = .01, '***' = .001), 
         gof_omit = 'AIC|BIC|Log.Lik.|R2 |F', 
         statistic = "std.error", fmt = '%.2f' ,
         title = 'Effect of the undermining messages on responses to the fact-check (respondents who were motivated to reject the statistics)', #  on the impact of the fact check, and on trust in the fact checker and their information
         # subtitle = "Scale from 0 (Definitely true) to 6 (Definitely false)",
         # notes = list('OLS regression models.')
         ) 

```


```{r ols (dvs: fact-opinion and ok to disagree) m2r, include = FALSE} 

# ```{r ols (dvs: fact-opinion and ok to disagree) m2r, warning = FALSE, message = FALSE, echo = FALSE, fig.cap="Effect of the six post-truth comments on post-truth reasoning -- respondents who were motivated to reject the statistics"} 

models_post_truth_m2r <- list(
  "(1) Matter of opinion (OLS)" = lm(factOpinion_num ~ treatment, data = subset(df, m2r_imp==1)),
  "(2) Okay to disagree (OLS)" = lm(ok2disagree_num ~ treatment, subset(df, m2r_imp==1)),
    "(3) Believe something different (Logit)" = lm(believeSomethingDifferent ~ treatment, subset(df, m2r_imp==1), family = "binomial")
)

# modelsummary(models2, coef_omit = "Intercept", stars=TRUE)
# modelsummary(models, output = "markdown")

msummary(models_post_truth_m2r, 
         output = "markdown", # output = 'table.tex', 
         coef_map = cm, 
         coef_omit = 'Intercept', # Added this to omit the intercept
         stars = c('*' = .05, '**' = .01, '***' = .001), 
         gof_omit = 'AIC|BIC|Log.Lik.|F', 
         statistic = "std.error", fmt = '%.2f' ,
         title = 'Effect of the undermining messages on post-truth reasoning (respondents who were motivated to reject the statistics)', 
         # subtitle = "Scale from 0 (Definitely true) to 6 (Definitely false)",
         # notes = list('OLS regression models.')
         ) 

```

\newpage

# Appendix C - Pilot Study

```{r pilot data management, warning = FALSE, message = FALSE, echo = FALSE}

### Pilot 1 ###

pilot1 <- read.csv("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Pre-Test/Pre-Test I/pretest_words.csv")
# pilot1 <- read.csv("/Users/christine/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Pre-Test/Pre-Test I/pretest_words.csv")

# Delete first 2 rows (headers) and 3rd row (me, pretesting)
pilot1 <- pilot1[-(1:3) , ]

# Delete misperceptions1. prefix from variable names
names(pilot1) <- gsub("trustSources1_", "", names(pilot1))
names(pilot1) <- gsub("trustSources2_", "", names(pilot1))
names(pilot1) <- gsub("misperceptions1.", "", names(pilot1))
names(pilot1) <- gsub("misperceptions2.", "", names(pilot1))

# Create dummies for leave/remain 
pilot1$leave <- NA
pilot1$leave[pilot1$voteLeave=="I voted to LEAVE the European Union."] <- "Leave"
pilot1$leave[pilot1$wouldVoteLeave=="I would have voted to LEAVE the European Union." ] <- "Leave"
pilot1$leave[pilot1$brexitWouldVote=="I would have voted to LEAVE the European Union." ] <- "Leave"

pilot1$leave[pilot1$voteLeave=="I voted to REMAIN in the European Union." ] <- "Remain"
pilot1$leave[pilot1$wouldVoteLeave=="I would have voted to REMAIN in the European Union." ] <- "Remain"
pilot1$leave[pilot1$brexitWouldVote=="I would have voted to REMAIN in the European Union." ] <- "Remain"

# Create variable for immigration opinions
pilot1$immigOpinions3[pilot1$immigration_1 < 3] <- "fewer"
pilot1$immigOpinions3[pilot1$immigration_1 == 3] <- "no change"
pilot1$immigOpinions3[pilot1$immigration_1 > 3] <- "more"
pilot1$immigOpinions3 <- factor(pilot1$immigOpinions3, levels = c("fewer", "no change", "more"))

pilot1$immigOpinions2[pilot1$immigration_1 < 3] <- "anti-immig"
pilot1$immigOpinions2[pilot1$immigration_1 >= 3] <- "pro-immig"
pilot1$immigOpinions2 <- factor(pilot1$immigOpinions2, levels = c("anti-immig", "pro-immig"))


# Sources -- Least trustworthy first
pilot1$bbc <- NA
pilot1$bbc[pilot1$BBC=="Not At All" ] <- 1
pilot1$bbc[pilot1$BBC=="Not Very" ] <- 2
pilot1$bbc[pilot1$BBC=="Fairly" ] <- 3
pilot1$bbc[pilot1$BBC=="Mostly" ] <- 4
pilot1$bbc[pilot1$BBC=="Completely" ] <- 5
pilot1$bbc <- as.numeric(as.character(pilot1$bbc))

pilot1$hoc <- NA
pilot1$hoc[pilot1$HoC=="Not At All" ] <- 1
pilot1$hoc[pilot1$HoC=="Not Very" ] <- 2
pilot1$hoc[pilot1$HoC=="Fairly" ] <- 3
pilot1$hoc[pilot1$HoC=="Mostly" ] <- 4
pilot1$hoc[pilot1$HoC=="Completely" ] <- 5
pilot1$hoc <- as.numeric(as.character(pilot1$hoc))

pilot1$smf <- NA
pilot1$smf[pilot1$SocialMarket1=="Not At All" ] <- 1
pilot1$smf[pilot1$SocialMarket1=="Not Very" ] <- 2
pilot1$smf[pilot1$SocialMarket1=="Fairly" ] <- 3
pilot1$smf[pilot1$SocialMarket1=="Mostly" ] <- 4
pilot1$smf[pilot1$SocialMarket1=="Completely" ] <- 5
pilot1$smf <- as.numeric(as.character(pilot1$smf))

# NB: It looks like we accidentally asked this twice: 
# both the SocialMarket1 and the SocialMarketEcon variables ask about 
# "A research fellow at the Social Market Foundation"

# pilot1$smf_econ <- NA
# pilot1$smf_econ[pilot1$SocialMarketEcon=="Not At All" ] <- 1
# pilot1$smf_econ[pilot1$SocialMarketEcon=="Not Very" ] <- 2
# pilot1$smf_econ[pilot1$SocialMarketEcon=="Fairly" ] <- 3
# pilot1$smf_econ[pilot1$SocialMarketEcon=="Mostly" ] <- 4
# pilot1$smf_econ[pilot1$SocialMarketEcon=="Completely" ] <- 5
# pilot1$smf_econ <- as.numeric(as.character(pilot1$smf_econ))

pilot1$mig_watch <- NA
pilot1$mig_watch[pilot1$MigrationWatch=="Not At All" ] <- 1
pilot1$mig_watch[pilot1$MigrationWatch=="Not Very" ] <- 2
pilot1$mig_watch[pilot1$MigrationWatch=="Fairly" ] <- 3
pilot1$mig_watch[pilot1$MigrationWatch=="Mostly" ] <- 4
pilot1$mig_watch[pilot1$MigrationWatch=="Completely" ] <- 5
pilot1$mig_watch <- as.numeric(as.character(pilot1$mig_watch))

pilot1$oxf_econ <- NA
pilot1$oxf_econ[pilot1$OxfordEcon=="Not At All" ] <- 1
pilot1$oxf_econ[pilot1$OxfordEcon=="Not Very" ] <- 2
pilot1$oxf_econ[pilot1$OxfordEcon=="Fairly" ] <- 3
pilot1$oxf_econ[pilot1$OxfordEcon=="Mostly" ] <- 4
pilot1$oxf_econ[pilot1$OxfordEcon=="Completely" ] <- 5
pilot1$oxf_econ <- as.numeric(as.character(pilot1$oxf_econ))

pilot1$border_agency <- NA
pilot1$border_agency[pilot1$UKBorderAgency=="Not At All" ] <- 1
pilot1$border_agency[pilot1$UKBorderAgency=="Not Very" ] <- 2
pilot1$border_agency[pilot1$UKBorderAgency=="Fairly" ] <- 3
pilot1$border_agency[pilot1$UKBorderAgency=="Mostly" ] <- 4
pilot1$border_agency[pilot1$UKBorderAgency=="Completely" ] <- 5
pilot1$border_agency <- as.numeric(as.character(pilot1$border_agency))

pilot1$chat_house <- NA
pilot1$chat_house[pilot1$ChathamHouse=="Not At All" ] <- 1
pilot1$chat_house[pilot1$ChathamHouse=="Not Very" ] <- 2
pilot1$chat_house[pilot1$ChathamHouse=="Fairly" ] <- 3
pilot1$chat_house[pilot1$ChathamHouse=="Mostly" ] <- 4
pilot1$chat_house[pilot1$ChathamHouse=="Completely" ] <- 5
pilot1$chat_house <- as.numeric(as.character(pilot1$chat_house))

pilot1$oxf_pol <- NA
pilot1$oxf_pol[pilot1$OxfordPolSc=="Not At All" ] <- 1
pilot1$oxf_pol[pilot1$OxfordPolSc=="Not Very" ] <- 2
pilot1$oxf_pol[pilot1$OxfordPolSc=="Fairly" ] <- 3
pilot1$oxf_pol[pilot1$OxfordPolSc=="Mostly" ] <- 4
pilot1$oxf_pol[pilot1$OxfordPolSc=="Completely" ] <- 5
pilot1$oxf_pol <- as.numeric(as.character(pilot1$oxf_pol))

pilot1$ons <- NA
pilot1$ons[pilot1$ONS=="Not At All" ] <- 1
pilot1$ons[pilot1$ONS=="Not Very" ] <- 2
pilot1$ons[pilot1$ONS=="Fairly" ] <- 3
pilot1$ons[pilot1$ONS=="Mostly" ] <- 4
pilot1$ons[pilot1$ONS=="Completely" ] <- 5
pilot1$ons <- as.numeric(as.character(pilot1$ons))


# Liberal misperceptions

# Immigration to the United Kingdom does not affect the wages of the low paid.

pilot1$T_noEffectLowPaid <- as.factor(as.character(pilot1$T_noEffectLowPaid))

pilot1$noEffectLowPaid[pilot1$T_noEffectLowPaid=="TRUE"] <- 1
pilot1$noEffectLowPaid[pilot1$T_noEffectLowPaid=="FALSE"] <- 0

pilot1$certain_noEffectLowPaid[pilot1$Certain_noEffectLowPaid=="Not At All" ] <- 1
pilot1$certain_noEffectLowPaid[pilot1$Certain_noEffectLowPaid=="Not Very" ] <- 2
pilot1$certain_noEffectLowPaid[pilot1$Certain_noEffectLowPaid=="Fairly" ] <- 3
pilot1$certain_noEffectLowPaid[pilot1$Certain_noEffectLowPaid=="Very" ] <- 4
pilot1$certain_noEffectLowPaid[pilot1$Certain_noEffectLowPaid=="Absolutely" ] <- 5
pilot1$certain_noEffectLowPaid <- as.numeric(as.character(pilot1$certain_noEffectLowPaid))

# UK courts are more likely to convict black defendants than white defendants.

pilot1$T_racistCourts <- as.factor(as.character(pilot1$T_racistCourts))

pilot1$racistCourts[pilot1$T_racistCourts=="TRUE" ] <- 1
pilot1$racistCourts[pilot1$T_racistCourts=="FALSE" ] <- 0

pilot1$certain_racistCourts[pilot1$Certain_racistCourts=="Not At All" ] <- 1
pilot1$certain_racistCourts[pilot1$Certain_racistCourts=="Not Very" ] <- 2
pilot1$certain_racistCourts[pilot1$Certain_racistCourts=="Fairly" ] <- 3
pilot1$certain_racistCourts[pilot1$Certain_racistCourts=="Very" ] <- 4
pilot1$certain_racistCourts[pilot1$Certain_racistCourts=="Absolutely" ] <- 5
pilot1$certain_racistCourts <- as.numeric(as.character(pilot1$certain_racistCourts))

# The UK is the only major Western democracy to include international students in its net migration statistics. 

pilot1$T_studentsInStats <- as.factor(as.character(pilot1$T_studentsInStats))

pilot1$studentsInStats[pilot1$T_studentsInStats=="TRUE" ] <- 1
pilot1$studentsInStats[pilot1$T_studentsInStats=="FALSE" ] <- 0

pilot1$certain_studentsInStats[pilot1$Certain_studentsInStats=="Not At All" ] <- 1
pilot1$certain_studentsInStats[pilot1$Certain_studentsInStats=="Not Very" ] <- 2
pilot1$certain_studentsInStats[pilot1$Certain_studentsInStats=="Fairly" ] <- 3
pilot1$certain_studentsInStats[pilot1$Certain_studentsInStats=="Very" ] <- 4
pilot1$certain_studentsInStats[pilot1$Certain_studentsInStats=="Absolutely" ] <- 5
pilot1$certain_studentsInStats <- as.numeric(as.character(pilot1$certain_studentsInStats))

# The rate of net migration to the UK has not increased much in recent decades. 

pilot1$T_noIncrease <- as.factor(as.character(pilot1$T_noIncrease))

pilot1$noIncrease[pilot1$T_noIncrease=="TRUE" ] <- 1
pilot1$noIncrease[pilot1$T_noIncrease=="FALSE" ] <- 0

pilot1$certain_noIncrease[pilot1$Certain_noIncrease=="Not At All" ] <- 1
pilot1$certain_noIncrease[pilot1$Certain_noIncrease=="Not Very" ] <- 2
pilot1$certain_noIncrease[pilot1$Certain_noIncrease=="Fairly" ] <- 3
pilot1$certain_noIncrease[pilot1$Certain_noIncrease=="Very" ] <- 4
pilot1$certain_noIncrease[pilot1$Certain_noIncrease=="Absolutely" ] <- 5
pilot1$certain_noIncrease <- as.numeric(as.character(pilot1$certain_noIncrease))


# Conservative misperceptions

# There has seen a sharp rise in the number of people applying for asylum in the UK in the past 10 years.

pilot1$T_riseAsylum <- as.factor(as.character(pilot1$T_riseAsylum))

pilot1$riseAsylum[pilot1$T_riseAsylum=="TRUE" ] <- 1
pilot1$riseAsylum[pilot1$T_riseAsylum=="FALSE" ] <- 0

pilot1$certain_riseAsylum[pilot1$Certain_riseAsylum=="Not At All" ] <- 1
pilot1$certain_riseAsylum[pilot1$Certain_riseAsylum=="Not Very" ] <- 2
pilot1$certain_riseAsylum[pilot1$Certain_riseAsylum=="Fairly" ] <- 3
pilot1$certain_riseAsylum[pilot1$Certain_riseAsylum=="Very" ] <- 4
pilot1$certain_riseAsylum[pilot1$Certain_riseAsylum=="Absolutely" ] <- 5
pilot1$certain_riseAsylum <- as.numeric(as.character(pilot1$certain_riseAsylum))

# Compared to countries like France, Spain and the Netherlands, the UK takes more than its fair share of refugees.

pilot1$T_fairShare <- as.factor(as.character(pilot1$T_fairShare))

pilot1$fairShare[pilot1$T_fairShare=="TRUE" ] <- 1
pilot1$fairShare[pilot1$T_fairShare=="FALSE" ] <- 0

pilot1$certain_fairShare[pilot1$Certain_fairShare=="Not At All" ] <- 1
pilot1$certain_fairShare[pilot1$Certain_fairShare=="Not Very" ] <- 2
pilot1$certain_fairShare[pilot1$Certain_fairShare=="Fairly" ] <- 3
pilot1$certain_fairShare[pilot1$Certain_fairShare=="Very" ] <- 4
pilot1$certain_fairShare[pilot1$Certain_fairShare=="Absolutely" ] <- 5
pilot1$certain_fairShare <- as.numeric(as.character(pilot1$certain_fairShare))

# More than 10 per cent of the UK population is Muslim.

pilot1$T_loadsOfMuslim <- as.factor(as.character(pilot1$T_loadsOfMuslim))

pilot1$loadsOfMuslim[pilot1$T_loadsOfMuslim=="TRUE" ] <- 1
pilot1$loadsOfMuslim[pilot1$T_loadsOfMuslim=="FALSE" ] <- 0

pilot1$certain_loadsOfMuslim[pilot1$Certain_loadsOfMuslim=="Not At All" ] <- 1
pilot1$certain_loadsOfMuslim[pilot1$Certain_loadsOfMuslim=="Not Very" ] <- 2
pilot1$certain_loadsOfMuslim[pilot1$Certain_loadsOfMuslim=="Fairly" ] <- 3
pilot1$certain_loadsOfMuslim[pilot1$Certain_loadsOfMuslim=="Very" ] <- 4
pilot1$certain_loadsOfMuslim[pilot1$Certain_loadsOfMuslim=="Absolutely" ] <- 5
pilot1$certain_loadsOfMuslim <- as.numeric(as.character(pilot1$certain_loadsOfMuslim))

# Immigrants receive more in benefits and services than they pay in taxes.

pilot1$T_benefitsServices <- as.factor(as.character(pilot1$T_benefitsServices))

pilot1$benefitsServices[pilot1$T_benefitsServices=="TRUE" ] <- 1
pilot1$benefitsServices[pilot1$T_benefitsServices=="FALSE" ] <- 0

pilot1$certain_benefitsServices[pilot1$Certain_benefitsServices=="Not At All" ] <- 1
pilot1$certain_benefitsServices[pilot1$Certain_benefitsServices=="Not Very" ] <- 2
pilot1$certain_benefitsServices[pilot1$Certain_benefitsServices=="Fairly" ] <- 3
pilot1$certain_benefitsServices[pilot1$Certain_benefitsServices=="Very" ] <- 4
pilot1$certain_benefitsServices[pilot1$Certain_benefitsServices=="Absolutely" ] <- 5
pilot1$certain_benefitsServices <- as.numeric(as.character(pilot1$certain_benefitsServices))


### Pilot 2 ###

pilot2 <- read.csv("/Users/cstedtnitz/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Pre-Test/Pre-Test II/pretest2_words.csv")
# pilot2 <- read.csv("/Users/christine/Dropbox/1.PhD/1.Papers/3.BAgrantProject/Pre-Test/Pre-Test II/pretest2_words.csv")

# Delete first 2 rows (headers) 
pilot2 <- pilot2[-(1:2) , ]


# Create dummies for leave/remain 
pilot2$leave <- NA
pilot2$leave[pilot2$voteLeave=="I voted to LEAVE the European Union."] <- "Leave"
pilot2$leave[pilot2$wouldVoteLeave=="I would have voted to LEAVE the European Union." ] <- "Leave"
pilot2$leave[pilot2$brexitWouldVote=="I would have voted to LEAVE the European Union." ] <- "Leave"

pilot2$leave[pilot2$voteLeave=="I voted to REMAIN in the European Union." ] <- "Remain"
pilot2$leave[pilot2$wouldVoteLeave=="I would have voted to REMAIN in the European Union." ] <- "Remain"
pilot2$leave[pilot2$brexitWouldVote=="I would have voted to REMAIN in the European Union." ] <- "Remain"

# Create variable for immigration opinions
pilot2$immigration_1 <- as.numeric(as.character(pilot2$immigration_1))
pilot2$immigOpinions3[pilot2$immigration_1 < 3] <- "fewer"
pilot2$immigOpinions3[pilot2$immigration_1 == 3] <- "no change"
pilot2$immigOpinions3[pilot2$immigration_1 > 3] <- "more"
pilot2$immigOpinions3 <- factor(pilot2$immigOpinions3, levels = c("fewer", "no change", "more"))


pilot2$immigOpinions2[pilot2$immigration_1 < 3] <- "anti-immig"
pilot2$immigOpinions2[pilot2$immigration_1 >= 3] <- "pro-immig"
pilot2$immigOpinions2 <- factor(pilot2$immigOpinions2, levels = c("anti-immig", "pro-immig"))

# Liberal misperceptions

# The majority of crimes in London are committed by white people.

pilot2$crime_white <- ifelse(pilot2$l_crime_T == "Definitely False", 1, 
                      ifelse(pilot2$l_crime_T == "Probably False", 2, 
                      ifelse(pilot2$l_crime_T == "Probably True", 3, 
                      ifelse(pilot2$l_crime_T == "Definitely True", 4, NA))))

pilot2$strong_crime_white <- ifelse(pilot2$l_crime_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$l_crime_Certain == "3", 4, 
                              ifelse(pilot2$l_crime_Certain == "2", 3, 
                              ifelse(pilot2$l_crime_Certain == "1", 2,
                              ifelse(pilot2$l_crime_Certain == "0 - Not very strongly", 1, NA)))))

# Immigration to the UK does not affect the wages of the low-paid.

pilot2$low_paid <- ifelse(pilot2$l_lowPaid_T == "Definitely False", 1, 
                      ifelse(pilot2$l_lowPaid_T == "Probably False", 2, 
                      ifelse(pilot2$l_lowPaid_T == "Probably True", 3, 
                      ifelse(pilot2$l_lowPaid_T == "Definitely True", 4, NA))))

pilot2$strong_low_paid <- ifelse(pilot2$l_lowPaid_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$l_lowPaid_Certain == "3", 4, 
                              ifelse(pilot2$l_lowPaid_Certain == "2", 3, 
                              ifelse(pilot2$l_lowPaid_Certain == "1", 2,
                              ifelse(pilot2$l_lowPaid_Certain == "0 - Not very strongly", 1, NA)))))

# UK courts are more likely to convict black defendants than white defendants. 

pilot2$courts <- ifelse(pilot2$l_defendants_T == "Definitely False", 1, 
                      ifelse(pilot2$l_defendants_T == "Probably False", 2, 
                      ifelse(pilot2$l_defendants_T == "Probably True", 3, 
                      ifelse(pilot2$l_defendants_T == "Definitely True", 4, NA))))

pilot2$strong_crime_white <- ifelse(pilot2$l_defendants_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$l_defendants_Certain == "3", 4, 
                              ifelse(pilot2$l_defendants_Certain == "2", 3, 
                              ifelse(pilot2$l_defendants_Certain == "1", 2,
                              ifelse(pilot2$l_defendants_Certain == "0 - Not very strongly", 1, NA)))))

# The proportion of immigrants in prison is approximately the same as the proportion of immigrants in the UK.

pilot2$prison <- ifelse(pilot2$l_prison_T == "Definitely False", 1, 
                      ifelse(pilot2$l_prison_T == "Probably False", 2, 
                      ifelse(pilot2$l_prison_T == "Probably True", 3, 
                      ifelse(pilot2$l_prison_T == "Definitely True", 4, NA))))

pilot2$strong_prison <- ifelse(pilot2$l_prison_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$l_prison_Certain == "3", 4, 
                              ifelse(pilot2$l_prison_Certain == "2", 3, 
                              ifelse(pilot2$l_prison_Certain == "1", 2,
                              ifelse(pilot2$l_prison_Certain == "0 - Not very strongly", 1, NA)))))

# The rate of net migration to the UK has not increased much in recent decades. 

pilot2$net_migration <- ifelse(pilot2$l_noIncrease_T == "Definitely False", 1, 
                        ifelse(pilot2$l_noIncrease_T == "Probably False", 2, 
                        ifelse(pilot2$l_noIncrease_T == "Probably True", 3, 
                        ifelse(pilot2$l_noIncrease_T == "Definitely True", 4, NA))))

pilot2$strong_net_migration <- ifelse(pilot2$l_noIncrease_Certain == "4 - Very Strongly", 5, 
                                ifelse(pilot2$l_noIncrease_Certain == "3", 4, 
                                ifelse(pilot2$l_noIncrease_Certain == "2", 3, 
                                ifelse(pilot2$l_noIncrease_Certain == "1", 2,
                                ifelse(pilot2$l_noIncrease_Certain == "0 - Not very strongly", 1, NA)))))


# Conservative misperceptions

# There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years. 

pilot2$asylum <- ifelse(pilot2$c_riseAsylum_T == "Definitely False", 1, 
                 ifelse(pilot2$c_riseAsylum_T == "Probably False", 2, 
                 ifelse(pilot2$c_riseAsylum_T == "Probably True", 3, 
                 ifelse(pilot2$c_riseAsylum_T == "Definitely True", 4, NA))))

pilot2$strong_asylum <- ifelse(pilot2$c_riseAsylum_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$c_riseAsylum_Certain == "3", 4, 
                              ifelse(pilot2$c_riseAsylum_Certain == "2", 3, 
                              ifelse(pilot2$c_riseAsylum_Certain == "1", 2,
                              ifelse(pilot2$c_riseAsylum_Certain == "0 - Not very strongly", 1, NA)))))

# Immigrants in the UK receive more in benefits and services than they pay in taxes. 

pilot2$benefits <- ifelse(pilot2$c_benefits_T == "Definitely False", 1, 
                      ifelse(pilot2$c_benefits_T == "Probably False", 2, 
                      ifelse(pilot2$c_benefits_T == "Probably True", 3, 
                      ifelse(pilot2$c_benefits_T == "Definitely True", 4, NA))))

pilot2$strong_benefits <- ifelse(pilot2$c_benefits_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$c_benefits_Certain == "3", 4, 
                              ifelse(pilot2$c_benefits_Certain == "2", 3, 
                              ifelse(pilot2$c_benefits_Certain == "1", 2,
                              ifelse(pilot2$c_benefits_Certain == "0 - Not very strongly", 1, NA)))))

# Immigration from Europe has increased crime. 

pilot2$more_crime <- ifelse(pilot2$c_crime_T == "Definitely False", 1, 
                      ifelse(pilot2$c_crime_T == "Probably False", 2, 
                      ifelse(pilot2$c_crime_T == "Probably True", 3, 
                      ifelse(pilot2$c_crime_T == "Definitely True", 4, NA))))

pilot2$strong_more_crime <- ifelse(pilot2$c_crime_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$c_crime_Certain == "3", 4, 
                              ifelse(pilot2$c_crime_Certain == "2", 3, 
                              ifelse(pilot2$c_crime_Certain == "1", 2,
                              ifelse(pilot2$c_crime_Certain == "0 - Not very strongly", 1, NA)))))

# In proportion to its population the UK takes more refugees than nearby countries like France, Denmark and the Netherlands.

pilot2$fair_share <- ifelse(pilot2$c_fairShare_T == "Definitely False", 1, 
                      ifelse(pilot2$c_fairShare_T == "Probably False", 2, 
                      ifelse(pilot2$c_fairShare_T == "Probably True", 3, 
                      ifelse(pilot2$c_fairShare_T == "Definitely True", 4, NA))))

pilot2$strong_fair_share <- ifelse(pilot2$c_fairShare_Certain == "4 - Very Strongly", 5, 
                              ifelse(pilot2$c_fairShare_Certain == "3", 4, 
                              ifelse(pilot2$c_fairShare_Certain == "2", 3, 
                              ifelse(pilot2$c_fairShare_Certain == "1", 2,
                              ifelse(pilot2$c_fairShare_Certain == "0 - Not very strongly", 1, NA)))))

pilot1$immigration_1 <- as.numeric(as.character(pilot1$immigration_1))
pilot2$immigration_1 <- as.numeric(as.character(pilot2$immigration_1))

# NB Not merging after all because we used different answer options for the false facts
# Pilot 1 is a true-false scale, pilot 2 a four-point scale

# # MERGE
# 
# pilots <- full_join(pilot1, pilot2, by=c("id", "RecordedDate", "StartDate", "EndDate", "ResponseId", "votedEURef", "immigration_1", "immigOpinions2", "brexitWouldVote", "voteLeave", "wouldVoteLeave", "Status", "IPAddress", "Progress", "Duration..in.seconds.", "Finished", "RecipientLastName", "RecipientFirstName", "RecipientEmail", "ExternalReference", "LocationLatitude", "LocationLongitude", "DistributionChannel", "UserLanguage"))
# 
# # Delete variables and anonymise
# 
# drop <- c("Status", "IPAddress", "Progress", "Duration..in.seconds.", "Finished", "RecipientLastName", "RecipientFirstName", "RecipientEmail", "ExternalReference", "LocationLatitude", "LocationLongitude", "DistributionChannel", "UserLanguage")
# 
# pilots = pilots[,!(names(pilots) %in% drop)]

```

We conducted two small pilot studies to identify prominent false beliefs about immigration, and a trustworthy source for our fact checks. In the first pilot fielded on 24 Nov 2018, we tried to identify a source for the fact-checks that would be equally trusted by rspondents with different views on immigration. 
Table 7 shows average levels of trust in information about immigration from various sources on a scale from 1 (not at all) to 5 (completely). The most trusted source among respondents on both sides of the immigration divide was the 'spokesperson at the Office for National Statistics'; followed by the 'Professor of Economics at the University of Oxford'. Hence, we made our fact-checker a Professor of Economics at the University of Oxford and gave him work experience at the Office for National Statistics. To keep the authoritative version of the undermining message at about the same level of authoritativeness as the fact-check we also attributed it to a 'Professor of Economics', switching the institution to the London School of Economics. 


```{r pilot1_sources using vtable, warning = FALSE, message = FALSE, echo = FALSE}

df_pilot1_sources <-
pilot1 %>%
  select(`Immigration preferences` =  immigOpinions2,
         `Journalist from the BBC News Reality Check Team` =  bbc,
         `Researcher at the at the House of Commons Library`= hoc,
         `Research fellow at the Social Market Foundation`= smf,
         `UK Border Agency official` = border_agency,
         `Spokesperson at the Office for National Statistics` =  ons,
         `Researcher at Migration Watch UK`= mig_watch,
         `Professor of Economics at the University of Oxford` = oxf_econ,
         `Fellow at Chatham House`= chat_house, #  The Royal Institute of International Affairs
         `Researcher at Oxford University's Migration Observatory`= oxf_pol # A researcher at the Migration Observatory at the University of Oxford
         )

library("vtable")
sumtable(df_pilot1_sources,
         # vars=c("riseAsylum", "fairShare"),
         out="kable",
         group = 'Immigration preferences', 
         # col.width=c(60,rep(13,6)), # only for latex
         # fit.page='.5\\textwidth',  # only for latex
         title="Trust in information from various sources (Pilot Study 1)",
         note = 'Note: Pilot 1 (24 Nov 2018), prolific academic, n=124 UK respondents')


```


To identify common misperceptions we also piloted a number of false facts from from UK fact checking websites. 
<!-- We also piloted a number of false facts drawn from various fact-checking sites. In both pilots, we asked, "Here are a few statements relating to Britain today. Would you say that they are true or false?".  -->
In our first pilot study, we asked respondents to rate the following statements as 'true' or 'false': 
(1) 'There has seen a sharp rise in the number of people applying for asylum in the UK in the past 10 years.',
(2) 'Compared to countries like France, Spain and the Netherlands, the UK takes more than its fair share of refugees.', 
(3) 'More than 10 per cent of the UK population is Muslim.', 
(4) 'Immigrants receive more in benefits and services than they pay in taxes.', 
(5) 'Immigration to the UK does not affect the wages of the low paid.', 
(6) 'UK courts are more likely to convict black defendants than white defendants.', 
(7) 'The UK is the only major Western democracy to include international students in its net migration statistics.', 
(8) 'The rate of net migration to the UK has not increased much in recent decades.'
<!-- and followed up with a question on certainty ('absolutely certain', 'very certain', 'fairly certain', and 'not very certain'). -->
We found high levels of belief in three of the anti-immigration statements but relatively low levels of belief in the pro-immigration statements. 

```{r pilot1_misperceptions using vtable, warning = FALSE, message = FALSE, echo = FALSE}

# https://cran.r-project.org/web/packages/vtable/vignettes/vtablefunction.html

df_pilot1_misperceptions <- 
pilot1 %>%
  select(immigOpinions2, 
  `Immigration preferences` =  immigOpinions2,
  '(1) sharp rise in number of asylum seekers' =  riseAsylum,
  '(2) UK takes in its fair share' =  fairShare, 
  '(3) 10 per cent Muslim' =  loadsOfMuslim, 
  '(4) immigrants receive more than they pay' =  benefitsServices,
  '(5) no effect on low wages' = noEffectLowPaid,
  '(6) courts more likely to convict black defendants' =  racistCourts,
  '(7) UK includes students in migration statistics' =  studentsInStats, 
  '(8) net migration has not increased' = noIncrease) 

library("vtable")
sumtable(df_pilot1_misperceptions,
         # vars=c("riseAsylum", "fairShare"),
         out="kable",
         group = 'Immigration preferences', 
         # col.width=c(60,rep(13,6)), # only for latex
         # fit.page='.5\\textwidth',  # only for latex
         title="Belief in false statements  (Pilot Study 1)",
         note = "Note: Pilot 1 (24 Nov 2018), prolific academic, n=124 UK respondents.") # Outcome variable: 'True' (1), 'False' (0).

# labs <- c('numeric aggregate personal savings',
#     'numeric % of population under 15',
#     'numeric % of population over 75',
#     NA,
#     'numeric % growth rate of dpi')
# sumtable(LifeCycleSavings,labels=labs)

```


In our second pilot study, we tested belief in a few more false statements that we thought might be popular among pro-immigration respondents. We replaced the binary true/false scale with a four-point scale, asking respondents to rate each false statement as 'definitely true' (4), 'probably true' (3), 'probably false' (2), or 'definitely false' (1). Respondents assessed the following statements: 
(1) 'There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years.'; 
(2) 'Immigrants in the UK receive more in benefits and services than they pay in taxes.'; 
(3) 'Immigration from Europe has increased crime.'; 
(4) 'In proportion to its population the UK takes more refugees than nearby countries like France, Denmark and the Netherlands.'; 
(5) 'The majority of crimes in London are committed by white people.'; 
(6) 'Immigration to the UK does not affect the wages of the low-paid.';
^[U.S. readers may be surprised to find statement 6 ("Immigration to the UK does not affect the wages of the low-paid") categorized as false. There is an ongoing debate about the overall effect of immigration on local wages, with some U.S. studies (most notably, @Ottaviano2012) finding a positive effect on local wages. In the U.K., however, recent research has shown that the effect differs of immigration on wages depends on the sector: Immigration to the U.K. has had a positive, or no effect on wages for high-skilled jobs, but a negative effect on wages for low-skilled jobs [@Parekh2017; @Nickell2017; @Dustmann2013].]
(7) 'UK courts are more likely to convict black defendants than white defendants.'; 
(8) 'The proportion of immigrants in prison is approximately the same as the proportion of immigrants in the UK.'; 
(9) 'The rate of net migration to the UK has not increased much in recent decades.' For the main study, we chose four claims that were clearly false and easily proven wrong -- two that were popular among those with anti-immigration views (statements 1 and 2), and two that were popular among those with pro-immigraiton views (statements 5 and 6). 

```{r pilot2_misperceptions using vtable, warning = FALSE, message = FALSE, echo = FALSE}

df_pilot2_misperceptions <- 
pilot2 %>%
  select(immigOpinions2, 
         `Immigration preferences` =  immigOpinions2,
         '(1) sharp rise in the number of asylum seekers' = asylum, 
         '(2) immigrants receive more than they pay'= benefits,
         '(3) European immigration has increased crime'= more_crime, 
         '(4) UK takes in its fair share'= fair_share,
         '(5) most London crimes committed by white people' = crime_white,
         '(6) no effect on low wages' = low_paid,
         '(7) courts more likely to convict black defendants' = courts,
         '(8) proportion of immigrants in prison' = prison,
         '(9) no increase in net migration' = net_migration
         ) 


library("vtable")
sumtable(df_pilot2_misperceptions,
         # vars=c("riseAsylum", "fairShare"),
         out="kable",
         group = 'Immigration preferences', 
         # col.width=c(60,rep(13,6)), # only for latex
         # fit.page='.5\\textwidth',  # only for latex
         title="Belief in false facts (Pilot Study 2)",
         note = 'Note: 29 Nov 2018, prolific academic, n=199 UK respondents.') # Outcome variable: definitely false (1), probably false (2), probably true (3), definitely true (4)'

```


\newpage

# Appendix D - Questionnaire {-}

## Stage 1 {.unlisted .unnumbered}

### Background characteristics  {.unlisted .unnumbered}

<!-- (e.g. gender, age, region, education, profession, party identity) -->

Q1	**[gender]** Which of the following best describes how you think of yourself?   [OPTIONS: Male; Female; In another way]

Q2 **[age]** And how old are you? 

Q3	**[region]** Where do you live? [OPTIONS: Northern Ireland; Scotland; North West; North East; Yorkshire and the Humber; Wales; West Midlands; East Midlands; South West; South East; Eastern; London; Other]

Q4	**[education]** What is the highest educational level that you have achieved? 

[OPTIONS: Secondary school; University degree or equivalent professional qualification, NVQ level 4 etc; Higher university degree, doctorate, MBA, NVQ level 5 etc; Still in full time education; No formal education; Dont know/prefer not to answer]

Q5	**[profession]** Please indicate which one of the following best describes the profession of the chief income earner in your household. 

[OPTIONS: High managerial, administrative or professional e.g. doctor, lawyer, medium / large company director (50+ people); Intermediate managerial, administrative or professional e.g. teacher, manager, accountant; Supervisor, administrative or professional e.g. policeman, nurse, secretary, self-employed; Skilled manual worker e.g. mechanic, plumber, electrician, lorry driver, train driver; Semi-skilled or unskilled manual worker e.g. waiter, factory worker, receptionist, labourer; House-wife / house-husband; Unemployed;	Student; Retired]

Q6	**[postcode]** This survey needs you to enter your full postcode before proceeding. 
The postcode is used purely to collect information about the area you live in to be analysed in relation to the other data we collect. It will not be used to identify you individually, or be used for any other purpose other than for academic research. We would like to reassure you that your answers are anonymous and will be completely confidential. PLEASE WRITE IN YOUR FULL POSTCODE:

Q7	**[voteTom]** On a scale of 0 (certain NOT to vote) to 10 (absolutely certain to vote), how likely would you be to vote in a general election tomorrow? 

Q8	**[voteTomParty]** If there were a general election held tomorrow, which party would you vote for? 

[OPTIONS: Conservative; Labour; Liberal Democrat; UK Independence Party (UKIP);	Scottish National Party (SNP); Plaid Cymru (PC); Green; Some other party; Would not vote; Dont know; Refuse]

Q9	**[voteTomParty2]** And now imagine The Independent Group (TIG) and The Brexit Party put up candidates at the next general election. The Conservative party, Labour, Liberal Democrats, UKIP and other parties also stand. How would you then vote?  ...

Q10	**[vote2017]** Talking to people about the General Election on June 8th 2017, we have found that a lot of people didnt manage to vote. How about you - did you manage to vote in the General Election in 2017? [OPTIONS: Yes; No]

Q11	**[vote2017Party]** Which party did you vote for in the General Election on June 8th 2017?  ...

Q12	**[attention]** How much attention do you generally pay to politics? Please use the following scale, where 0 means no attention at all and 10 means a great deal of attention 

Q13	**[issues]** Here are some issues facing Britain today. Please choose the three issues that are most important to you and rank them from 1 (most important) to 3 (third most important). *[randomize order]*

[OPTIONS: Immigration [issues_immig]; The economy [issues_econ]; NHS/Health [issues_nhs]; Crime [issues_crime]; EU/Brexit [issues_eu]; Housing [issues_housing]; Schools/Education 

Here is a short list of statements. How much you agree or disagree with each one? *[randomize order]*

Q14	**[ethno1]** Britain has a lot to learn from other countries in running its affairs. 

Q15	**[pop_no_compromise]** What people call compromise in politics is really just selling out on ones principles.  

Q16	**[ethno2]** I would rather be a citizen of Britain than of any other country in the world.  

Q17	**[pop_people_make_decisions]** The people, and not politicians, should make our most important policy decisions.  

Q18	**[immigFeelLikeHome]** There are so many foreigners round here that it doesnt feel like home any more.  

Q19	**[ethno6]** I am often less proud of Britain than I would like to be.  

[OPTIONS: Strongly Agree, Agree, Disagree, Strongly Disagree, Dont Know]

Q20	**[rightLeft]** Some people talk about 'left', 'right', and 'centre' to describe parties and politicians. Where would you place yourself on this scale? 

[OPTIONS: Very left wing, fairly left wing, slightly left wing, centre, slightly right wing, fairly right wing, very right wing, dont know]

Q21	**[immig]** Some people think that we should allow many fewer immigrants come to the UK and others think that we should allow many more immigrants. Where would you place yourself on this scale? 

[OPTIONS: -3 = many fewer, 0 = no change, +3 = many more]

Q22	**[immigImportance]** How important to you is this issue? 

[OPTIONS: Extremely important (4), very important (3), somewhat important (2), not at all important (1)]

Now here is another list of statements.  Again, please say how much you agree or disagree. *[randomize order]*

Q23	**[ethno3]** There are some things about Britain today that make me ashamed to be British.    
Q24	**[ethno5]** The world would be a better place if people from other countries were more like the British.    
Q25	**[pop_rep_by_citizen]** I would rather be represented by a citizen than by a specialized politician.    
Q26	**[pop_pol_talk_too_much]** Elected officials talk too much and take too little action.
Q27	**[immigEcon]** Immigration is good for the British economy.   
Q28 **[ethno4]**	People in Britain are too ready to criticise their country.   

[OPTIONS: Strongly Agree; Agree; Disagree; Strongly Disagree; Dont Know]

### Belief in false claims about immigration  {.unlisted .unnumbered}

And here is a third list of statements. This time, wed like you to say whether, to the best of your knowledge, they are true or false? *[randomize order]*

Q29 **[noAsylum_T1]** There has been a sharp rise in the number of people applying for asylum in the UK in the past ten years. 						
Q30 **[costImmig_T1]** European immigrants receive more in benefits and services than they pay in taxes. 	
Q31 **[whiteCrime_T1]**	The majority of crimes in London are committed by white people, not ethnic minorities. 							
Q32 **[lowPaid_T1]** Immigration to the UK does not affect the wages of the low-paid. 			
Q33 **[no5_T1]**	Britain is the fifth largest economy in the world. 							
Q34 **[recession_T1]**	The Leave vote in June 2016 did not result in an instant UK recession. 	
Q35 **[fracking_T1]**	Fracking causes earthquakes. 							
Q36 **[plasticBags_T1]** Englands plastic bag usage dropped 85% since 5p charge was introduced. 	 	

[OPTIONS: 0 Definitely False;	1; 2; 3; 4; 5; 6 Definitely True]


## Stage 2 - Fact-Check  {.unlisted .unnumbered}

We have asked Richard Clarke, Professor of Economics at the University of Oxford to provide us with information about the statements you just read. On the following page, you will see some detailed information about one of these statements, that is:  
*[Re-print the false statement respondents rated closest to true, i.e. Q29, Q30, Q31, or Q32. If two or more were given the same highest score, randomly assign respondents to one of them. Then show the respective fact-check.]*

<!-- *[Next page:]* -->

![](/Users/cstedtnitz/Dropbox/Bibtex/images/richard_clark.jpg){width=50%}

By Professor Richard Clark

University of Oxford

Professor Richard Clark is a Professor of Population Economics at the University of Oxford. From 2009 to 2015, he was a Consultant on Population and Demography with the Office for National Statistics (ONS).  Professor Clarke holds a PhD from Harvard University.

*[Insert respective fact-check, as shown below]*

### Fact-check: "There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years."  {.unlisted .unnumbered}

![](/Users/cstedtnitz/Dropbox/Bibtex/images/no_asylum_fact_check.jpg){width=100%}

This statement is false. Asylum applications in the UK have remained stable over the past ten years.  It is true is that there has been a sharp rise in the number of people crossing into Europe in 2015. Few of these made it to the UK. Germany, Sweden and Hungary shouldered most of the asylum claims. The graph below is based on the official immigration statistics that the Home Office publishes every year. It shows the number of asylum applications the UK received since 2001. The UK receives about the same number of refugees today than it did ten years ago.

<!-- \newpage -->
### Fact-check: "European immigrants receive more in benefits and services than they pay in taxes."  {.unlisted .unnumbered}

![](/Users/cstedtnitz/Dropbox/Bibtex/images/cost_immig_fact_check.jpg){width=100%}

This statement is false. European immigrants pay substantially more in taxes to the government than they receive in benefits or public services. According to the most recent data European migrants made a total contribution of 4.7bn to the public finances in 2016-17. This graph shows how much migrants contribute relative to how much the average UK citizen contributes. An average adult migrant from one of the 13 countries that joined the EU before 2004 (most of Western Europe) contributed 3,740 more to Britains exchequer than an average UK citizen. Migrants from countries that joined after 2004 (that includes Eastern European countries) paid an average of 1,040 more in taxes than they receive.

<!-- \newpage -->

### Fact-check: "The majority of crimes in London are committed by white people."  {.unlisted .unnumbered}

![](/Users/cstedtnitz/Dropbox/Bibtex/images/white_crime_fact_check.jpg){width=100%}

This statement is false. According to data from the Office for National Statistics (ONS) 43% of the population in London in 2017 identified as black, Asian and minority ethnic (BAME). But, as on the right-hand side of the graph below, 56% of all crime offenders were BAME. How overrepresented BAME offenders are depends on the type of crime. Every blue bar that exceeds the 43% dotted line means that, for this crime, BAME people are overrepresented. There are three offenses for which BAME people are particularly overrepresented:  Drugs, Robbery, and Sexual Offenses.

<!-- \newpage -->

### Fact-check: "Immigration to the UK does not affect the wages of the low-paid."  {.unlisted .unnumbered}

![](/Users/cstedtnitz/Dropbox/Bibtex/images/low_paid_fact_check.jpg){width=100%}

This statement is false. You have to distinguish between sectors. It is true that in many sectors immigration has no effect on wages. But things are different in the less skilled sector  that is, for people working as cleaners, in care homes, in bars and restaurants, and so on. One of my Oxford colleagues and his co-author at the Bank of England looked at the effect of immigration on wages in different sectors from 1992 to 2016. Their results are clear: in the semi- and unskilled sector, 10 per cent more immigrants in a region led to a 2.6 percent reduction in hourly pay.

\newpage

*[Buffer questions]*

Q37	**[marital]** Which of the following best describes your marital status? [OPTIONS: Single; Married; Civil partnership; Co-habiting; Widowed; Separated; Divorced; Prefer not to answer]

Q38	**[kidsNoAnswer]** Do you have any children aged 18 or under? If so, how old are they?

[OPTIONS: No children aged 18 or under [kidsNone]; Yes - children aged under 5 years old  [kidsUnder5];  Yes - children aged 5-10 years old [kids5to10];  Yes - children aged 11-15 years old  [kids11to15] ; Yes - children aged 16-18 years old [kids16to18];  Prefer not to answer]

Q39	**[householdIncome]** What is the combined annual income of your household, prior to tax being deducted? 

[OPTIONS: Up - 7,000; 7,001 - 14,000; 14,001 - 21,000; 21,001 - 28,000;	28,001 - 34,000; 34,001 - 41,000; 41,001 - 48,000; 48,001 - 55,000; 55,001 - 62,000; 62,001 - 69,000; 69,001 - 76,000; 76,001 - 83,000; 83,001 or more; Prefer not to answer]

Q40	**[supportParty]** Generally speaking, do you usually think of yourself as supporter of any one particular party? [*If yes:*]

Q41	**[party]** Which party is that? 

[OPTIONS: Conservative; Labour; Liberal Democrat; UKIP; Scottish National Party; Plaid Cymru; Green; Other [Write in] 

Q42	**[votedEURef]** Did you vote in the referendum on the UKs membership of the EU held on 23 June 2016? [OPTIONS: Yes;	No]

Q43	**[brexitVote]**[If Yes:] And how did you vote in the referendum? [OPTIONS: Leave; Remain; Can't Remember]

Q44	**[hypBrexitVote]** [If No:] How do you think you would have voted if you had taken part? Please select one option [OPTIONS: Leave; Remain; Don't Know]

\newpage

## Stage 3 - Undermining message  {.unlisted .unnumbered}

*Experimental design at Stage 4: Randomly split respondents into eight groups: Groups 1 and 2 (control group, 25% of the sample): Proceed directly to stage 4. Groups 3-5 see an undermining message attributed to a professor: Expert bias (3), Personal experience (4), Truthiness (5). Groups 6-8 see an undermining message attributed a a blogger: Expert bias (6), Personal experience (7), Truthiness (8).*  

Now, we'd like to go back to that earlier statement: 

*[Re-print fact-checked statement.]*

\newpage

Earlier, you saw some information about that statement. Now, here is a comment on that information from a different source.  


![](/Users/cstedtnitz/Dropbox/Bibtex/images/david_williams.jpg){width=50%}

David Williams  
Professor of Economics at the London School of Economics *[Source: Professor]*. \newline
Blogger *[Source: Blogger]*.   

*[Message: expert bias]*
I would take these statistics with a big pinch of salt. The fact that someone is a professor doesnt mean that they dont have an agenda. And we all know that there is a lot of scope to choose and present statistics so that they end up saying just what want them to say. 

*[Message: personal experience]*
I would take these statistics with a big pinch of salt. A graph might say one thing but the experience of peoples everyday lives could be quite different.  And I think that a lot of people reading those statistics will say: that doesnt sound like the world I live in. 

*[Message: truthiness]*
I would take these statistics with a big pinch of salt. Theres so much information and so many statistics out there that it can be hard to know what to believe.  In that case, I think its best to trust your instincts even if looks as if the facts are different. 

\newpage

## Stage 4  {.unlisted .unnumbered}

### Re-testing belief in false claims  {.unlisted .unnumbered}

Thinking again about these statements: Would you say they are true or false? 

*[If respondent saw one of the anti-immigration statements (Q21 or Q22) fact-checked ask them to re-rate the veracity of both anti-immigration claims. If respondent saw one of the pro-immigration statements (Q23 or Q24) fact-checked ask them to re-rate the veracity of both pro-immigration claims.]*

Q45	**[noAsylum_T2]** There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years.    
Q46	**[costImmig_T2]** Immigrants receive more in benefits and services than they pay in taxes.   

[OPTIONS: 0 Definitely False;	1; 2; 3; 4; 5; 6 Definitely True]

*[If respondent saw one of the pro-immigration statements (Q23 or Q24) fact-checked ask them to re-rate the veracity of both pro-immigration claims.]*

Q47	**[whiteCrime_T2]** The majority of crimes in London are committed by white people, not ethnic minorities.    
Q48	**[lowPaid_T2]** Immigration to the UK does not affect the wages of the low-paid.    

[OPTIONS: 0 Definitely False;	1; 2; 3; 4; 5; 6 Definitely True]

### Post-truth reasoning  {.unlisted .unnumbered}

The last two questions asked you to decide whether those statements are true or false. But sometimes its hard to say whether something is true or false. Sometimes it can be a matter of opinion on which there are different points of view. Thinking again about these statements, and this time on a scale from 0 (purely a matter of fact) to 6 (purely a matter of opinion), how would you rate the two? 

*[If respondent saw one of the anti-immigration statements (Q21 or Q22) fact-checked re-print both anti-immigration statements. If respondent saw one of the pro-immigration statements (Q23 or Q24) fact-checked re-print both pro-immigration statements]*

Q49 **[noAsylum_opinion]**  There has been a sharp rise in the number of people applying for asylum in the UK in the past 10 years.    
Q50 **[costImmig_opinion]** European immigrants receive more in benefits and services than they pay in taxes.    

[OPTIONS: 0 Purely a matter of fact;	1; 2; 3; 4; 5; 6 Purely a matter of opinion]

*[If respondent saw one of the pro-immigration statements (Q23 or Q24) fact-checked]:*

Q51 **[whiteCrime_ opinion]** The majority of crimes in London are committed by white people, not ethnic minorities. 

Q52 **[costImmig_ opinion]** Immigration to the UK does not affect the wages of the low-paid.  
[OPTIONS: 0 Purely a matter of fact;	1; 2; 3; 4; 5; 6 Purely a matter of opinion]


Q53	**[consistent]** Sometimes people see a difference between what they believed was true and what the statistics say.  Would you say that the statistics here were consistent with what you believed? 

[OPTIONS: Yes, No] *[IF 'Yes', skip to Q43, If 'No' show Q54:]*

Q54 **[ifInconsistent]** Which of these best describes where you stand? 

[OPTIONS: The statistics are probably right, but I believe something different;	I think that the statistics are wrong;	The statistics made me change my mind.] *[randomize order]*

Q55	**[ok2disagree]** And how much would you agree or disagree with the following statement: "Its OK to disagree with the facts if thats what you believe"

[OPTIONS: Strongly Agree [4]; Agree [3]; Disagree [2]: Strongly Disagree [1]]


### Trust in the source of the fact-check  {.unlisted .unnumbered}

Now we would like you to think back about the article you read at the very beginning of this survey, written by Richard Clark, Professor of Population Economics at the University of Oxford (see photo). It provided some information, including a graph about one of the statements you rated on a scale from 'true' to 'false'. *[Re-print Richard Clarks photo]*

Q56	**[accurate_Expert]** How accurate would you say was the information this professor used? 

[OPTIONS: Not at all accurate (1), Not very accurate (2), Fairly accurate (3), Very accurate (4), Cant remember (5)]

Q57	**[trust_Expert]** And how much would you generally trust what this professor says on the issue of immigration?

[OPTIONS: 0 Would not trust at all; 1; 2; 3; 4; 5; 6 Would trust a great deal; Cant remember]

*[GROUPS 1-2 (who did not see the comment from the 2nd source) end here.]*


### Trust in the source of the undermining message  {.unlisted .unnumbered}

*[GROUPS 3-5 (who saw a comment from a blogger):]*

Turning now to the second source, the comment from David Williams (Blogger, see photo) about Professor Clarks article: 

*[Re-print David Williams photo]*

Q58	**[accuratePostTruthBlogger]** How accurate would you say was the information this blogger used? 

[OPTIONS: Not at all accurate; Not very accurate; Fairly accurate; Very accurate; Cant remember]

Q59	**[trustPostTruthBlogger]** And how much would you generally trust what this blogger says on the issue of immigration? 

[OPTIONS: 0 Would not trust at all; 1; 2; 3; 4; 5; 6 Would trust a great deal; Cant remember]

### Trust in the source of the undermining message  {.unlisted .unnumbered}

Groups 6-8 (who saw a comment from a professor):

Turning now to the second source, the comment from David Williams, Professor of Economics at the London School of Economics about Professor Clarks article: [Re-print David Williams photo]

Q60	**[accuratePostTruthProf]** How accurate would you say was the information this professor used? 

[OPTIONS: Not at all accurate; Not very accurate; Fairly accurate; Very accurate; Cant remember]

Q61	**[trustPostTruthProf]** And how much would you generally trust what this professor says on the issue of immigration? 

[OPTIONS: 0 Would not trust at all; 1; 2; 3; 4; 5; 6 Would trust a great deal; Cant remember]


